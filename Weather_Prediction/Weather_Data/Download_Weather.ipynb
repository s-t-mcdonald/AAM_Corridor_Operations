{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3eff47c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e5bf579e99473da64f25eb6d7bc5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: ABE\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yq/cccd6k8570jdry6l6fpch6rw0000gn/T/ipykernel_16236/1647311745.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;31m#     download_alldata()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/yq/cccd6k8570jdry6l6fpch6rw0000gn/T/ipykernel_16236/1647311745.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0muri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s&station=K%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{station} not an airport\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yq/cccd6k8570jdry6l6fpch6rw0000gn/T/ipykernel_16236/1647311745.py\u001b[0m in \u001b[0;36mdownload_data\u001b[0;34m(uri)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mMAX_ATTEMPTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ERROR\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readall_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_readall_chunked\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# Read the next chunk size from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example script that scrapes data from the IEM ASOS download service\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import json\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "\n",
    "# Python 2 and 3: alternative 4\n",
    "try:\n",
    "    from urllib.request import urlopen\n",
    "except ImportError:\n",
    "    from urllib2 import urlopen\n",
    "\n",
    "# Number of attempts to download data\n",
    "MAX_ATTEMPTS = 6\n",
    "# HTTPS here can be problematic for installs that don't have Lets Encrypt CA\n",
    "SERVICE = \"http://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?\"\n",
    "\n",
    "\n",
    "def download_data(uri):\n",
    "    \"\"\"Fetch the data from the IEM\n",
    "    The IEM download service has some protections in place to keep the number\n",
    "    of inbound requests in check.  This function implements an exponential\n",
    "    backoff to keep individual downloads from erroring.\n",
    "    Args:\n",
    "      uri (string): URL to fetch\n",
    "    Returns:\n",
    "      string data\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while attempt < MAX_ATTEMPTS:\n",
    "        try:\n",
    "            data = urlopen(uri, timeout=300).read().decode(\"utf-8\")\n",
    "            if data is not None and not data.startswith(\"ERROR\"):\n",
    "                return data\n",
    "        except Exception as exp:\n",
    "            print(\"download_data(%s) failed with %s\" % (uri, exp))\n",
    "            time.sleep(5)\n",
    "        attempt += 1\n",
    "\n",
    "    print(\"Exhausted attempts to download, returning empty data\")\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_stations_from_filelist(filename):\n",
    "    \"\"\"Build a listing of stations from a simple file listing the stations.\n",
    "    The file should simply have one station per line.\n",
    "    \"\"\"\n",
    "    stations = []\n",
    "    for line in open(filename):\n",
    "        stations.append(line.strip())\n",
    "    return stations\n",
    "\n",
    "\n",
    "def get_stations_from_networks():\n",
    "    \"\"\"Build a station list by using a bunch of IEM networks.\"\"\"\n",
    "    stations = []\n",
    "    states = \"\"\"MA\"\"\"\n",
    "    networks = []\n",
    "    for state in states.split():\n",
    "        networks.append(\"%s_ASOS\" % (state,))\n",
    "\n",
    "    for network in networks:\n",
    "        # Get metadata\n",
    "        uri = (\n",
    "            \"https://mesonet.agron.iastate.edu/geojson/network/%s.geojson\"\n",
    "        ) % (network,)\n",
    "        data = urlopen(uri)\n",
    "        jdict = json.load(data)\n",
    "        for site in jdict[\"features\"]:\n",
    "            stations.append(site[\"properties\"][\"sid\"])\n",
    "    return stations\n",
    "\n",
    "\n",
    "def download_alldata():\n",
    "    \"\"\"An alternative method that fetches all available data.\n",
    "    Service supports up to 24 hours worth of data at a time.\"\"\"\n",
    "    # timestamps in UTC to request data for\n",
    "    startts = datetime.datetime(2020, 1, 1)\n",
    "    endts = datetime.datetime(2020, 12, 20)\n",
    "    interval = datetime.timedelta(hours=24)\n",
    "\n",
    "    service = SERVICE + \"data=all&tz=Etc/UTC&format=comma&latlon=yes&\"\n",
    "\n",
    "    now = startts\n",
    "    while now < endts:\n",
    "        thisurl = service\n",
    "        thisurl += now.strftime(\"year1=%Y&month1=%m&day1=%d&\")\n",
    "        thisurl += (now + interval).strftime(\"year2=%Y&month2=%m&day2=%d&\")\n",
    "        print(\"Downloading: %s\" % (now,))\n",
    "        data = download_data(thisurl)\n",
    "        outfn = \"Training_Data/Data/%s.txt\" % (now.strftime(\"%Y%m%d\"),)\n",
    "        with open(outfn, \"w\") as fh:\n",
    "            fh.write(data)\n",
    "        now += interval\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Our main method\"\"\"\n",
    "    # timestamps in UTC to request data for\n",
    "    startts = datetime.datetime(2019, 1, 1)\n",
    "    endts = datetime.datetime(2019, 12, 20)\n",
    "\n",
    "    service = SERVICE + \"data=all&tz=Etc/UTC&format=comma&latlon=yes&\"\n",
    "\n",
    "    service += startts.strftime(\"year1=%Y&month1=%m&day1=%d&\")\n",
    "    service += endts.strftime(\"year2=%Y&month2=%m&day2=%d&\")\n",
    "\n",
    "    # Two examples of how to specify a list of stations\n",
    "    stations = ['ABE', 'ACK', 'ACY', 'AFN', 'ALB', 'APG',\n",
    "       'AQW', 'ASH', 'AVP', 'BAF', 'BDL', 'BDR', 'BED', 'BGM', 'BID',\n",
    "       'BLM', 'BOS', 'BVY', 'CDW', 'CEF', 'CKZ', 'CQX', 'DOV', 'DXR',\n",
    "       'DYL', 'EWB', 'EWR', 'FIT', 'FMH', 'FOK', 'FRG', 'FWN', 'GHG',\n",
    "       'GON', 'HFD', 'HPN', 'HVN', 'HWV', 'HYA', 'HZL', 'IJD', 'ILG',\n",
    "       'ISP', 'JFK', 'JPX', 'LDJ', 'LGA', 'LNS', 'LOM', 'LWM',\n",
    "       'MGJ', 'MIV', 'MJX', 'MMK', 'MMU', 'MPO', 'MQS', 'MSV',\n",
    "       'MVY', 'N03', 'NEL', 'NYC', 'OQN', 'OQU', 'ORE', 'ORH',\n",
    "       'OWD', 'OXC', 'PHL', 'PNE', 'POU', 'PSF', 'PTW', 'PVC', 'PVD',\n",
    "       'PYM', 'RDG', 'SCH', 'SFZ', 'SMQ', 'SNC', 'SWF', 'TAN', 'TEB',\n",
    "       'TTN', 'UKT', 'UUU', 'VAY', 'W29', 'WRI', 'WST', 'WWD', 'XLL']\n",
    "    # stations = get_stations_from_filelist(\"mystations.txt\")\n",
    "    for station in tqdm(stations):\n",
    "        uri = \"%s&station=K%s\" % (service, station)\n",
    "        print(\"Downloading: %s\" % (station,))\n",
    "        data = download_data(uri)\n",
    "        if len(data)< 1000:\n",
    "            print(f\"{station} not an airport\")\n",
    "            continue\n",
    "            \n",
    "        outfn = \"Training_Data/%s_%s_%s.txt\" % (\n",
    "            station,\n",
    "            startts.strftime(\"%Y%m%d%H%M\"),\n",
    "            endts.strftime(\"%Y%m%d%H%M\"),\n",
    "        )\n",
    "        out = open(outfn, \"w\")\n",
    "        out.write(data)\n",
    "        out.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     download_alldata()\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3b37d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import pydeck as pdk\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from meteostat import Point, Daily, Hourly\n",
    "import pyproj\n",
    "import ipywidgets\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "JFK_LAT_LON = 40.645944, -73.784839\n",
    "LL = 38.585021, -77.555894\n",
    "UR = 42.634826, -70.954819\n",
    "\n",
    "LL = 39.88494891-1, -75.33930212-1\n",
    "UR = 41.888126+1, -72.73301048+3\n",
    "\n",
    "DOWNTOWN_BOUNDING_BOX = [\n",
    "    LL[1],\n",
    "    LL[0],\n",
    "    UR[1],\n",
    "    UR[0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c9b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_bounding_box(point):\n",
    "    \"\"\"Determine whether a point is in our downtown bounding box\"\"\"\n",
    "    lng, lat = point\n",
    "    in_lng_bounds = DOWNTOWN_BOUNDING_BOX[0] <= lng <= DOWNTOWN_BOUNDING_BOX[2]\n",
    "    in_lat_bounds = DOWNTOWN_BOUNDING_BOX[1] <= lat <= DOWNTOWN_BOUNDING_BOX[3]\n",
    "    return in_lng_bounds and in_lat_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef9dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir(\"Training_Data\") if \".txt\" in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "215421c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "addval_start_date = datetime.datetime(2019, 1, 1)\n",
    "addval_end_date = datetime.datetime(2019, 3, 1)\n",
    "addval_daterange = (pd.date_range(start=addval_start_date, end=addval_end_date, freq='5min')).to_frame(name = 'times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "139b63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_array = []\n",
    "for i in range(len(files)):\n",
    "    new_df = pd.read_csv(f\"Training_Data/{files[i]}\", parse_dates=['valid'], skiprows=5, low_memory=False)\n",
    "    new_df = new_df.set_index(\"valid\")\n",
    "    df = pd.merge_asof(left=addval_daterange,right=new_df,right_index=True,left_index=True,direction='nearest')\n",
    "    df_array.append(df)\n",
    "\n",
    "df = pd.concat(df_array)\n",
    "\n",
    "df = df.replace(['M',\"CLR\",\"VV \",\"FEW\",\"SCT\",\"BKN\",\"OVC\"],[0,0,0,0.1,0.3,0.8,1])\n",
    "df[\"vsby\"] = df[\"vsby\"].astype(float)\n",
    "\n",
    "Stations = np.unique(df.station)\n",
    "Times = np.unique(df.times)\n",
    "\n",
    "df = df.set_index(['times','station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9eeae5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056d78cd837849b9b71c8e07b30d4387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16993 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Node_Data = []\n",
    "Y_data = []\n",
    "\n",
    "n_nodes = len(Stations)\n",
    "for time in tqdm(Times):\n",
    "    \n",
    "    Node_Lon_Lat = []\n",
    "    Node_Color = []\n",
    "    Size = []\n",
    "    Vertiport = []\n",
    "    Tooltip = []\n",
    "    IFRs = []\n",
    "    Cloud_Coverages = []\n",
    "    Cloud_Alts = []\n",
    "    East_Winds = []\n",
    "    North_Winds = []\n",
    "    Precips = []\n",
    "    Lons = []\n",
    "    Lats = []\n",
    "\n",
    "    nData = np.zeros((n_nodes, 8))\n",
    "\n",
    "    for i, station in enumerate(Stations):\n",
    "        \n",
    "        arr = df.loc[time,station]\n",
    "        \n",
    "        lon = float(arr[\"lon\"])\n",
    "        lat = float(arr[\"lat\"])\n",
    "        vsby = float(arr[\"vsby\"])\n",
    "        wind_dir = float(arr[\"drct\"]) + 180\n",
    "        wind_speed = float(arr[\"sknt\"])*30.8667 #m/min\n",
    "        precip = float(arr[\"p01i\"])\n",
    "        \n",
    "        e_wind = wind_speed*np.sin(np.deg2rad(wind_dir))\n",
    "        n_wind = wind_speed*np.cos(np.deg2rad(wind_dir))\n",
    "                \n",
    "        IFR = vsby < 3\n",
    "        \n",
    "        skycond = float(arr[f'skyc1'] )\n",
    "        skyalt = float(arr[f'skyl1'])\n",
    "                \n",
    "        for j in range(4):\n",
    "            \n",
    "            skycondt = arr[f'skyc{j+1}'] \n",
    "            skyaltt = float(arr[f'skyl{j+1}'])\n",
    "            \n",
    "            if (skycondt > 0.7) and (skyaltt < 1000):\n",
    "                skycond = skycondt\n",
    "                skyalt = skyaltt\n",
    "                IFR = True\n",
    "                break\n",
    "                \n",
    "        nData[i,0] = float(IFR)\n",
    "        nData[i,1] = skycond\n",
    "        nData[i,2] = skyalt\n",
    "        nData[i,3] = precip\n",
    "        nData[i,4] = e_wind\n",
    "        nData[i,5] = n_wind\n",
    "        nData[i,6] = lon\n",
    "        nData[i,7] = lat\n",
    "        \n",
    "    Node_Data.append(nData)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd11fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_dict = {}\n",
    "for i, data in enumerate(Node_Data):\n",
    "    full_data_dict[i] = data.tolist()\n",
    "\n",
    "with open(\"complete_graph_data_training.json\", \"w\") as outfile:\n",
    "    json.dump(full_data_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
