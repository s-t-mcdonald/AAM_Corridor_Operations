{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "import pydeck as pdk\n",
    "from datetime import datetime\n",
    "\n",
    "import ipywidgets\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import spektral\n",
    "import scipy.sparse as sparse\n",
    "from spektral.datasets.citation import Cora\n",
    "from spektral.layers import GCNConv, GATConv, GCSConv\n",
    "from spektral.models.gcn import GCN\n",
    "from spektral.transforms import AdjToSpTensor, LayerPreprocess\n",
    "from spektral.utils import tic, toc\n",
    "from spektral.data.loaders import BatchLoader\n",
    "from spektral.data import Graph, Dataset\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from spektral.data.loaders import SingleLoader\n",
    "from spektral.datasets.citation import Citation\n",
    "from spektral.layers import ARMAConv, GCNConv, ChebConv, AGNNConv, EdgeConv, ECCConv, DiffusionConv, APPNPConv, GraphSageConv, GATConv\n",
    "from spektral.transforms import LayerPreprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib\n",
    "import json\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "JFK_LAT_LON = 40.645944, -73.784839\n",
    "# LL = 38.585021, -77.555894\n",
    "# UR = 42.634826, -70.954819\n",
    "\n",
    "LL = 39.88494891-2, -75.33930212-2\n",
    "UR = 41.888126+2, -72.73301048+4\n",
    "\n",
    "DOWNTOWN_BOUNDING_BOX = [\n",
    "    LL[1],\n",
    "    LL[0],\n",
    "    UR[1],\n",
    "    UR[0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_bounding_box(point):\n",
    "    \"\"\"Determine whether a point is in our downtown bounding box\"\"\"\n",
    "    lng, lat = point\n",
    "    in_lng_bounds = DOWNTOWN_BOUNDING_BOX[0] <= lng <= DOWNTOWN_BOUNDING_BOX[2]\n",
    "    in_lat_bounds = DOWNTOWN_BOUNDING_BOX[1] <= lat <= DOWNTOWN_BOUNDING_BOX[3]\n",
    "    return in_lng_bounds and in_lat_bounds\n",
    "\n",
    "def haversine(lonlat1, lonlat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance in kilometers between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    lon1, lat1 = lonlat1\n",
    "    lon2, lat2 = lonlat2\n",
    "    \n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 3440.064795 # Radius of earth in meters. Use 3956 for miles. Determines return value units.\n",
    "    return c * r\n",
    "\n",
    "\n",
    "def gaus_kernel(dist, length):\n",
    "    val = np.exp(-(dist**2)/(2*length**2))\n",
    "    return val\n",
    "\n",
    "def return_adj(Node_Data, hour):\n",
    "\n",
    "    adj = np.zeros((n_nodes,n_nodes))\n",
    "    \n",
    "    org_lon_lat = []\n",
    "    new_lon_lat = []\n",
    "    east_winds = []\n",
    "    north_winds = []\n",
    "    for n1 in range(n_nodes):\n",
    "        \n",
    "        e_wind = Node_Data[n1][3]\n",
    "        n_wind = Node_Data[n1][4]\n",
    "        lon_old = Node_Data[n1][6]\n",
    "        lat_old = Node_Data[n1][7]\n",
    "        \n",
    "        e_dist = e_wind*hour\n",
    "        n_dist = n_wind*hour\n",
    "        \n",
    "        nm_per_lon = haversine((lon_old,lat_old), (lon_old+1,lat_old))\n",
    "        nm_per_lat = haversine((lon_old,lat_old), (lon_old,lat_old+1))\n",
    "        \n",
    "        delta_lon =  e_dist/nm_per_lon\n",
    "        delta_lat =  n_dist/nm_per_lat\n",
    "        \n",
    "        new_lon = lon_old - delta_lon\n",
    "        new_lat = lat_old - delta_lat\n",
    "        \n",
    "        org_lon_lat.append([lon_old,lat_old])\n",
    "        new_lon_lat.append([new_lon,new_lat])\n",
    "        east_winds.append(e_wind)\n",
    "        north_winds.append(n_wind)\n",
    "\n",
    "        for n2 in range(n_nodes):\n",
    "\n",
    "            lon = Node_Data[n2][6]\n",
    "            lat = Node_Data[n2][7]\n",
    "            \n",
    "            dist = haversine((new_lon,new_lat), (lon,lat))\n",
    "            \n",
    "            adj[int(n1),int(n2)] = gaus_kernel(dist, 10)\n",
    "\n",
    "           \n",
    "    adj = spektral.utils.convolution.gcn_filter(adj)\n",
    "    \n",
    "    return adj, org_lon_lat, new_lon_lat, east_winds, north_winds\n",
    "\n",
    "\n",
    "def Split_Data(graphs, p_test = .3, p_val = .2):\n",
    "    \n",
    "    N = len(graphs)\n",
    "    \n",
    "    n_test = round(N*p_test)\n",
    "    \n",
    "    n_val = round((N-n_test)*p_val)\n",
    "    \n",
    "    graph_test = graphs[:n_test]\n",
    "    graph_val = graphs[(n_test):(n_test+n_val)]\n",
    "    graph_train = graphs[(n_test+n_val):]\n",
    "    \n",
    "    \n",
    "    return graph_train, graph_val, graph_test\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, Graphs, **kwargs):\n",
    "        self.Graphs = Graphs\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        return self.Graphs\n",
    "    \n",
    "def plot_roc(labels, predictions, **kwargs):\n",
    "    fp, tp, thres = sklearn.metrics.roc_curve(labels, predictions)\n",
    "    \n",
    "    geo_mean = np.sqrt(tp*(1-fp))\n",
    "    ind = np.argmax(geo_mean)\n",
    "    plt.plot(fp*100, tp*100, linewidth=2, **kwargs)\n",
    "    \n",
    "    plt.scatter(fp[ind]*100, tp[ind]*100, marker='*', s=200)\n",
    "\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.xlim([-5,100])\n",
    "    plt.ylim([0,105])\n",
    "    plt.grid(True)\n",
    "    \n",
    "    auc = sklearn.metrics.roc_auc_score(labels, predictions)\n",
    "    \n",
    "    \n",
    "    ax = plt.gca()\n",
    "\n",
    "    \n",
    "    return fp, tp, thres, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Graph and Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Weather_Data/complete_graph_data.json\") as user_file:\n",
    "    Node_Data_Dict = json.load(user_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Node_Data = []\n",
    "for key in list(Node_Data_Dict.keys()):\n",
    "    Node_Data.append(np.array(Node_Data_Dict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Node Data and Labels (Light Weather and 40kts Wind Speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_data = []\n",
    "Sum_Closed = 0\n",
    "Sum_Open = 0\n",
    "\n",
    "Max_Times = len(Node_Data)\n",
    "max_ahead = 5\n",
    "\n",
    "Predict_Times = Max_Times - max_ahead\n",
    "\n",
    "n_nodes, num_features = Node_Data[0].shape\n",
    "\n",
    "for k in range(Predict_Times):\n",
    "\n",
    "    labels = np.zeros((n_nodes, max_ahead))\n",
    "    for ahead in range(max_ahead):\n",
    "        labels[:, ahead] = Node_Data[k+1+ahead][:,0]\n",
    "        \n",
    "    Y_data.append(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjacent Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Truth_Graph_List = []\n",
    "Wind_Projected_Data_Org = {}\n",
    "Wind_Projected_Data_New = {}\n",
    "East_Wind = {}\n",
    "North_Wind = {}\n",
    "\n",
    "Used_Node_Data = deepcopy(Node_Data)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(np.concatenate(Used_Node_Data))\n",
    "for k in range(Predict_Times):\n",
    "    Used_Node_Data[k] = scaler.transform(Used_Node_Data[k])\n",
    "    \n",
    "        \n",
    "for ahead in range(max_ahead):\n",
    "\n",
    "    adj_list = []\n",
    "    for k in range(Predict_Times):\n",
    "        adj, org_lon_lat, new_lon_lat, east_winds, north_winds = return_adj(Node_Data[k], ahead+1)\n",
    "        Wind_Projected_Data_Org[(k,ahead)] = org_lon_lat\n",
    "        Wind_Projected_Data_New[(k,ahead)] = new_lon_lat\n",
    "        East_Wind[(k,ahead)] = east_winds\n",
    "        North_Wind[(k,ahead)] = north_winds\n",
    "        adj_list.append(adj)\n",
    "\n",
    "    Graph_List = []\n",
    "    for k in range(Predict_Times):\n",
    "        Graph_List.append(Graph(x = Used_Node_Data[k], a=adj_list[k], y = Y_data[k][:,ahead].reshape(-1,1)))\n",
    "        \n",
    "    Truth_Graph_List.append(Graph_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 8)            0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " gcn_conv (GCNConv)             (None, 64)           576         ['dropout[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['gcn_conv[0][0]']               \n",
      "                                                                                                  \n",
      " gcn_conv_1 (GCNConv)           (None, 64)           4160        ['dropout_1[0][0]',              \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64)           0           ['gcn_conv_1[0][0]']             \n",
      "                                                                                                  \n",
      " gcn_conv_4 (GCNConv)           (None, 1)            65          ['dropout_2[0][0]',              \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,801\n",
      "Trainable params: 4,801\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcdon\\anaconda3\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6956 - auc: 0.2128 - acc: 0.5731WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6956 - auc: 0.2128 - acc: 0.5731 - val_loss: 0.5027 - val_auc: 0.6105 - val_acc: 0.9254\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 0.5441 - auc: 0.6065 - acc: 0.8244 - val_loss: 0.3885 - val_auc: 0.7236 - val_acc: 0.9238\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.4451 - auc: 0.7851 - acc: 0.8316 - val_loss: 0.3058 - val_auc: 0.7462 - val_acc: 0.9273\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.3750 - auc: 0.8450 - acc: 0.8537 - val_loss: 0.2543 - val_auc: 0.7643 - val_acc: 0.9303\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.3258 - auc: 0.8728 - acc: 0.8799 - val_loss: 0.2289 - val_auc: 0.7740 - val_acc: 0.9342\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.2921 - auc: 0.8915 - acc: 0.8946 - val_loss: 0.2164 - val_auc: 0.7809 - val_acc: 0.9355\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2730 - auc: 0.9028 - acc: 0.9018 - val_loss: 0.2220 - val_auc: 0.7850 - val_acc: 0.9332\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.2672 - auc: 0.9093 - acc: 0.9032 - val_loss: 0.2193 - val_auc: 0.7970 - val_acc: 0.9345\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.2679 - auc: 0.9135 - acc: 0.9021 - val_loss: 0.2215 - val_auc: 0.8122 - val_acc: 0.9334\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.2703 - auc: 0.9161 - acc: 0.9036 - val_loss: 0.2245 - val_auc: 0.8043 - val_acc: 0.9346\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.2728 - auc: 0.9171 - acc: 0.9044 - val_loss: 0.2191 - val_auc: 0.8196 - val_acc: 0.9354\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 0.2706 - auc: 0.9196 - acc: 0.9060 - val_loss: 0.2134 - val_auc: 0.8209 - val_acc: 0.9364\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 1s 741ms/step - loss: 0.2682 - auc: 0.9206 - acc: 0.9064 - val_loss: 0.2066 - val_auc: 0.8310 - val_acc: 0.9376\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.2650 - auc: 0.9218 - acc: 0.9063 - val_loss: 0.2019 - val_auc: 0.8349 - val_acc: 0.9367\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.2591 - auc: 0.9242 - acc: 0.9059 - val_loss: 0.1891 - val_auc: 0.8460 - val_acc: 0.9382\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.2529 - auc: 0.9254 - acc: 0.9058 - val_loss: 0.1912 - val_auc: 0.8429 - val_acc: 0.9363\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.2471 - auc: 0.9261 - acc: 0.9059 - val_loss: 0.1814 - val_auc: 0.8571 - val_acc: 0.9379\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 0.2426 - auc: 0.9271 - acc: 0.9067 - val_loss: 0.1874 - val_auc: 0.8531 - val_acc: 0.9350\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 0.2410 - auc: 0.9279 - acc: 0.9065 - val_loss: 0.1790 - val_auc: 0.8612 - val_acc: 0.9402\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2409 - auc: 0.9288 - acc: 0.9062 - val_loss: 0.1915 - val_auc: 0.8608 - val_acc: 0.9365\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.2418 - auc: 0.9296 - acc: 0.9055 - val_loss: 0.1936 - val_auc: 0.8645 - val_acc: 0.9353\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.2447 - auc: 0.9279 - acc: 0.9065 - val_loss: 0.1884 - val_auc: 0.8672 - val_acc: 0.9379\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.2430 - auc: 0.9293 - acc: 0.9060 - val_loss: 0.1908 - val_auc: 0.8552 - val_acc: 0.9362\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.2421 - auc: 0.9290 - acc: 0.9069 - val_loss: 0.1742 - val_auc: 0.8679 - val_acc: 0.9420\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.2392 - auc: 0.9303 - acc: 0.9063 - val_loss: 0.1888 - val_auc: 0.8716 - val_acc: 0.9322\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.2384 - auc: 0.9294 - acc: 0.9068 - val_loss: 0.1716 - val_auc: 0.8627 - val_acc: 0.9408\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.2387 - auc: 0.9287 - acc: 0.9057 - val_loss: 0.1801 - val_auc: 0.8668 - val_acc: 0.9355\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.2371 - auc: 0.9300 - acc: 0.9072 - val_loss: 0.1818 - val_auc: 0.8705 - val_acc: 0.9337\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.2377 - auc: 0.9293 - acc: 0.9066 - val_loss: 0.1714 - val_auc: 0.8597 - val_acc: 0.9380\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2371 - auc: 0.9307 - acc: 0.9058 - val_loss: 0.1728 - val_auc: 0.8600 - val_acc: 0.9392\n",
      "Epoch 31/10000\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.2364 - auc: 0.9309 - acc: 0.9071 - val_loss: 0.1809 - val_auc: 0.8712 - val_acc: 0.9337\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.2353 - auc: 0.9316 - acc: 0.9073 - val_loss: 0.1787 - val_auc: 0.8620 - val_acc: 0.9360\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.2357 - auc: 0.9316 - acc: 0.9081 - val_loss: 0.1773 - val_auc: 0.8651 - val_acc: 0.9366\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.2349 - auc: 0.9322 - acc: 0.9080 - val_loss: 0.1776 - val_auc: 0.8690 - val_acc: 0.9350\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.2347 - auc: 0.9324 - acc: 0.9078 - val_loss: 0.1838 - val_auc: 0.8666 - val_acc: 0.9323\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.2342 - auc: 0.9323 - acc: 0.9078 - val_loss: 0.1674 - val_auc: 0.8612 - val_acc: 0.9418\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.2326 - auc: 0.9334 - acc: 0.9079 - val_loss: 0.1754 - val_auc: 0.8642 - val_acc: 0.9363\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.2346 - auc: 0.9318 - acc: 0.9073 - val_loss: 0.1729 - val_auc: 0.8685 - val_acc: 0.9391\n",
      "Epoch 39/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 565ms/step - loss: 0.2344 - auc: 0.9320 - acc: 0.9080 - val_loss: 0.1882 - val_auc: 0.8671 - val_acc: 0.9298\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.2319 - auc: 0.9332 - acc: 0.9089 - val_loss: 0.1671 - val_auc: 0.8623 - val_acc: 0.9414\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.2350 - auc: 0.9310 - acc: 0.9078 - val_loss: 0.1787 - val_auc: 0.8738 - val_acc: 0.9355\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.2330 - auc: 0.9327 - acc: 0.9077 - val_loss: 0.1707 - val_auc: 0.8702 - val_acc: 0.9393\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.2328 - auc: 0.9325 - acc: 0.9088 - val_loss: 0.1807 - val_auc: 0.8578 - val_acc: 0.9350\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 0.2332 - auc: 0.9322 - acc: 0.9078 - val_loss: 0.1678 - val_auc: 0.8733 - val_acc: 0.9406\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.2330 - auc: 0.9322 - acc: 0.9076 - val_loss: 0.1758 - val_auc: 0.8773 - val_acc: 0.9357\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.2313 - auc: 0.9336 - acc: 0.9082 - val_loss: 0.1730 - val_auc: 0.8713 - val_acc: 0.9376\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.2329 - auc: 0.9331 - acc: 0.9072 - val_loss: 0.1774 - val_auc: 0.8690 - val_acc: 0.9365\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.2321 - auc: 0.9330 - acc: 0.9079 - val_loss: 0.1772 - val_auc: 0.8775 - val_acc: 0.9347\n",
      "Epoch 49/10000\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 0.2326 - auc: 0.9327 - acc: 0.9079 - val_loss: 0.1749 - val_auc: 0.8747 - val_acc: 0.9368\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 0.2323 - auc: 0.9331 - acc: 0.9075 - val_loss: 0.1763 - val_auc: 0.8599 - val_acc: 0.9372\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.2311 - auc: 0.9337 - acc: 0.9082 - val_loss: 0.1721 - val_auc: 0.8763 - val_acc: 0.9372\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.2326 - auc: 0.9329 - acc: 0.9077 - val_loss: 0.1636 - val_auc: 0.8763 - val_acc: 0.9411\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.2316 - auc: 0.9331 - acc: 0.9073 - val_loss: 0.1884 - val_auc: 0.8688 - val_acc: 0.9293\n",
      "Epoch 54/10000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2324 - auc: 0.9327 - acc: 0.9080 - val_loss: 0.1716 - val_auc: 0.8726 - val_acc: 0.9386\n",
      "Epoch 55/10000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.2312 - auc: 0.9337 - acc: 0.9084 - val_loss: 0.1716 - val_auc: 0.8725 - val_acc: 0.9386\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.2304 - auc: 0.9350 - acc: 0.9077 - val_loss: 0.1739 - val_auc: 0.8645 - val_acc: 0.9376\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 0.2304 - auc: 0.9339 - acc: 0.9088 - val_loss: 0.1640 - val_auc: 0.8811 - val_acc: 0.9411\n",
      "Epoch 58/10000\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.2310 - auc: 0.9336 - acc: 0.9081 - val_loss: 0.1744 - val_auc: 0.8711 - val_acc: 0.9370\n",
      "Epoch 59/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2299 - auc: 0.9349 - acc: 0.9082 - val_loss: 0.1772 - val_auc: 0.8713 - val_acc: 0.9358\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.2311 - auc: 0.9343 - acc: 0.9076 - val_loss: 0.1757 - val_auc: 0.8782 - val_acc: 0.9365\n",
      "Epoch 61/10000\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.2298 - auc: 0.9346 - acc: 0.9082 - val_loss: 0.1790 - val_auc: 0.8695 - val_acc: 0.9344\n",
      "Epoch 62/10000\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.2305 - auc: 0.9342 - acc: 0.9090 - val_loss: 0.1602 - val_auc: 0.8764 - val_acc: 0.9441\n",
      "Epoch 63/10000\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.2296 - auc: 0.9351 - acc: 0.9086 - val_loss: 0.1760 - val_auc: 0.8713 - val_acc: 0.9362\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.2315 - auc: 0.9333 - acc: 0.9073 - val_loss: 0.1737 - val_auc: 0.8763 - val_acc: 0.9383\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.2296 - auc: 0.9349 - acc: 0.9083 - val_loss: 0.1792 - val_auc: 0.8734 - val_acc: 0.9344\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.2326 - auc: 0.9328 - acc: 0.9073 - val_loss: 0.1690 - val_auc: 0.8756 - val_acc: 0.9405\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.2307 - auc: 0.9342 - acc: 0.9090 - val_loss: 0.1752 - val_auc: 0.8777 - val_acc: 0.9365\n",
      "Epoch 68/10000\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.2305 - auc: 0.9340 - acc: 0.9082 - val_loss: 0.1855 - val_auc: 0.8672 - val_acc: 0.9324\n",
      "Epoch 69/10000\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.2306 - auc: 0.9345 - acc: 0.9077 - val_loss: 0.1581 - val_auc: 0.8785 - val_acc: 0.9435\n",
      "Epoch 70/10000\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.2304 - auc: 0.9346 - acc: 0.9072 - val_loss: 0.1797 - val_auc: 0.8720 - val_acc: 0.9345\n",
      "Epoch 71/10000\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2297 - auc: 0.9348 - acc: 0.9086 - val_loss: 0.1697 - val_auc: 0.8773 - val_acc: 0.9386\n",
      "Epoch 72/10000\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.2297 - auc: 0.9345 - acc: 0.9095 - val_loss: 0.1817 - val_auc: 0.8686 - val_acc: 0.9343\n",
      "Epoch 73/10000\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.2295 - auc: 0.9348 - acc: 0.9089 - val_loss: 0.1694 - val_auc: 0.8820 - val_acc: 0.9386\n",
      "Epoch 74/10000\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.2308 - auc: 0.9344 - acc: 0.9086 - val_loss: 0.1672 - val_auc: 0.8710 - val_acc: 0.9396\n",
      "Epoch 75/10000\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2320 - auc: 0.9326 - acc: 0.9083 - val_loss: 0.1798 - val_auc: 0.8820 - val_acc: 0.9337\n",
      "Epoch 76/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.2293 - auc: 0.9352 - acc: 0.9087 - val_loss: 0.1721 - val_auc: 0.8608 - val_acc: 0.9391\n",
      "Epoch 77/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2298 - auc: 0.9351 - acc: 0.9079 - val_loss: 0.1621 - val_auc: 0.8834 - val_acc: 0.9422\n",
      "Epoch 78/10000\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.2286 - auc: 0.9357 - acc: 0.9090 - val_loss: 0.1878 - val_auc: 0.8731 - val_acc: 0.9306\n",
      "Epoch 79/10000\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 0.2298 - auc: 0.9346 - acc: 0.9085 - val_loss: 0.1558 - val_auc: 0.8829 - val_acc: 0.9444\n",
      "Epoch 80/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.2298 - auc: 0.9345 - acc: 0.9093 - val_loss: 0.1730 - val_auc: 0.8618 - val_acc: 0.9391\n",
      "Epoch 81/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2297 - auc: 0.9345 - acc: 0.9089 - val_loss: 0.1814 - val_auc: 0.8869 - val_acc: 0.9322\n",
      "Epoch 82/10000\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.2296 - auc: 0.9348 - acc: 0.9077 - val_loss: 0.1635 - val_auc: 0.8700 - val_acc: 0.9428\n",
      "Epoch 83/10000\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.2292 - auc: 0.9349 - acc: 0.9084 - val_loss: 0.1780 - val_auc: 0.8818 - val_acc: 0.9348\n",
      "Epoch 84/10000\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.2282 - auc: 0.9361 - acc: 0.9086 - val_loss: 0.1810 - val_auc: 0.8739 - val_acc: 0.9333\n",
      "Epoch 85/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2280 - auc: 0.9359 - acc: 0.9090 - val_loss: 0.1574 - val_auc: 0.8737 - val_acc: 0.9438\n",
      "Epoch 86/10000\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.2290 - auc: 0.9354 - acc: 0.9095 - val_loss: 0.1845 - val_auc: 0.8721 - val_acc: 0.9322\n",
      "Epoch 87/10000\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2297 - auc: 0.9347 - acc: 0.9090 - val_loss: 0.1818 - val_auc: 0.8790 - val_acc: 0.9334\n",
      "Epoch 88/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 518ms/step - loss: 0.2294 - auc: 0.9349 - acc: 0.9089 - val_loss: 0.1682 - val_auc: 0.8815 - val_acc: 0.9391\n",
      "Epoch 89/10000\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.2288 - auc: 0.9356 - acc: 0.9083 - val_loss: 0.1735 - val_auc: 0.8707 - val_acc: 0.9378\n",
      "Epoch 90/10000\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.2277 - auc: 0.9359 - acc: 0.9095 - val_loss: 0.1625 - val_auc: 0.8751 - val_acc: 0.9421\n",
      "Epoch 91/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2291 - auc: 0.9351 - acc: 0.9089 - val_loss: 0.1701 - val_auc: 0.8861 - val_acc: 0.9376\n",
      "Epoch 92/10000\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.2300 - auc: 0.9346 - acc: 0.9085 - val_loss: 0.1751 - val_auc: 0.8792 - val_acc: 0.9357\n",
      "Epoch 93/10000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.2283 - auc: 0.9353 - acc: 0.9095 - val_loss: 0.1632 - val_auc: 0.8804 - val_acc: 0.9415\n",
      "Epoch 94/10000\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.2290 - auc: 0.9354 - acc: 0.9077 - val_loss: 0.1773 - val_auc: 0.8704 - val_acc: 0.9361\n",
      "Epoch 95/10000\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.2286 - auc: 0.9355 - acc: 0.9093 - val_loss: 0.1830 - val_auc: 0.8701 - val_acc: 0.9335\n",
      "Epoch 96/10000\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.2289 - auc: 0.9355 - acc: 0.9085 - val_loss: 0.1670 - val_auc: 0.8770 - val_acc: 0.9411\n",
      "Epoch 97/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2297 - auc: 0.9344 - acc: 0.9097 - val_loss: 0.1744 - val_auc: 0.8790 - val_acc: 0.9360\n",
      "Epoch 98/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2287 - auc: 0.9351 - acc: 0.9088 - val_loss: 0.1742 - val_auc: 0.8764 - val_acc: 0.9378\n",
      "Epoch 99/10000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2294 - auc: 0.9350 - acc: 0.9095 - val_loss: 0.1678 - val_auc: 0.8767 - val_acc: 0.9391\n",
      "Epoch 100/10000\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.2269 - auc: 0.9368 - acc: 0.9100 - val_loss: 0.1814 - val_auc: 0.8713 - val_acc: 0.9336\n",
      "Epoch 101/10000\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.2300 - auc: 0.9345 - acc: 0.9085 - val_loss: 0.1652 - val_auc: 0.8755 - val_acc: 0.9417\n",
      "Epoch 102/10000\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.2290 - auc: 0.9350 - acc: 0.9091 - val_loss: 0.1669 - val_auc: 0.8818 - val_acc: 0.9399\n",
      "Epoch 103/10000\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.2286 - auc: 0.9348 - acc: 0.9091 - val_loss: 0.1660 - val_auc: 0.8871 - val_acc: 0.9395\n",
      "Epoch 104/10000\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.2278 - auc: 0.9365 - acc: 0.9091 - val_loss: 0.1741 - val_auc: 0.8699 - val_acc: 0.9375\n",
      "Epoch 105/10000\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.2289 - auc: 0.9354 - acc: 0.9086 - val_loss: 0.1771 - val_auc: 0.8737 - val_acc: 0.9365\n",
      "Epoch 106/10000\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.2276 - auc: 0.9360 - acc: 0.9093 - val_loss: 0.1764 - val_auc: 0.8798 - val_acc: 0.9351\n",
      "Epoch 107/10000\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.2284 - auc: 0.9356 - acc: 0.9090 - val_loss: 0.1658 - val_auc: 0.8662 - val_acc: 0.9417\n",
      "Epoch 108/10000\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.2282 - auc: 0.9358 - acc: 0.9089 - val_loss: 0.1783 - val_auc: 0.8840 - val_acc: 0.9341\n",
      "Epoch 109/10000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.2288 - auc: 0.9351 - acc: 0.9095 - val_loss: 0.1601 - val_auc: 0.8799 - val_acc: 0.9435\n",
      "Epoch 110/10000\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.2276 - auc: 0.9361 - acc: 0.9094 - val_loss: 0.1775 - val_auc: 0.8754 - val_acc: 0.9360\n",
      "Epoch 111/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2281 - auc: 0.9358 - acc: 0.9091 - val_loss: 0.1768 - val_auc: 0.8692 - val_acc: 0.9362\n",
      "Epoch 112/10000\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.2283 - auc: 0.9354 - acc: 0.9094 - val_loss: 0.1756 - val_auc: 0.8794 - val_acc: 0.9367\n",
      "Epoch 113/10000\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.2273 - auc: 0.9364 - acc: 0.9096 - val_loss: 0.1653 - val_auc: 0.8830 - val_acc: 0.9406\n",
      "Epoch 114/10000\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.2291 - auc: 0.9352 - acc: 0.9087 - val_loss: 0.1729 - val_auc: 0.8770 - val_acc: 0.9371\n",
      "Epoch 115/10000\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2290 - auc: 0.9354 - acc: 0.9087 - val_loss: 0.1757 - val_auc: 0.8736 - val_acc: 0.9373\n",
      "Epoch 116/10000\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2262 - auc: 0.9372 - acc: 0.9096 - val_loss: 0.1684 - val_auc: 0.8783 - val_acc: 0.9404\n",
      "Epoch 117/10000\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 0.2271 - auc: 0.9366 - acc: 0.9086 - val_loss: 0.1716 - val_auc: 0.8772 - val_acc: 0.9362\n",
      "Epoch 118/10000\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.2273 - auc: 0.9363 - acc: 0.9102 - val_loss: 0.1747 - val_auc: 0.8758 - val_acc: 0.9380\n",
      "Epoch 119/10000\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 0.2284 - auc: 0.9355 - acc: 0.9087 - val_loss: 0.1804 - val_auc: 0.8782 - val_acc: 0.9335\n",
      "Epoch 120/10000\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.2273 - auc: 0.9361 - acc: 0.9094 - val_loss: 0.1657 - val_auc: 0.8729 - val_acc: 0.9426\n",
      "Epoch 121/10000\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 0.2268 - auc: 0.9368 - acc: 0.9095 - val_loss: 0.1669 - val_auc: 0.8908 - val_acc: 0.9391\n",
      "Epoch 122/10000\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.2284 - auc: 0.9356 - acc: 0.9091 - val_loss: 0.1741 - val_auc: 0.8720 - val_acc: 0.9375\n",
      "Epoch 123/10000\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 0.2279 - auc: 0.9362 - acc: 0.9089 - val_loss: 0.1656 - val_auc: 0.8796 - val_acc: 0.9411\n",
      "Epoch 124/10000\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.2272 - auc: 0.9370 - acc: 0.9087 - val_loss: 0.1734 - val_auc: 0.8660 - val_acc: 0.9387\n",
      "Epoch 125/10000\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.2257 - auc: 0.9375 - acc: 0.9096 - val_loss: 0.1731 - val_auc: 0.8869 - val_acc: 0.9351\n",
      "Epoch 126/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.2265 - auc: 0.9369 - acc: 0.9100 - val_loss: 0.1649 - val_auc: 0.8767 - val_acc: 0.9425\n",
      "Epoch 127/10000\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 0.2267 - auc: 0.9367 - acc: 0.9095 - val_loss: 0.1763 - val_auc: 0.8828 - val_acc: 0.9353\n",
      "Epoch 128/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2270 - auc: 0.9366 - acc: 0.9091 - val_loss: 0.1747 - val_auc: 0.8748 - val_acc: 0.9369\n",
      "Epoch 129/10000\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.2271 - auc: 0.9361 - acc: 0.9100 - val_loss: 0.1647 - val_auc: 0.8805 - val_acc: 0.9404\n",
      "Epoch 130/10000\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.2283 - auc: 0.9364 - acc: 0.9089 - val_loss: 0.1766 - val_auc: 0.8716 - val_acc: 0.9360\n",
      "Epoch 131/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2259 - auc: 0.9375 - acc: 0.9099 - val_loss: 0.1718 - val_auc: 0.8805 - val_acc: 0.9384\n",
      "Epoch 132/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.2277 - auc: 0.9361 - acc: 0.9094 - val_loss: 0.1727 - val_auc: 0.8824 - val_acc: 0.9360\n",
      "Epoch 133/10000\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.2281 - auc: 0.9358 - acc: 0.9094 - val_loss: 0.1660 - val_auc: 0.8770 - val_acc: 0.9419\n",
      "Epoch 134/10000\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.2277 - auc: 0.9358 - acc: 0.9087 - val_loss: 0.1597 - val_auc: 0.8911 - val_acc: 0.9426\n",
      "Epoch 135/10000\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.2269 - auc: 0.9370 - acc: 0.9091 - val_loss: 0.1808 - val_auc: 0.8771 - val_acc: 0.9339\n",
      "Epoch 136/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.2269 - auc: 0.9370 - acc: 0.9098 - val_loss: 0.1795 - val_auc: 0.8634 - val_acc: 0.9360\n",
      "Epoch 137/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 528ms/step - loss: 0.2269 - auc: 0.9369 - acc: 0.9086 - val_loss: 0.1546 - val_auc: 0.9000 - val_acc: 0.9431\n",
      "Epoch 138/10000\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.2267 - auc: 0.9371 - acc: 0.9104 - val_loss: 0.1812 - val_auc: 0.8710 - val_acc: 0.9349\n",
      "Epoch 139/10000\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.2265 - auc: 0.9368 - acc: 0.9101 - val_loss: 0.1691 - val_auc: 0.8873 - val_acc: 0.9385\n",
      "Epoch 140/10000\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.2266 - auc: 0.9366 - acc: 0.9090 - val_loss: 0.1639 - val_auc: 0.8827 - val_acc: 0.9409\n",
      "Epoch 141/10000\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 0.2263 - auc: 0.9368 - acc: 0.9092 - val_loss: 0.1710 - val_auc: 0.8730 - val_acc: 0.9395\n",
      "Epoch 142/10000\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.2266 - auc: 0.9369 - acc: 0.9094 - val_loss: 0.1727 - val_auc: 0.8810 - val_acc: 0.9375\n",
      "Epoch 143/10000\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.2259 - auc: 0.9372 - acc: 0.9095 - val_loss: 0.1622 - val_auc: 0.8883 - val_acc: 0.9421\n",
      "Epoch 144/10000\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.2263 - auc: 0.9374 - acc: 0.9099 - val_loss: 0.1810 - val_auc: 0.8677 - val_acc: 0.9340\n",
      "Epoch 145/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2262 - auc: 0.9368 - acc: 0.9097 - val_loss: 0.1625 - val_auc: 0.8989 - val_acc: 0.9408\n",
      "Epoch 146/10000\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.2266 - auc: 0.9370 - acc: 0.9091 - val_loss: 0.1727 - val_auc: 0.8678 - val_acc: 0.9396\n",
      "Epoch 147/10000\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.2274 - auc: 0.9365 - acc: 0.9086 - val_loss: 0.1600 - val_auc: 0.8847 - val_acc: 0.9425\n",
      "Epoch 148/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2260 - auc: 0.9373 - acc: 0.9093 - val_loss: 0.1861 - val_auc: 0.8761 - val_acc: 0.9320\n",
      "Epoch 149/10000\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.2263 - auc: 0.9368 - acc: 0.9098 - val_loss: 0.1724 - val_auc: 0.8843 - val_acc: 0.9365\n",
      "Epoch 150/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2261 - auc: 0.9376 - acc: 0.9094 - val_loss: 0.1621 - val_auc: 0.8762 - val_acc: 0.9431\n",
      "Epoch 151/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2263 - auc: 0.9369 - acc: 0.9094 - val_loss: 0.1732 - val_auc: 0.8881 - val_acc: 0.9357\n",
      "Epoch 152/10000\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.2273 - auc: 0.9360 - acc: 0.9096 - val_loss: 0.1574 - val_auc: 0.8724 - val_acc: 0.9456\n",
      "Epoch 153/10000\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.2259 - auc: 0.9374 - acc: 0.9098 - val_loss: 0.1903 - val_auc: 0.8791 - val_acc: 0.9297\n",
      "Epoch 154/10000\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.2268 - auc: 0.9369 - acc: 0.9091 - val_loss: 0.1549 - val_auc: 0.8871 - val_acc: 0.9454\n",
      "Epoch 155/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2251 - auc: 0.9382 - acc: 0.9102 - val_loss: 0.1654 - val_auc: 0.8729 - val_acc: 0.9411\n",
      "Epoch 156/10000\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.2267 - auc: 0.9369 - acc: 0.9097 - val_loss: 0.1769 - val_auc: 0.8856 - val_acc: 0.9357\n",
      "Epoch 157/10000\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 0.2263 - auc: 0.9377 - acc: 0.9089 - val_loss: 0.1699 - val_auc: 0.8814 - val_acc: 0.9386\n",
      "Epoch 158/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2262 - auc: 0.9371 - acc: 0.9102 - val_loss: 0.1608 - val_auc: 0.8865 - val_acc: 0.9426\n",
      "Epoch 159/10000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2263 - auc: 0.9372 - acc: 0.9099 - val_loss: 0.1738 - val_auc: 0.8722 - val_acc: 0.9382\n",
      "Epoch 160/10000\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.2261 - auc: 0.9371 - acc: 0.9093 - val_loss: 0.1781 - val_auc: 0.8837 - val_acc: 0.9350\n",
      "Epoch 161/10000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.2260 - auc: 0.9371 - acc: 0.9099 - val_loss: 0.1696 - val_auc: 0.8824 - val_acc: 0.9381\n",
      "Epoch 162/10000\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.2249 - auc: 0.9379 - acc: 0.9098 - val_loss: 0.1710 - val_auc: 0.8809 - val_acc: 0.9393\n",
      "Epoch 163/10000\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.2243 - auc: 0.9384 - acc: 0.9105 - val_loss: 0.1739 - val_auc: 0.8837 - val_acc: 0.9369\n",
      "Epoch 164/10000\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.2248 - auc: 0.9379 - acc: 0.9097 - val_loss: 0.1614 - val_auc: 0.8862 - val_acc: 0.9419\n",
      "Epoch 165/10000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.2252 - auc: 0.9379 - acc: 0.9101 - val_loss: 0.1744 - val_auc: 0.8761 - val_acc: 0.9365\n",
      "Epoch 166/10000\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.2259 - auc: 0.9375 - acc: 0.9097 - val_loss: 0.1689 - val_auc: 0.8840 - val_acc: 0.9397\n",
      "Epoch 167/10000\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.2262 - auc: 0.9370 - acc: 0.9096 - val_loss: 0.1615 - val_auc: 0.8882 - val_acc: 0.9417\n",
      "Epoch 168/10000\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2261 - auc: 0.9375 - acc: 0.9098 - val_loss: 0.1724 - val_auc: 0.8798 - val_acc: 0.9385\n",
      "Epoch 169/10000\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.2256 - auc: 0.9373 - acc: 0.9101 - val_loss: 0.1713 - val_auc: 0.8777 - val_acc: 0.9387\n",
      "Epoch 170/10000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.2255 - auc: 0.9373 - acc: 0.9102 - val_loss: 0.1738 - val_auc: 0.8883 - val_acc: 0.9371\n",
      "Epoch 171/10000\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.2261 - auc: 0.9371 - acc: 0.9095 - val_loss: 0.1708 - val_auc: 0.8803 - val_acc: 0.9382\n",
      "Epoch 172/10000\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.2259 - auc: 0.9373 - acc: 0.9097 - val_loss: 0.1717 - val_auc: 0.8843 - val_acc: 0.9378\n",
      "Epoch 173/10000\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.2243 - auc: 0.9380 - acc: 0.9108 - val_loss: 0.1655 - val_auc: 0.8808 - val_acc: 0.9413\n",
      "Epoch 174/10000\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.2254 - auc: 0.9374 - acc: 0.9101 - val_loss: 0.1630 - val_auc: 0.8832 - val_acc: 0.9415\n",
      "Epoch 175/10000\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.2248 - auc: 0.9380 - acc: 0.9107 - val_loss: 0.1645 - val_auc: 0.8878 - val_acc: 0.9414\n",
      "Epoch 176/10000\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.2242 - auc: 0.9386 - acc: 0.9096 - val_loss: 0.1748 - val_auc: 0.8826 - val_acc: 0.9372\n",
      "Epoch 177/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2251 - auc: 0.9378 - acc: 0.9102 - val_loss: 0.1714 - val_auc: 0.8739 - val_acc: 0.9388\n",
      "Epoch 178/10000\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.2262 - auc: 0.9371 - acc: 0.9092 - val_loss: 0.1679 - val_auc: 0.8879 - val_acc: 0.9392\n",
      "Epoch 179/10000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.2237 - auc: 0.9382 - acc: 0.9109 - val_loss: 0.1674 - val_auc: 0.8858 - val_acc: 0.9398\n",
      "Epoch 180/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2256 - auc: 0.9373 - acc: 0.9099 - val_loss: 0.1597 - val_auc: 0.8865 - val_acc: 0.9423\n",
      "Epoch 181/10000\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.2249 - auc: 0.9379 - acc: 0.9097 - val_loss: 0.1813 - val_auc: 0.8786 - val_acc: 0.9341\n",
      "Epoch 182/10000\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.2247 - auc: 0.9380 - acc: 0.9102 - val_loss: 0.1557 - val_auc: 0.8830 - val_acc: 0.9456\n",
      "Epoch 183/10000\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.2235 - auc: 0.9388 - acc: 0.9108 - val_loss: 0.1770 - val_auc: 0.8789 - val_acc: 0.9360\n",
      "Epoch 184/10000\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.2257 - auc: 0.9372 - acc: 0.9102 - val_loss: 0.1714 - val_auc: 0.8891 - val_acc: 0.9371\n",
      "Epoch 185/10000\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.2246 - auc: 0.9385 - acc: 0.9098 - val_loss: 0.1641 - val_auc: 0.8870 - val_acc: 0.9416\n",
      "Epoch 186/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 490ms/step - loss: 0.2246 - auc: 0.9380 - acc: 0.9108 - val_loss: 0.1666 - val_auc: 0.8867 - val_acc: 0.9402\n",
      "Epoch 187/10000\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.2239 - auc: 0.9389 - acc: 0.9107 - val_loss: 0.1658 - val_auc: 0.8848 - val_acc: 0.9405\n",
      "Epoch 188/10000\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.2241 - auc: 0.9384 - acc: 0.9100 - val_loss: 0.1718 - val_auc: 0.8792 - val_acc: 0.9385\n",
      "Epoch 189/10000\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.2247 - auc: 0.9375 - acc: 0.9108 - val_loss: 0.1768 - val_auc: 0.8810 - val_acc: 0.9358\n",
      "Epoch 190/10000\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.2231 - auc: 0.9394 - acc: 0.9107 - val_loss: 0.1616 - val_auc: 0.8862 - val_acc: 0.9431\n",
      "Epoch 191/10000\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.2240 - auc: 0.9379 - acc: 0.9106 - val_loss: 0.1745 - val_auc: 0.8805 - val_acc: 0.9369\n",
      "Epoch 192/10000\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.2249 - auc: 0.9382 - acc: 0.9100 - val_loss: 0.1643 - val_auc: 0.8797 - val_acc: 0.9414\n",
      "Epoch 193/10000\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.2248 - auc: 0.9377 - acc: 0.9096 - val_loss: 0.1676 - val_auc: 0.8865 - val_acc: 0.9395\n",
      "Epoch 194/10000\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.2245 - auc: 0.9385 - acc: 0.9095 - val_loss: 0.1696 - val_auc: 0.8834 - val_acc: 0.9388\n",
      "Epoch 195/10000\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.2246 - auc: 0.9380 - acc: 0.9101 - val_loss: 0.1702 - val_auc: 0.8839 - val_acc: 0.9387\n",
      "Epoch 196/10000\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.2256 - auc: 0.9372 - acc: 0.9092 - val_loss: 0.1699 - val_auc: 0.8845 - val_acc: 0.9388\n",
      "Epoch 197/10000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.2242 - auc: 0.9381 - acc: 0.9096 - val_loss: 0.1630 - val_auc: 0.8850 - val_acc: 0.9416\n",
      "Epoch 198/10000\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.2242 - auc: 0.9385 - acc: 0.9103 - val_loss: 0.1645 - val_auc: 0.8829 - val_acc: 0.9413\n",
      "Epoch 199/10000\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.2247 - auc: 0.9383 - acc: 0.9107 - val_loss: 0.1690 - val_auc: 0.8826 - val_acc: 0.9396\n",
      "Epoch 200/10000\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.2246 - auc: 0.9382 - acc: 0.9097 - val_loss: 0.1701 - val_auc: 0.8867 - val_acc: 0.9384\n",
      "Epoch 201/10000\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.2243 - auc: 0.9382 - acc: 0.9106 - val_loss: 0.1624 - val_auc: 0.8833 - val_acc: 0.9420\n",
      "Epoch 202/10000\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.2249 - auc: 0.9383 - acc: 0.9098 - val_loss: 0.1730 - val_auc: 0.8844 - val_acc: 0.9373\n",
      "Epoch 203/10000\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.2247 - auc: 0.9377 - acc: 0.9098 - val_loss: 0.1680 - val_auc: 0.8853 - val_acc: 0.9397\n",
      "Epoch 204/10000\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.2252 - auc: 0.9375 - acc: 0.9099 - val_loss: 0.1668 - val_auc: 0.8867 - val_acc: 0.9402\n",
      "Epoch 205/10000\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.2244 - auc: 0.9382 - acc: 0.9105 - val_loss: 0.1685 - val_auc: 0.8847 - val_acc: 0.9397\n",
      "Epoch 206/10000\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.2241 - auc: 0.9383 - acc: 0.9103 - val_loss: 0.1668 - val_auc: 0.8881 - val_acc: 0.9403\n",
      "Epoch 207/10000\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.2235 - auc: 0.9389 - acc: 0.9101 - val_loss: 0.1683 - val_auc: 0.8846 - val_acc: 0.9399\n",
      "Epoch 208/10000\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.2246 - auc: 0.9381 - acc: 0.9098 - val_loss: 0.1701 - val_auc: 0.8842 - val_acc: 0.9393\n",
      "Epoch 209/10000\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.2246 - auc: 0.9381 - acc: 0.9105 - val_loss: 0.1675 - val_auc: 0.8839 - val_acc: 0.9402\n",
      "Epoch 210/10000\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.2240 - auc: 0.9389 - acc: 0.9108 - val_loss: 0.1701 - val_auc: 0.8855 - val_acc: 0.9389\n",
      "Epoch 211/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2238 - auc: 0.9383 - acc: 0.9109 - val_loss: 0.1701 - val_auc: 0.8851 - val_acc: 0.9385\n",
      "Epoch 212/10000\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.2225 - auc: 0.9398 - acc: 0.9100 - val_loss: 0.1679 - val_auc: 0.8852 - val_acc: 0.9406\n",
      "Epoch 213/10000\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.2239 - auc: 0.9388 - acc: 0.9103 - val_loss: 0.1662 - val_auc: 0.8837 - val_acc: 0.9408\n",
      "Epoch 214/10000\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.2241 - auc: 0.9383 - acc: 0.9098 - val_loss: 0.1670 - val_auc: 0.8873 - val_acc: 0.9404\n",
      "Epoch 215/10000\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.2223 - auc: 0.9400 - acc: 0.9106 - val_loss: 0.1671 - val_auc: 0.8845 - val_acc: 0.9400\n",
      "Epoch 216/10000\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.2233 - auc: 0.9397 - acc: 0.9098 - val_loss: 0.1669 - val_auc: 0.8857 - val_acc: 0.9403\n",
      "Epoch 217/10000\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.2237 - auc: 0.9390 - acc: 0.9101 - val_loss: 0.1732 - val_auc: 0.8832 - val_acc: 0.9380\n",
      "Epoch 218/10000\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.2238 - auc: 0.9391 - acc: 0.9099 - val_loss: 0.1657 - val_auc: 0.8781 - val_acc: 0.9411\n",
      "Epoch 219/10000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.2237 - auc: 0.9392 - acc: 0.9096 - val_loss: 0.1692 - val_auc: 0.8862 - val_acc: 0.9388\n",
      "Epoch 220/10000\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.2236 - auc: 0.9386 - acc: 0.9093 - val_loss: 0.1694 - val_auc: 0.8828 - val_acc: 0.9398\n",
      "Epoch 221/10000\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.2253 - auc: 0.9377 - acc: 0.9095 - val_loss: 0.1667 - val_auc: 0.8827 - val_acc: 0.9406\n",
      "Epoch 222/10000\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.2229 - auc: 0.9395 - acc: 0.9102 - val_loss: 0.1654 - val_auc: 0.8887 - val_acc: 0.9402\n",
      "Epoch 223/10000\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.2240 - auc: 0.9387 - acc: 0.9101 - val_loss: 0.1731 - val_auc: 0.8797 - val_acc: 0.9382\n",
      "Epoch 224/10000\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.2240 - auc: 0.9386 - acc: 0.9103 - val_loss: 0.1628 - val_auc: 0.8941 - val_acc: 0.9412\n",
      "Epoch 225/10000\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.2229 - auc: 0.9392 - acc: 0.9101 - val_loss: 0.1691 - val_auc: 0.8839 - val_acc: 0.9389\n",
      "Epoch 226/10000\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.2241 - auc: 0.9385 - acc: 0.9096 - val_loss: 0.1710 - val_auc: 0.8863 - val_acc: 0.9386\n",
      "Epoch 227/10000\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.2240 - auc: 0.9385 - acc: 0.9100 - val_loss: 0.1628 - val_auc: 0.8794 - val_acc: 0.9430\n",
      "Epoch 228/10000\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2226 - auc: 0.9393 - acc: 0.9110 - val_loss: 0.1641 - val_auc: 0.8934 - val_acc: 0.9409\n",
      "Epoch 229/10000\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.2238 - auc: 0.9386 - acc: 0.9104 - val_loss: 0.1715 - val_auc: 0.8819 - val_acc: 0.9388\n",
      "Epoch 230/10000\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.2233 - auc: 0.9394 - acc: 0.9107 - val_loss: 0.1694 - val_auc: 0.8862 - val_acc: 0.9388\n",
      "Epoch 231/10000\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.2230 - auc: 0.9391 - acc: 0.9109 - val_loss: 0.1570 - val_auc: 0.8875 - val_acc: 0.9443\n",
      "Epoch 232/10000\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.2235 - auc: 0.9393 - acc: 0.9106 - val_loss: 0.1765 - val_auc: 0.8842 - val_acc: 0.9349\n",
      "Epoch 233/10000\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.2230 - auc: 0.9390 - acc: 0.9104 - val_loss: 0.1634 - val_auc: 0.8882 - val_acc: 0.9423\n",
      "Epoch 234/10000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.2238 - auc: 0.9387 - acc: 0.9103 - val_loss: 0.1703 - val_auc: 0.8860 - val_acc: 0.9391\n",
      "Epoch 235/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 480ms/step - loss: 0.2235 - auc: 0.9392 - acc: 0.9104 - val_loss: 0.1682 - val_auc: 0.8867 - val_acc: 0.9403\n",
      "Epoch 236/10000\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.2232 - auc: 0.9392 - acc: 0.9109 - val_loss: 0.1803 - val_auc: 0.8786 - val_acc: 0.9346\n",
      "Epoch 237/10000\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.2232 - auc: 0.9388 - acc: 0.9106 - val_loss: 0.1539 - val_auc: 0.8921 - val_acc: 0.9460\n",
      "Epoch 238/10000\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.2240 - auc: 0.9393 - acc: 0.9102 - val_loss: 0.1767 - val_auc: 0.8800 - val_acc: 0.9365\n",
      "Epoch 239/10000\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2242 - auc: 0.9390 - acc: 0.9100 - val_loss: 0.1580 - val_auc: 0.8890 - val_acc: 0.9445\n",
      "Epoch 240/10000\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.2242 - auc: 0.9386 - acc: 0.9102 - val_loss: 0.1740 - val_auc: 0.8753 - val_acc: 0.9381\n",
      "Epoch 241/10000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2243 - auc: 0.9381 - acc: 0.9106 - val_loss: 0.1673 - val_auc: 0.8878 - val_acc: 0.9404\n",
      "Epoch 242/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.2231 - auc: 0.9387 - acc: 0.9108 - val_loss: 0.1610 - val_auc: 0.8871 - val_acc: 0.9420\n",
      "Epoch 243/10000\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 0.2234 - auc: 0.9388 - acc: 0.9099 - val_loss: 0.1704 - val_auc: 0.8946 - val_acc: 0.9376\n",
      "Epoch 244/10000\n",
      "1/1 [==============================] - 1s 738ms/step - loss: 0.2234 - auc: 0.9391 - acc: 0.9096 - val_loss: 0.1680 - val_auc: 0.8805 - val_acc: 0.9404\n",
      "Epoch 245/10000\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 0.2222 - auc: 0.9397 - acc: 0.9102 - val_loss: 0.1782 - val_auc: 0.8836 - val_acc: 0.9342\n",
      "Epoch 246/10000\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 0.2238 - auc: 0.9388 - acc: 0.9100 - val_loss: 0.1628 - val_auc: 0.8812 - val_acc: 0.9422\n",
      "Epoch 247/10000\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.2239 - auc: 0.9385 - acc: 0.9107 - val_loss: 0.1646 - val_auc: 0.8861 - val_acc: 0.9423\n",
      "Epoch 248/10000\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2231 - auc: 0.9396 - acc: 0.9105 - val_loss: 0.1790 - val_auc: 0.8845 - val_acc: 0.9339\n",
      "Epoch 249/10000\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.2230 - auc: 0.9394 - acc: 0.9100 - val_loss: 0.1437 - val_auc: 0.8794 - val_acc: 0.9514\n",
      "Epoch 250/10000\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2219 - auc: 0.9399 - acc: 0.9107 - val_loss: 0.1690 - val_auc: 0.8933 - val_acc: 0.9384\n",
      "Epoch 251/10000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2219 - auc: 0.9400 - acc: 0.9112 - val_loss: 0.1786 - val_auc: 0.8834 - val_acc: 0.9349\n",
      "Epoch 252/10000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2224 - auc: 0.9400 - acc: 0.9108 - val_loss: 0.1628 - val_auc: 0.8932 - val_acc: 0.9416\n",
      "Epoch 253/10000\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.2230 - auc: 0.9392 - acc: 0.9107 - val_loss: 0.1645 - val_auc: 0.8766 - val_acc: 0.9410\n",
      "Epoch 254/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2243 - auc: 0.9388 - acc: 0.9099 - val_loss: 0.1625 - val_auc: 0.8904 - val_acc: 0.9424\n",
      "Epoch 255/10000\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.2230 - auc: 0.9393 - acc: 0.9103 - val_loss: 0.1629 - val_auc: 0.8882 - val_acc: 0.9419\n",
      "Epoch 256/10000\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.2218 - auc: 0.9404 - acc: 0.9103 - val_loss: 0.1733 - val_auc: 0.8862 - val_acc: 0.9377\n",
      "Epoch 257/10000\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2231 - auc: 0.9395 - acc: 0.9105 - val_loss: 0.1743 - val_auc: 0.8813 - val_acc: 0.9361\n",
      "Epoch 258/10000\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.2230 - auc: 0.9392 - acc: 0.9112 - val_loss: 0.1589 - val_auc: 0.8879 - val_acc: 0.9442\n",
      "Epoch 259/10000\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.2228 - auc: 0.9394 - acc: 0.9105 - val_loss: 0.1720 - val_auc: 0.8924 - val_acc: 0.9369\n",
      "Epoch 260/10000\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.2235 - auc: 0.9387 - acc: 0.9112 - val_loss: 0.1639 - val_auc: 0.8802 - val_acc: 0.9423\n",
      "Epoch 261/10000\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.2226 - auc: 0.9397 - acc: 0.9105 - val_loss: 0.1679 - val_auc: 0.8926 - val_acc: 0.9383\n",
      "Epoch 262/10000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2225 - auc: 0.9399 - acc: 0.9111 - val_loss: 0.1713 - val_auc: 0.8851 - val_acc: 0.9384\n",
      "Epoch 263/10000\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2233 - auc: 0.9392 - acc: 0.9104 - val_loss: 0.1686 - val_auc: 0.8772 - val_acc: 0.9398\n",
      "Epoch 264/10000\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.2225 - auc: 0.9397 - acc: 0.9109 - val_loss: 0.1687 - val_auc: 0.8920 - val_acc: 0.9384\n",
      "Epoch 265/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.2223 - auc: 0.9396 - acc: 0.9107 - val_loss: 0.1607 - val_auc: 0.8870 - val_acc: 0.9427\n",
      "Epoch 266/10000\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.2230 - auc: 0.9390 - acc: 0.9111 - val_loss: 0.1754 - val_auc: 0.8793 - val_acc: 0.9372\n",
      "Epoch 267/10000\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2234 - auc: 0.9389 - acc: 0.9101 - val_loss: 0.1651 - val_auc: 0.8798 - val_acc: 0.9424\n",
      "Epoch 268/10000\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2229 - auc: 0.9394 - acc: 0.9108 - val_loss: 0.1675 - val_auc: 0.8906 - val_acc: 0.9383\n",
      "Epoch 269/10000\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2231 - auc: 0.9395 - acc: 0.9101 - val_loss: 0.1601 - val_auc: 0.8979 - val_acc: 0.9435\n",
      "Epoch 270/10000\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.2222 - auc: 0.9398 - acc: 0.9104 - val_loss: 0.1716 - val_auc: 0.8742 - val_acc: 0.9382\n",
      "Epoch 271/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.2229 - auc: 0.9393 - acc: 0.9107 - val_loss: 0.1727 - val_auc: 0.8938 - val_acc: 0.9356\n",
      "Epoch 272/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.2222 - auc: 0.9398 - acc: 0.9109 - val_loss: 0.1574 - val_auc: 0.8883 - val_acc: 0.9448\n",
      "Epoch 273/10000\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.2233 - auc: 0.9390 - acc: 0.9101 - val_loss: 0.1708 - val_auc: 0.8803 - val_acc: 0.9392\n",
      "Epoch 274/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.2238 - auc: 0.9391 - acc: 0.9102 - val_loss: 0.1624 - val_auc: 0.8924 - val_acc: 0.9404\n",
      "Epoch 275/10000\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.2230 - auc: 0.9397 - acc: 0.9104 - val_loss: 0.1668 - val_auc: 0.8827 - val_acc: 0.9411\n",
      "Epoch 276/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2234 - auc: 0.9393 - acc: 0.9099 - val_loss: 0.1705 - val_auc: 0.8844 - val_acc: 0.9390\n",
      "Epoch 277/10000\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.2232 - auc: 0.9392 - acc: 0.9104 - val_loss: 0.1610 - val_auc: 0.8910 - val_acc: 0.9414\n",
      "Epoch 278/10000\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.2216 - auc: 0.9401 - acc: 0.9110 - val_loss: 0.1754 - val_auc: 0.8813 - val_acc: 0.9371\n",
      "Epoch 279/10000\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.2218 - auc: 0.9399 - acc: 0.9108 - val_loss: 0.1693 - val_auc: 0.8766 - val_acc: 0.9397\n",
      "Epoch 280/10000\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.2226 - auc: 0.9393 - acc: 0.9113 - val_loss: 0.1595 - val_auc: 0.8936 - val_acc: 0.9413\n",
      "Epoch 281/10000\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.2220 - auc: 0.9399 - acc: 0.9105 - val_loss: 0.1731 - val_auc: 0.8954 - val_acc: 0.9369\n",
      "Epoch 282/10000\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.2216 - auc: 0.9402 - acc: 0.9112 - val_loss: 0.1539 - val_auc: 0.8809 - val_acc: 0.9468\n",
      "Epoch 283/10000\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.2218 - auc: 0.9401 - acc: 0.9111 - val_loss: 0.1613 - val_auc: 0.8885 - val_acc: 0.9421\n",
      "Epoch 284/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 487ms/step - loss: 0.2224 - auc: 0.9392 - acc: 0.9103 - val_loss: 0.1765 - val_auc: 0.8800 - val_acc: 0.9364\n",
      "Epoch 285/10000\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.2233 - auc: 0.9388 - acc: 0.9104 - val_loss: 0.1668 - val_auc: 0.8919 - val_acc: 0.9391\n",
      "Epoch 286/10000\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.2219 - auc: 0.9399 - acc: 0.9112 - val_loss: 0.1679 - val_auc: 0.8933 - val_acc: 0.9396\n",
      "Epoch 287/10000\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.2219 - auc: 0.9395 - acc: 0.9104 - val_loss: 0.1595 - val_auc: 0.8763 - val_acc: 0.9440\n",
      "Epoch 288/10000\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.2224 - auc: 0.9395 - acc: 0.9104 - val_loss: 0.1730 - val_auc: 0.8927 - val_acc: 0.9368\n",
      "Epoch 289/10000\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.2230 - auc: 0.9390 - acc: 0.9114 - val_loss: 0.1639 - val_auc: 0.8928 - val_acc: 0.9408\n",
      "Epoch 290/10000\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.2232 - auc: 0.9388 - acc: 0.9103 - val_loss: 0.1715 - val_auc: 0.8887 - val_acc: 0.9386\n",
      "Epoch 291/10000\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.2228 - auc: 0.9394 - acc: 0.9107 - val_loss: 0.1599 - val_auc: 0.8869 - val_acc: 0.9444\n",
      "Epoch 292/10000\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.2218 - auc: 0.9400 - acc: 0.9111 - val_loss: 0.1563 - val_auc: 0.8876 - val_acc: 0.9441\n",
      "Epoch 293/10000\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.2224 - auc: 0.9395 - acc: 0.9110 - val_loss: 0.1705 - val_auc: 0.8922 - val_acc: 0.9365\n",
      "Epoch 294/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2227 - auc: 0.9396 - acc: 0.9106 - val_loss: 0.1682 - val_auc: 0.8815 - val_acc: 0.9400\n",
      "Epoch 295/10000\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.2222 - auc: 0.9397 - acc: 0.9104 - val_loss: 0.1699 - val_auc: 0.8784 - val_acc: 0.9397\n",
      "Epoch 296/10000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2229 - auc: 0.9390 - acc: 0.9111 - val_loss: 0.1745 - val_auc: 0.8927 - val_acc: 0.9368\n",
      "Epoch 297/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2226 - auc: 0.9396 - acc: 0.9110 - val_loss: 0.1674 - val_auc: 0.8933 - val_acc: 0.9389\n",
      "Epoch 298/10000\n",
      "1/1 [==============================] - 1s 500ms/step - loss: 0.2224 - auc: 0.9395 - acc: 0.9105 - val_loss: 0.1527 - val_auc: 0.8842 - val_acc: 0.9460\n",
      "Epoch 299/10000\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.2228 - auc: 0.9397 - acc: 0.9110 - val_loss: 0.1747 - val_auc: 0.8905 - val_acc: 0.9358\n",
      "Epoch 300/10000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2218 - auc: 0.9402 - acc: 0.9107 - val_loss: 0.1709 - val_auc: 0.8858 - val_acc: 0.9393\n",
      "Epoch 301/10000\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.2210 - auc: 0.9407 - acc: 0.9111 - val_loss: 0.1629 - val_auc: 0.8903 - val_acc: 0.9407\n",
      "Epoch 302/10000\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.2216 - auc: 0.9403 - acc: 0.9106 - val_loss: 0.1589 - val_auc: 0.8786 - val_acc: 0.9452\n",
      "Epoch 303/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.2243 - auc: 0.9380 - acc: 0.9101 - val_loss: 0.1696 - val_auc: 0.8887 - val_acc: 0.9396\n",
      "Epoch 304/10000\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.2217 - auc: 0.9401 - acc: 0.9106 - val_loss: 0.1688 - val_auc: 0.8999 - val_acc: 0.9368\n",
      "Epoch 305/10000\n",
      "1/1 [==============================] - 1s 709ms/step - loss: 0.2230 - auc: 0.9393 - acc: 0.9103 - val_loss: 0.1716 - val_auc: 0.8757 - val_acc: 0.9384\n",
      "Epoch 306/10000\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.2209 - auc: 0.9408 - acc: 0.9106 - val_loss: 0.1670 - val_auc: 0.9010 - val_acc: 0.9380\n",
      "Epoch 307/10000\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.2211 - auc: 0.9409 - acc: 0.9106 - val_loss: 0.1576 - val_auc: 0.8882 - val_acc: 0.9441\n",
      "Epoch 308/10000\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 0.2211 - auc: 0.9407 - acc: 0.9104 - val_loss: 0.1729 - val_auc: 0.8805 - val_acc: 0.9370\n",
      "Epoch 309/10000\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.2225 - auc: 0.9395 - acc: 0.9109 - val_loss: 0.1599 - val_auc: 0.8926 - val_acc: 0.9421\n",
      "Epoch 310/10000\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.2212 - auc: 0.9405 - acc: 0.9111 - val_loss: 0.1752 - val_auc: 0.8812 - val_acc: 0.9375\n",
      "Epoch 311/10000\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.2205 - auc: 0.9407 - acc: 0.9108 - val_loss: 0.1562 - val_auc: 0.8901 - val_acc: 0.9442\n",
      "Epoch 312/10000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2206 - auc: 0.9404 - acc: 0.9120 - val_loss: 0.1629 - val_auc: 0.8913 - val_acc: 0.9425\n",
      "Epoch 313/10000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2216 - auc: 0.9402 - acc: 0.9104 - val_loss: 0.1780 - val_auc: 0.8949 - val_acc: 0.9334\n",
      "Epoch 314/10000\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.2213 - auc: 0.9400 - acc: 0.9119 - val_loss: 0.1581 - val_auc: 0.8815 - val_acc: 0.9445\n",
      "Epoch 315/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.2217 - auc: 0.9406 - acc: 0.9107 - val_loss: 0.1665 - val_auc: 0.8822 - val_acc: 0.9410\n",
      "Epoch 316/10000\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.2225 - auc: 0.9402 - acc: 0.9103 - val_loss: 0.1657 - val_auc: 0.8921 - val_acc: 0.9390\n",
      "Epoch 317/10000\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.2218 - auc: 0.9398 - acc: 0.9108 - val_loss: 0.1830 - val_auc: 0.8852 - val_acc: 0.9333\n",
      "Epoch 318/10000\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 0.2216 - auc: 0.9404 - acc: 0.9107 - val_loss: 0.1506 - val_auc: 0.9002 - val_acc: 0.9451\n",
      "Epoch 319/10000\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.2217 - auc: 0.9400 - acc: 0.9113 - val_loss: 0.1795 - val_auc: 0.8698 - val_acc: 0.9362\n",
      "Epoch 320/10000\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.2224 - auc: 0.9396 - acc: 0.9106 - val_loss: 0.1464 - val_auc: 0.9012 - val_acc: 0.9484\n",
      "Epoch 321/10000\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.2209 - auc: 0.9406 - acc: 0.9115 - val_loss: 0.1789 - val_auc: 0.8909 - val_acc: 0.9344\n",
      "Epoch 322/10000\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.2216 - auc: 0.9403 - acc: 0.9102 - val_loss: 0.1666 - val_auc: 0.8791 - val_acc: 0.9412\n",
      "Epoch 323/10000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.2210 - auc: 0.9407 - acc: 0.9105 - val_loss: 0.1623 - val_auc: 0.8990 - val_acc: 0.9406\n",
      "Epoch 324/10000\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.2220 - auc: 0.9399 - acc: 0.9103 - val_loss: 0.1638 - val_auc: 0.8903 - val_acc: 0.9410\n",
      "Epoch 325/10000\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.2211 - auc: 0.9404 - acc: 0.9105 - val_loss: 0.1710 - val_auc: 0.8888 - val_acc: 0.9379\n",
      "Epoch 326/10000\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.2202 - auc: 0.9411 - acc: 0.9104 - val_loss: 0.1691 - val_auc: 0.8902 - val_acc: 0.9385\n",
      "Epoch 327/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.2211 - auc: 0.9406 - acc: 0.9111 - val_loss: 0.1636 - val_auc: 0.8973 - val_acc: 0.9405\n",
      "Epoch 328/10000\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.2226 - auc: 0.9396 - acc: 0.9111 - val_loss: 0.1658 - val_auc: 0.8879 - val_acc: 0.9400\n",
      "Epoch 329/10000\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2218 - auc: 0.9403 - acc: 0.9104 - val_loss: 0.1597 - val_auc: 0.8903 - val_acc: 0.9414\n",
      "Epoch 330/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2206 - auc: 0.9405 - acc: 0.9117 - val_loss: 0.1623 - val_auc: 0.8892 - val_acc: 0.9419\n",
      "Epoch 331/10000\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.2222 - auc: 0.9401 - acc: 0.9108 - val_loss: 0.1700 - val_auc: 0.8898 - val_acc: 0.9383\n",
      "Epoch 332/10000\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.2227 - auc: 0.9399 - acc: 0.9104 - val_loss: 0.1762 - val_auc: 0.8831 - val_acc: 0.9359\n",
      "Epoch 333/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 542ms/step - loss: 0.2212 - auc: 0.9408 - acc: 0.9105 - val_loss: 0.1539 - val_auc: 0.8955 - val_acc: 0.9447\n",
      "Epoch 334/10000\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.2213 - auc: 0.9402 - acc: 0.9114 - val_loss: 0.1780 - val_auc: 0.8778 - val_acc: 0.9351\n",
      "Epoch 335/10000\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.2211 - auc: 0.9402 - acc: 0.9107 - val_loss: 0.1615 - val_auc: 0.8965 - val_acc: 0.9420\n",
      "Epoch 336/10000\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.2203 - auc: 0.9412 - acc: 0.9112 - val_loss: 0.1516 - val_auc: 0.8881 - val_acc: 0.9463\n",
      "Epoch 337/10000\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.2223 - auc: 0.9402 - acc: 0.9096 - val_loss: 0.1709 - val_auc: 0.8911 - val_acc: 0.9378\n",
      "Epoch 338/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.2217 - auc: 0.9404 - acc: 0.9108 - val_loss: 0.1710 - val_auc: 0.8916 - val_acc: 0.9366\n",
      "Epoch 339/10000\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.2215 - auc: 0.9405 - acc: 0.9110 - val_loss: 0.1696 - val_auc: 0.8889 - val_acc: 0.9389\n",
      "Epoch 340/10000\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.2206 - auc: 0.9405 - acc: 0.9117 - val_loss: 0.1663 - val_auc: 0.8917 - val_acc: 0.9402\n",
      "Epoch 341/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.2209 - auc: 0.9406 - acc: 0.9116 - val_loss: 0.1603 - val_auc: 0.8841 - val_acc: 0.9439\n",
      "Epoch 342/10000\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.2210 - auc: 0.9407 - acc: 0.9106 - val_loss: 0.1575 - val_auc: 0.8904 - val_acc: 0.9431\n",
      "Epoch 343/10000\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.2211 - auc: 0.9408 - acc: 0.9108 - val_loss: 0.1749 - val_auc: 0.8895 - val_acc: 0.9358\n",
      "Epoch 344/10000\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.2216 - auc: 0.9405 - acc: 0.9103 - val_loss: 0.1581 - val_auc: 0.8947 - val_acc: 0.9435\n",
      "Epoch 345/10000\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.2199 - auc: 0.9416 - acc: 0.9113 - val_loss: 0.1671 - val_auc: 0.8911 - val_acc: 0.9382\n",
      "Epoch 346/10000\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 0.2207 - auc: 0.9410 - acc: 0.9107 - val_loss: 0.1661 - val_auc: 0.8870 - val_acc: 0.9403\n",
      "Epoch 347/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.2211 - auc: 0.9406 - acc: 0.9107 - val_loss: 0.1633 - val_auc: 0.8940 - val_acc: 0.9413\n",
      "Epoch 348/10000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2202 - auc: 0.9411 - acc: 0.9120 - val_loss: 0.1727 - val_auc: 0.8925 - val_acc: 0.9361\n",
      "Epoch 349/10000\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.2219 - auc: 0.9399 - acc: 0.9110 - val_loss: 0.1655 - val_auc: 0.8891 - val_acc: 0.9399\n",
      "Evaluating model.\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2901 - auc: 0.8980 - acc: 0.8776\n",
      "Done.\n",
      "Test loss: 0.2900838553905487\n",
      "Test accuracy: 0.8979759216308594\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 8)            0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " gcn_conv_5 (GCNConv)           (None, 64)           576         ['dropout_5[0][0]',              \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 64)           0           ['gcn_conv_5[0][0]']             \n",
      "                                                                                                  \n",
      " gcn_conv_6 (GCNConv)           (None, 64)           4160        ['dropout_6[0][0]',              \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 64)           0           ['gcn_conv_6[0][0]']             \n",
      "                                                                                                  \n",
      " gcn_conv_9 (GCNConv)           (None, 1)            65          ['dropout_7[0][0]',              \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,801\n",
      "Trainable params: 4,801\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8074 - auc_1: 0.6964 - acc: 0.2037WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8074 - auc_1: 0.6964 - acc: 0.2037 - val_loss: 0.5602 - val_auc_1: 0.5654 - val_acc: 0.9247\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.6174 - auc_1: 0.4170 - acc: 0.8133 - val_loss: 0.4268 - val_auc_1: 0.6047 - val_acc: 0.9256\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.5222 - auc_1: 0.5361 - acc: 0.8232 - val_loss: 0.3440 - val_auc_1: 0.6766 - val_acc: 0.9233\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.4502 - auc_1: 0.7086 - acc: 0.8245 - val_loss: 0.2854 - val_auc_1: 0.7084 - val_acc: 0.9262\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.3903 - auc_1: 0.7994 - acc: 0.8378 - val_loss: 0.2549 - val_auc_1: 0.7231 - val_acc: 0.9260\n",
      "Epoch 6/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 573ms/step - loss: 0.3445 - auc_1: 0.8397 - acc: 0.8666 - val_loss: 0.2439 - val_auc_1: 0.7393 - val_acc: 0.9238\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.3152 - auc_1: 0.8628 - acc: 0.8814 - val_loss: 0.2395 - val_auc_1: 0.7345 - val_acc: 0.9242\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 0.3038 - auc_1: 0.8772 - acc: 0.8848 - val_loss: 0.2450 - val_auc_1: 0.7353 - val_acc: 0.9217\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.3072 - auc_1: 0.8834 - acc: 0.8848 - val_loss: 0.2460 - val_auc_1: 0.7421 - val_acc: 0.9231\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 0.3146 - auc_1: 0.8859 - acc: 0.8845 - val_loss: 0.2502 - val_auc_1: 0.7418 - val_acc: 0.9228\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 0.3177 - auc_1: 0.8901 - acc: 0.8821 - val_loss: 0.2560 - val_auc_1: 0.7460 - val_acc: 0.9219\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.3156 - auc_1: 0.8924 - acc: 0.8846 - val_loss: 0.2758 - val_auc_1: 0.7356 - val_acc: 0.9165\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.3136 - auc_1: 0.8923 - acc: 0.8858 - val_loss: 0.2456 - val_auc_1: 0.7501 - val_acc: 0.9251\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 0.3083 - auc_1: 0.8939 - acc: 0.8858 - val_loss: 0.2403 - val_auc_1: 0.7494 - val_acc: 0.9253\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3041 - auc_1: 0.8948 - acc: 0.8861 - val_loss: 0.2486 - val_auc_1: 0.7442 - val_acc: 0.9232\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2993 - auc_1: 0.8956 - acc: 0.8863 - val_loss: 0.2374 - val_auc_1: 0.7507 - val_acc: 0.9267\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2962 - auc_1: 0.8959 - acc: 0.8857 - val_loss: 0.2365 - val_auc_1: 0.7597 - val_acc: 0.9242\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 0.2897 - auc_1: 0.8980 - acc: 0.8863 - val_loss: 0.2293 - val_auc_1: 0.7518 - val_acc: 0.9279\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 0.2860 - auc_1: 0.8992 - acc: 0.8870 - val_loss: 0.2318 - val_auc_1: 0.7683 - val_acc: 0.9236\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.2853 - auc_1: 0.8989 - acc: 0.8859 - val_loss: 0.2317 - val_auc_1: 0.7659 - val_acc: 0.9238\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.2852 - auc_1: 0.8987 - acc: 0.8863 - val_loss: 0.2409 - val_auc_1: 0.7648 - val_acc: 0.9214\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 0.2840 - auc_1: 0.9000 - acc: 0.8864 - val_loss: 0.2267 - val_auc_1: 0.7772 - val_acc: 0.9284\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 0.2849 - auc_1: 0.9009 - acc: 0.8870 - val_loss: 0.2294 - val_auc_1: 0.7808 - val_acc: 0.9277\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.2847 - auc_1: 0.9016 - acc: 0.8864 - val_loss: 0.2463 - val_auc_1: 0.7800 - val_acc: 0.9184\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.2857 - auc_1: 0.9011 - acc: 0.8858 - val_loss: 0.2331 - val_auc_1: 0.7926 - val_acc: 0.9242\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.2832 - auc_1: 0.9028 - acc: 0.8870 - val_loss: 0.2292 - val_auc_1: 0.7833 - val_acc: 0.9256\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.2827 - auc_1: 0.9024 - acc: 0.8865 - val_loss: 0.2241 - val_auc_1: 0.7894 - val_acc: 0.9247\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 0.2793 - auc_1: 0.9042 - acc: 0.8872 - val_loss: 0.2284 - val_auc_1: 0.7888 - val_acc: 0.9206\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.2792 - auc_1: 0.9027 - acc: 0.8859 - val_loss: 0.2210 - val_auc_1: 0.7976 - val_acc: 0.9218\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 0.2779 - auc_1: 0.9036 - acc: 0.8863 - val_loss: 0.2127 - val_auc_1: 0.7949 - val_acc: 0.9247\n",
      "Epoch 31/10000\n",
      "1/1 [==============================] - 1s 721ms/step - loss: 0.2763 - auc_1: 0.9045 - acc: 0.8873 - val_loss: 0.2170 - val_auc_1: 0.7896 - val_acc: 0.9245\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.2776 - auc_1: 0.9037 - acc: 0.8870 - val_loss: 0.2174 - val_auc_1: 0.7863 - val_acc: 0.9233\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.2776 - auc_1: 0.9045 - acc: 0.8859 - val_loss: 0.2109 - val_auc_1: 0.8085 - val_acc: 0.9247\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.2789 - auc_1: 0.9031 - acc: 0.8861 - val_loss: 0.2041 - val_auc_1: 0.7976 - val_acc: 0.9285\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.2764 - auc_1: 0.9045 - acc: 0.8874 - val_loss: 0.2261 - val_auc_1: 0.7950 - val_acc: 0.9183\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.2777 - auc_1: 0.9035 - acc: 0.8871 - val_loss: 0.2094 - val_auc_1: 0.7972 - val_acc: 0.9259\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.2765 - auc_1: 0.9051 - acc: 0.8872 - val_loss: 0.2293 - val_auc_1: 0.7972 - val_acc: 0.9156\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.2747 - auc_1: 0.9061 - acc: 0.8873 - val_loss: 0.2170 - val_auc_1: 0.7937 - val_acc: 0.9243\n",
      "Epoch 39/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.2764 - auc_1: 0.9047 - acc: 0.8869 - val_loss: 0.2110 - val_auc_1: 0.8069 - val_acc: 0.9251\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.2758 - auc_1: 0.9053 - acc: 0.8877 - val_loss: 0.2173 - val_auc_1: 0.7844 - val_acc: 0.9253\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.2761 - auc_1: 0.9052 - acc: 0.8866 - val_loss: 0.2172 - val_auc_1: 0.8115 - val_acc: 0.9218\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 0.2747 - auc_1: 0.9060 - acc: 0.8885 - val_loss: 0.2332 - val_auc_1: 0.7880 - val_acc: 0.9153\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.2759 - auc_1: 0.9048 - acc: 0.8875 - val_loss: 0.2119 - val_auc_1: 0.7965 - val_acc: 0.9262\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 0.2763 - auc_1: 0.9050 - acc: 0.8862 - val_loss: 0.2124 - val_auc_1: 0.7984 - val_acc: 0.9260\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.2740 - auc_1: 0.9064 - acc: 0.8874 - val_loss: 0.2111 - val_auc_1: 0.8047 - val_acc: 0.9249\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.2743 - auc_1: 0.9056 - acc: 0.8873 - val_loss: 0.2280 - val_auc_1: 0.7861 - val_acc: 0.9197\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2733 - auc_1: 0.9068 - acc: 0.8887 - val_loss: 0.2034 - val_auc_1: 0.8110 - val_acc: 0.9281\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.2748 - auc_1: 0.9057 - acc: 0.8873 - val_loss: 0.2234 - val_auc_1: 0.8013 - val_acc: 0.9198\n",
      "Epoch 49/10000\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.2735 - auc_1: 0.9071 - acc: 0.8868 - val_loss: 0.2030 - val_auc_1: 0.8051 - val_acc: 0.9275\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.2731 - auc_1: 0.9068 - acc: 0.8881 - val_loss: 0.2221 - val_auc_1: 0.7971 - val_acc: 0.9214\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.2740 - auc_1: 0.9063 - acc: 0.8871 - val_loss: 0.1990 - val_auc_1: 0.8101 - val_acc: 0.9292\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.2726 - auc_1: 0.9072 - acc: 0.8889 - val_loss: 0.2274 - val_auc_1: 0.7890 - val_acc: 0.9196\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.2732 - auc_1: 0.9069 - acc: 0.8883 - val_loss: 0.2133 - val_auc_1: 0.8123 - val_acc: 0.9215\n",
      "Epoch 54/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 474ms/step - loss: 0.2720 - auc_1: 0.9076 - acc: 0.8876 - val_loss: 0.2084 - val_auc_1: 0.8034 - val_acc: 0.9267\n",
      "Epoch 55/10000\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.2725 - auc_1: 0.9074 - acc: 0.8882 - val_loss: 0.2062 - val_auc_1: 0.8131 - val_acc: 0.9244\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.2735 - auc_1: 0.9063 - acc: 0.8876 - val_loss: 0.2156 - val_auc_1: 0.7927 - val_acc: 0.9231\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.2721 - auc_1: 0.9075 - acc: 0.8874 - val_loss: 0.2204 - val_auc_1: 0.8140 - val_acc: 0.9195\n",
      "Epoch 58/10000\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.2724 - auc_1: 0.9075 - acc: 0.8886 - val_loss: 0.2148 - val_auc_1: 0.7989 - val_acc: 0.9227\n",
      "Epoch 59/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2728 - auc_1: 0.9072 - acc: 0.8874 - val_loss: 0.2074 - val_auc_1: 0.8171 - val_acc: 0.9229\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.2724 - auc_1: 0.9078 - acc: 0.8865 - val_loss: 0.2148 - val_auc_1: 0.7985 - val_acc: 0.9227\n",
      "Epoch 61/10000\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.2715 - auc_1: 0.9081 - acc: 0.8878 - val_loss: 0.2164 - val_auc_1: 0.8137 - val_acc: 0.9211\n",
      "Epoch 62/10000\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.2718 - auc_1: 0.9079 - acc: 0.8874 - val_loss: 0.2236 - val_auc_1: 0.8129 - val_acc: 0.9149\n",
      "Epoch 63/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2717 - auc_1: 0.9078 - acc: 0.8875 - val_loss: 0.2069 - val_auc_1: 0.7984 - val_acc: 0.9280\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.2713 - auc_1: 0.9079 - acc: 0.8886 - val_loss: 0.2038 - val_auc_1: 0.8091 - val_acc: 0.9267\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 0.2717 - auc_1: 0.9074 - acc: 0.8885 - val_loss: 0.2181 - val_auc_1: 0.8220 - val_acc: 0.9179\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 0.2715 - auc_1: 0.9074 - acc: 0.8888 - val_loss: 0.2022 - val_auc_1: 0.8098 - val_acc: 0.9273\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.2714 - auc_1: 0.9081 - acc: 0.8870 - val_loss: 0.2105 - val_auc_1: 0.8145 - val_acc: 0.9218\n",
      "Epoch 68/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.2716 - auc_1: 0.9080 - acc: 0.8883 - val_loss: 0.2273 - val_auc_1: 0.7908 - val_acc: 0.9173\n",
      "Epoch 69/10000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.2719 - auc_1: 0.9073 - acc: 0.8878 - val_loss: 0.2089 - val_auc_1: 0.8185 - val_acc: 0.9232\n",
      "Epoch 70/10000\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 0.2718 - auc_1: 0.9077 - acc: 0.8879 - val_loss: 0.2056 - val_auc_1: 0.8192 - val_acc: 0.9257\n",
      "Epoch 71/10000\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 0.2709 - auc_1: 0.9084 - acc: 0.8891 - val_loss: 0.2052 - val_auc_1: 0.8047 - val_acc: 0.9257\n",
      "Epoch 72/10000\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.2707 - auc_1: 0.9086 - acc: 0.8880 - val_loss: 0.2112 - val_auc_1: 0.8129 - val_acc: 0.9234\n",
      "Epoch 73/10000\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.2712 - auc_1: 0.9082 - acc: 0.8873 - val_loss: 0.2179 - val_auc_1: 0.8095 - val_acc: 0.9203\n",
      "Epoch 74/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2720 - auc_1: 0.9074 - acc: 0.8879 - val_loss: 0.2063 - val_auc_1: 0.8050 - val_acc: 0.9242\n",
      "Epoch 75/10000\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.2706 - auc_1: 0.9095 - acc: 0.8872 - val_loss: 0.2143 - val_auc_1: 0.8201 - val_acc: 0.9224\n",
      "Epoch 76/10000\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.2717 - auc_1: 0.9079 - acc: 0.8879 - val_loss: 0.2180 - val_auc_1: 0.8015 - val_acc: 0.9182\n",
      "Epoch 77/10000\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.2709 - auc_1: 0.9085 - acc: 0.8883 - val_loss: 0.2052 - val_auc_1: 0.8074 - val_acc: 0.9259\n",
      "Epoch 78/10000\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.2709 - auc_1: 0.9085 - acc: 0.8872 - val_loss: 0.2121 - val_auc_1: 0.8198 - val_acc: 0.9204\n",
      "Epoch 79/10000\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.2695 - auc_1: 0.9090 - acc: 0.8887 - val_loss: 0.2166 - val_auc_1: 0.8097 - val_acc: 0.9216\n",
      "Epoch 80/10000\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.2698 - auc_1: 0.9092 - acc: 0.8879 - val_loss: 0.2184 - val_auc_1: 0.8095 - val_acc: 0.9193\n",
      "Epoch 81/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.2696 - auc_1: 0.9092 - acc: 0.8886 - val_loss: 0.1987 - val_auc_1: 0.8013 - val_acc: 0.9294\n",
      "Epoch 82/10000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2704 - auc_1: 0.9090 - acc: 0.8889 - val_loss: 0.2271 - val_auc_1: 0.8151 - val_acc: 0.9165\n",
      "Epoch 83/10000\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 0.2712 - auc_1: 0.9084 - acc: 0.8872 - val_loss: 0.1996 - val_auc_1: 0.8142 - val_acc: 0.9259\n",
      "Epoch 84/10000\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2710 - auc_1: 0.9081 - acc: 0.8886 - val_loss: 0.2057 - val_auc_1: 0.8231 - val_acc: 0.9253\n",
      "Epoch 85/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2698 - auc_1: 0.9097 - acc: 0.8885 - val_loss: 0.2144 - val_auc_1: 0.8033 - val_acc: 0.9223\n",
      "Epoch 86/10000\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.2697 - auc_1: 0.9096 - acc: 0.8877 - val_loss: 0.2154 - val_auc_1: 0.8084 - val_acc: 0.9219\n",
      "Epoch 87/10000\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.2711 - auc_1: 0.9079 - acc: 0.8881 - val_loss: 0.2067 - val_auc_1: 0.8109 - val_acc: 0.9257\n",
      "Epoch 88/10000\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.2706 - auc_1: 0.9086 - acc: 0.8883 - val_loss: 0.2123 - val_auc_1: 0.8261 - val_acc: 0.9208\n",
      "Epoch 89/10000\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2692 - auc_1: 0.9103 - acc: 0.8884 - val_loss: 0.2216 - val_auc_1: 0.8003 - val_acc: 0.9194\n",
      "Epoch 90/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2705 - auc_1: 0.9089 - acc: 0.8883 - val_loss: 0.2123 - val_auc_1: 0.8106 - val_acc: 0.9225\n",
      "Epoch 91/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2711 - auc_1: 0.9088 - acc: 0.8879 - val_loss: 0.2065 - val_auc_1: 0.8229 - val_acc: 0.9248\n",
      "Epoch 92/10000\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.2699 - auc_1: 0.9094 - acc: 0.8888 - val_loss: 0.2156 - val_auc_1: 0.8034 - val_acc: 0.9212\n",
      "Epoch 93/10000\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.2701 - auc_1: 0.9092 - acc: 0.8889 - val_loss: 0.2015 - val_auc_1: 0.8241 - val_acc: 0.9274\n",
      "Epoch 94/10000\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.2693 - auc_1: 0.9097 - acc: 0.8888 - val_loss: 0.2096 - val_auc_1: 0.8158 - val_acc: 0.9240\n",
      "Epoch 95/10000\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.2693 - auc_1: 0.9100 - acc: 0.8888 - val_loss: 0.2249 - val_auc_1: 0.8118 - val_acc: 0.9150\n",
      "Epoch 96/10000\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.2684 - auc_1: 0.9112 - acc: 0.8889 - val_loss: 0.2053 - val_auc_1: 0.8199 - val_acc: 0.9266\n",
      "Epoch 97/10000\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 0.2684 - auc_1: 0.9105 - acc: 0.8894 - val_loss: 0.2015 - val_auc_1: 0.8093 - val_acc: 0.9277\n",
      "Epoch 98/10000\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.2703 - auc_1: 0.9091 - acc: 0.8885 - val_loss: 0.2032 - val_auc_1: 0.7995 - val_acc: 0.9269\n",
      "Epoch 99/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.2690 - auc_1: 0.9099 - acc: 0.8885 - val_loss: 0.2222 - val_auc_1: 0.8230 - val_acc: 0.9177\n",
      "Epoch 100/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2697 - auc_1: 0.9096 - acc: 0.8879 - val_loss: 0.2134 - val_auc_1: 0.8084 - val_acc: 0.9227\n",
      "Epoch 101/10000\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.2691 - auc_1: 0.9098 - acc: 0.8893 - val_loss: 0.2083 - val_auc_1: 0.8105 - val_acc: 0.9255\n",
      "Epoch 102/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 566ms/step - loss: 0.2708 - auc_1: 0.9080 - acc: 0.8881 - val_loss: 0.2058 - val_auc_1: 0.8076 - val_acc: 0.9256\n",
      "Epoch 103/10000\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.2686 - auc_1: 0.9105 - acc: 0.8892 - val_loss: 0.2088 - val_auc_1: 0.8244 - val_acc: 0.9233\n",
      "Epoch 104/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.2693 - auc_1: 0.9102 - acc: 0.8878 - val_loss: 0.2147 - val_auc_1: 0.7995 - val_acc: 0.9238\n",
      "Epoch 105/10000\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.2682 - auc_1: 0.9109 - acc: 0.8891 - val_loss: 0.2007 - val_auc_1: 0.8249 - val_acc: 0.9274\n",
      "Epoch 106/10000\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.2685 - auc_1: 0.9102 - acc: 0.8890 - val_loss: 0.2222 - val_auc_1: 0.8228 - val_acc: 0.9172\n",
      "Epoch 107/10000\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.2672 - auc_1: 0.9117 - acc: 0.8886 - val_loss: 0.2057 - val_auc_1: 0.8075 - val_acc: 0.9266\n",
      "Epoch 108/10000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2686 - auc_1: 0.9100 - acc: 0.8891 - val_loss: 0.2176 - val_auc_1: 0.7983 - val_acc: 0.9210\n",
      "Epoch 109/10000\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.2683 - auc_1: 0.9106 - acc: 0.8891 - val_loss: 0.2048 - val_auc_1: 0.8307 - val_acc: 0.9245\n",
      "Epoch 110/10000\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.2685 - auc_1: 0.9104 - acc: 0.8889 - val_loss: 0.2047 - val_auc_1: 0.8104 - val_acc: 0.9274\n",
      "Epoch 111/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2690 - auc_1: 0.9105 - acc: 0.8879 - val_loss: 0.2225 - val_auc_1: 0.8105 - val_acc: 0.9161\n",
      "Epoch 112/10000\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.2692 - auc_1: 0.9097 - acc: 0.8889 - val_loss: 0.2095 - val_auc_1: 0.8187 - val_acc: 0.9243\n",
      "Epoch 113/10000\n",
      "1/1 [==============================] - 1s 633ms/step - loss: 0.2693 - auc_1: 0.9100 - acc: 0.8884 - val_loss: 0.2084 - val_auc_1: 0.8153 - val_acc: 0.9253\n",
      "Epoch 114/10000\n",
      "1/1 [==============================] - 1s 636ms/step - loss: 0.2684 - auc_1: 0.9105 - acc: 0.8890 - val_loss: 0.2092 - val_auc_1: 0.8114 - val_acc: 0.9231\n",
      "Epoch 115/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.2683 - auc_1: 0.9109 - acc: 0.8895 - val_loss: 0.2026 - val_auc_1: 0.8233 - val_acc: 0.9278\n",
      "Epoch 116/10000\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.2696 - auc_1: 0.9097 - acc: 0.8882 - val_loss: 0.2203 - val_auc_1: 0.8142 - val_acc: 0.9197\n",
      "Epoch 117/10000\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.2676 - auc_1: 0.9111 - acc: 0.8894 - val_loss: 0.2097 - val_auc_1: 0.8099 - val_acc: 0.9244\n",
      "Epoch 118/10000\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.2675 - auc_1: 0.9113 - acc: 0.8901 - val_loss: 0.2063 - val_auc_1: 0.8109 - val_acc: 0.9243\n",
      "Epoch 119/10000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.2680 - auc_1: 0.9111 - acc: 0.8888 - val_loss: 0.2101 - val_auc_1: 0.8291 - val_acc: 0.9215\n",
      "Epoch 120/10000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.2689 - auc_1: 0.9105 - acc: 0.8882 - val_loss: 0.2197 - val_auc_1: 0.8047 - val_acc: 0.9197\n",
      "Epoch 121/10000\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.2685 - auc_1: 0.9110 - acc: 0.8884 - val_loss: 0.2029 - val_auc_1: 0.8116 - val_acc: 0.9277\n",
      "Epoch 122/10000\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.2680 - auc_1: 0.9107 - acc: 0.8897 - val_loss: 0.2179 - val_auc_1: 0.8239 - val_acc: 0.9202\n",
      "Epoch 123/10000\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.2682 - auc_1: 0.9109 - acc: 0.8884 - val_loss: 0.2107 - val_auc_1: 0.8136 - val_acc: 0.9229\n",
      "Epoch 124/10000\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.2680 - auc_1: 0.9105 - acc: 0.8889 - val_loss: 0.2107 - val_auc_1: 0.8190 - val_acc: 0.9224\n",
      "Epoch 125/10000\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.2662 - auc_1: 0.9120 - acc: 0.8899 - val_loss: 0.2018 - val_auc_1: 0.8111 - val_acc: 0.9277\n",
      "Epoch 126/10000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.2684 - auc_1: 0.9108 - acc: 0.8890 - val_loss: 0.2221 - val_auc_1: 0.7993 - val_acc: 0.9201\n",
      "Epoch 127/10000\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.2678 - auc_1: 0.9112 - acc: 0.8885 - val_loss: 0.2047 - val_auc_1: 0.8288 - val_acc: 0.9247\n",
      "Epoch 128/10000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2670 - auc_1: 0.9115 - acc: 0.8888 - val_loss: 0.2025 - val_auc_1: 0.8264 - val_acc: 0.9263\n",
      "Epoch 129/10000\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.2671 - auc_1: 0.9119 - acc: 0.8898 - val_loss: 0.2164 - val_auc_1: 0.8088 - val_acc: 0.9203\n",
      "Epoch 130/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.2690 - auc_1: 0.9101 - acc: 0.8891 - val_loss: 0.2053 - val_auc_1: 0.8181 - val_acc: 0.9267\n",
      "Epoch 131/10000\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 0.2699 - auc_1: 0.9095 - acc: 0.8884 - val_loss: 0.2195 - val_auc_1: 0.8132 - val_acc: 0.9187\n",
      "Epoch 132/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.2677 - auc_1: 0.9111 - acc: 0.8895 - val_loss: 0.2056 - val_auc_1: 0.8201 - val_acc: 0.9261\n",
      "Epoch 133/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2682 - auc_1: 0.9113 - acc: 0.8882 - val_loss: 0.2106 - val_auc_1: 0.8139 - val_acc: 0.9235\n",
      "Epoch 134/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2680 - auc_1: 0.9107 - acc: 0.8887 - val_loss: 0.2135 - val_auc_1: 0.8224 - val_acc: 0.9209\n",
      "Epoch 135/10000\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.2705 - auc_1: 0.9089 - acc: 0.8876 - val_loss: 0.2080 - val_auc_1: 0.8084 - val_acc: 0.9259\n",
      "Epoch 136/10000\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.2674 - auc_1: 0.9106 - acc: 0.8894 - val_loss: 0.2098 - val_auc_1: 0.8132 - val_acc: 0.9238\n",
      "Epoch 137/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2683 - auc_1: 0.9111 - acc: 0.8895 - val_loss: 0.2005 - val_auc_1: 0.8093 - val_acc: 0.9289\n",
      "Epoch 138/10000\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.2678 - auc_1: 0.9110 - acc: 0.8895 - val_loss: 0.2132 - val_auc_1: 0.8262 - val_acc: 0.9212\n",
      "Epoch 139/10000\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.2670 - auc_1: 0.9119 - acc: 0.8899 - val_loss: 0.2045 - val_auc_1: 0.8114 - val_acc: 0.9267\n",
      "Epoch 140/10000\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.2668 - auc_1: 0.9121 - acc: 0.8893 - val_loss: 0.2289 - val_auc_1: 0.8134 - val_acc: 0.9153\n",
      "Epoch 141/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2664 - auc_1: 0.9120 - acc: 0.8894 - val_loss: 0.1959 - val_auc_1: 0.8229 - val_acc: 0.9301\n",
      "Epoch 142/10000\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.2671 - auc_1: 0.9113 - acc: 0.8893 - val_loss: 0.2071 - val_auc_1: 0.8145 - val_acc: 0.9250\n",
      "Epoch 143/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2676 - auc_1: 0.9112 - acc: 0.8887 - val_loss: 0.2269 - val_auc_1: 0.8174 - val_acc: 0.9159\n",
      "Epoch 144/10000\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.2663 - auc_1: 0.9125 - acc: 0.8903 - val_loss: 0.2030 - val_auc_1: 0.8138 - val_acc: 0.9275\n",
      "Epoch 145/10000\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.2687 - auc_1: 0.9100 - acc: 0.8895 - val_loss: 0.2018 - val_auc_1: 0.8231 - val_acc: 0.9271\n",
      "Epoch 146/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2670 - auc_1: 0.9117 - acc: 0.8892 - val_loss: 0.2150 - val_auc_1: 0.8070 - val_acc: 0.9219\n",
      "Epoch 147/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2680 - auc_1: 0.9110 - acc: 0.8886 - val_loss: 0.2031 - val_auc_1: 0.8208 - val_acc: 0.9258\n",
      "Epoch 148/10000\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.2667 - auc_1: 0.9120 - acc: 0.8899 - val_loss: 0.2199 - val_auc_1: 0.8168 - val_acc: 0.9187\n",
      "Epoch 149/10000\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.2674 - auc_1: 0.9114 - acc: 0.8895 - val_loss: 0.1904 - val_auc_1: 0.8207 - val_acc: 0.9330\n",
      "Epoch 150/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 611ms/step - loss: 0.2666 - auc_1: 0.9120 - acc: 0.8885 - val_loss: 0.2312 - val_auc_1: 0.8075 - val_acc: 0.9147\n",
      "Epoch 151/10000\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 0.2666 - auc_1: 0.9124 - acc: 0.8891 - val_loss: 0.2045 - val_auc_1: 0.8267 - val_acc: 0.9254\n",
      "Epoch 152/10000\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.2662 - auc_1: 0.9124 - acc: 0.8896 - val_loss: 0.2079 - val_auc_1: 0.8142 - val_acc: 0.9248\n",
      "Epoch 153/10000\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.2670 - auc_1: 0.9117 - acc: 0.8899 - val_loss: 0.2174 - val_auc_1: 0.8116 - val_acc: 0.9203\n",
      "Epoch 154/10000\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 0.2665 - auc_1: 0.9119 - acc: 0.8897 - val_loss: 0.2006 - val_auc_1: 0.8170 - val_acc: 0.9293\n",
      "Epoch 155/10000\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 0.2647 - auc_1: 0.9136 - acc: 0.8898 - val_loss: 0.2066 - val_auc_1: 0.8269 - val_acc: 0.9237\n",
      "Epoch 156/10000\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.2663 - auc_1: 0.9121 - acc: 0.8885 - val_loss: 0.2162 - val_auc_1: 0.8087 - val_acc: 0.9220\n",
      "Epoch 157/10000\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.2662 - auc_1: 0.9121 - acc: 0.8890 - val_loss: 0.2061 - val_auc_1: 0.8354 - val_acc: 0.9238\n",
      "Epoch 158/10000\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 0.2669 - auc_1: 0.9117 - acc: 0.8891 - val_loss: 0.1997 - val_auc_1: 0.8010 - val_acc: 0.9303\n",
      "Epoch 159/10000\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.2658 - auc_1: 0.9126 - acc: 0.8888 - val_loss: 0.2239 - val_auc_1: 0.8228 - val_acc: 0.9153\n",
      "Epoch 160/10000\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.2666 - auc_1: 0.9118 - acc: 0.8887 - val_loss: 0.2007 - val_auc_1: 0.8154 - val_acc: 0.9280\n",
      "Epoch 161/10000\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 0.2660 - auc_1: 0.9130 - acc: 0.8890 - val_loss: 0.2136 - val_auc_1: 0.8171 - val_acc: 0.9224\n",
      "Epoch 162/10000\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.2657 - auc_1: 0.9128 - acc: 0.8897 - val_loss: 0.2037 - val_auc_1: 0.8165 - val_acc: 0.9266\n",
      "Epoch 163/10000\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 0.2654 - auc_1: 0.9134 - acc: 0.8894 - val_loss: 0.2125 - val_auc_1: 0.8116 - val_acc: 0.9240\n",
      "Epoch 164/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.2668 - auc_1: 0.9122 - acc: 0.8884 - val_loss: 0.2022 - val_auc_1: 0.8237 - val_acc: 0.9263\n",
      "Epoch 165/10000\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.2667 - auc_1: 0.9121 - acc: 0.8884 - val_loss: 0.2117 - val_auc_1: 0.8162 - val_acc: 0.9233\n",
      "Epoch 166/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.2664 - auc_1: 0.9124 - acc: 0.8887 - val_loss: 0.2140 - val_auc_1: 0.8276 - val_acc: 0.9204\n",
      "Epoch 167/10000\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.2658 - auc_1: 0.9127 - acc: 0.8899 - val_loss: 0.2075 - val_auc_1: 0.8145 - val_acc: 0.9260\n",
      "Epoch 168/10000\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.2670 - auc_1: 0.9113 - acc: 0.8893 - val_loss: 0.1889 - val_auc_1: 0.8202 - val_acc: 0.9328\n",
      "Epoch 169/10000\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.2659 - auc_1: 0.9128 - acc: 0.8893 - val_loss: 0.2199 - val_auc_1: 0.8111 - val_acc: 0.9208\n",
      "Epoch 170/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.2674 - auc_1: 0.9119 - acc: 0.8883 - val_loss: 0.2157 - val_auc_1: 0.8254 - val_acc: 0.9214\n",
      "Epoch 171/10000\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.2660 - auc_1: 0.9126 - acc: 0.8889 - val_loss: 0.2083 - val_auc_1: 0.8161 - val_acc: 0.9245\n",
      "Epoch 172/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.2661 - auc_1: 0.9127 - acc: 0.8892 - val_loss: 0.2048 - val_auc_1: 0.8219 - val_acc: 0.9256\n",
      "Epoch 173/10000\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.2656 - auc_1: 0.9128 - acc: 0.8891 - val_loss: 0.2105 - val_auc_1: 0.8199 - val_acc: 0.9242\n",
      "Epoch 174/10000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.2656 - auc_1: 0.9133 - acc: 0.8894 - val_loss: 0.2072 - val_auc_1: 0.8138 - val_acc: 0.9259\n",
      "Epoch 175/10000\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.2662 - auc_1: 0.9126 - acc: 0.8891 - val_loss: 0.2025 - val_auc_1: 0.8225 - val_acc: 0.9268\n",
      "Epoch 176/10000\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.2663 - auc_1: 0.9122 - acc: 0.8886 - val_loss: 0.2161 - val_auc_1: 0.8209 - val_acc: 0.9219\n",
      "Epoch 177/10000\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.2657 - auc_1: 0.9124 - acc: 0.8897 - val_loss: 0.2078 - val_auc_1: 0.8117 - val_acc: 0.9253\n",
      "Epoch 178/10000\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.2655 - auc_1: 0.9133 - acc: 0.8899 - val_loss: 0.2079 - val_auc_1: 0.8233 - val_acc: 0.9246\n",
      "Epoch 179/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.2662 - auc_1: 0.9125 - acc: 0.8906 - val_loss: 0.2034 - val_auc_1: 0.8161 - val_acc: 0.9270\n",
      "Epoch 180/10000\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.2651 - auc_1: 0.9133 - acc: 0.8897 - val_loss: 0.2151 - val_auc_1: 0.8239 - val_acc: 0.9210\n",
      "Epoch 181/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.2652 - auc_1: 0.9134 - acc: 0.8897 - val_loss: 0.2097 - val_auc_1: 0.8222 - val_acc: 0.9236\n",
      "Epoch 182/10000\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.2663 - auc_1: 0.9124 - acc: 0.8895 - val_loss: 0.2059 - val_auc_1: 0.8124 - val_acc: 0.9267\n",
      "Epoch 183/10000\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 0.2660 - auc_1: 0.9123 - acc: 0.8900 - val_loss: 0.2100 - val_auc_1: 0.8164 - val_acc: 0.9243\n",
      "Epoch 184/10000\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2656 - auc_1: 0.9132 - acc: 0.8893 - val_loss: 0.2039 - val_auc_1: 0.8267 - val_acc: 0.9267\n",
      "Epoch 185/10000\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.2653 - auc_1: 0.9135 - acc: 0.8900 - val_loss: 0.2072 - val_auc_1: 0.8139 - val_acc: 0.9267\n",
      "Epoch 186/10000\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.2660 - auc_1: 0.9128 - acc: 0.8889 - val_loss: 0.2048 - val_auc_1: 0.8221 - val_acc: 0.9259\n",
      "Epoch 187/10000\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.2652 - auc_1: 0.9135 - acc: 0.8893 - val_loss: 0.2099 - val_auc_1: 0.8157 - val_acc: 0.9245\n",
      "Epoch 188/10000\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.2650 - auc_1: 0.9133 - acc: 0.8896 - val_loss: 0.2122 - val_auc_1: 0.8207 - val_acc: 0.9230\n",
      "Epoch 189/10000\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.2659 - auc_1: 0.9124 - acc: 0.8898 - val_loss: 0.2033 - val_auc_1: 0.8224 - val_acc: 0.9266\n",
      "Epoch 190/10000\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 0.2656 - auc_1: 0.9130 - acc: 0.8889 - val_loss: 0.2095 - val_auc_1: 0.8155 - val_acc: 0.9254\n",
      "Epoch 191/10000\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.2644 - auc_1: 0.9133 - acc: 0.8901 - val_loss: 0.2073 - val_auc_1: 0.8229 - val_acc: 0.9250\n",
      "Epoch 192/10000\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.2649 - auc_1: 0.9129 - acc: 0.8910 - val_loss: 0.2101 - val_auc_1: 0.8188 - val_acc: 0.9244\n",
      "Epoch 193/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.2650 - auc_1: 0.9136 - acc: 0.8901 - val_loss: 0.2103 - val_auc_1: 0.8199 - val_acc: 0.9246\n",
      "Epoch 194/10000\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.2639 - auc_1: 0.9140 - acc: 0.8896 - val_loss: 0.2045 - val_auc_1: 0.8224 - val_acc: 0.9267\n",
      "Epoch 195/10000\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.2652 - auc_1: 0.9132 - acc: 0.8894 - val_loss: 0.2073 - val_auc_1: 0.8200 - val_acc: 0.9257\n",
      "Epoch 196/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.2656 - auc_1: 0.9131 - acc: 0.8896 - val_loss: 0.2125 - val_auc_1: 0.8203 - val_acc: 0.9233\n",
      "Epoch 197/10000\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.2644 - auc_1: 0.9136 - acc: 0.8900 - val_loss: 0.2035 - val_auc_1: 0.8196 - val_acc: 0.9269\n",
      "Epoch 198/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2653 - auc_1: 0.9135 - acc: 0.8891 - val_loss: 0.2073 - val_auc_1: 0.8203 - val_acc: 0.9258\n",
      "Epoch 199/10000\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.2661 - auc_1: 0.9130 - acc: 0.8878 - val_loss: 0.2067 - val_auc_1: 0.8169 - val_acc: 0.9260\n",
      "Epoch 200/10000\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.2646 - auc_1: 0.9138 - acc: 0.8902 - val_loss: 0.2089 - val_auc_1: 0.8248 - val_acc: 0.9245\n",
      "Epoch 201/10000\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.2654 - auc_1: 0.9133 - acc: 0.8907 - val_loss: 0.2106 - val_auc_1: 0.8157 - val_acc: 0.9247\n",
      "Epoch 202/10000\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.2643 - auc_1: 0.9137 - acc: 0.8898 - val_loss: 0.2074 - val_auc_1: 0.8213 - val_acc: 0.9258\n",
      "Epoch 203/10000\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.2653 - auc_1: 0.9133 - acc: 0.8899 - val_loss: 0.2052 - val_auc_1: 0.8232 - val_acc: 0.9265\n",
      "Epoch 204/10000\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2647 - auc_1: 0.9139 - acc: 0.8890 - val_loss: 0.2092 - val_auc_1: 0.8181 - val_acc: 0.9251\n",
      "Epoch 205/10000\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.2647 - auc_1: 0.9135 - acc: 0.8900 - val_loss: 0.2075 - val_auc_1: 0.8203 - val_acc: 0.9256\n",
      "Epoch 206/10000\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.2643 - auc_1: 0.9140 - acc: 0.8891 - val_loss: 0.2081 - val_auc_1: 0.8196 - val_acc: 0.9250\n",
      "Epoch 207/10000\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.2644 - auc_1: 0.9137 - acc: 0.8898 - val_loss: 0.2083 - val_auc_1: 0.8172 - val_acc: 0.9257\n",
      "Epoch 208/10000\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.2629 - auc_1: 0.9151 - acc: 0.8908 - val_loss: 0.2062 - val_auc_1: 0.8238 - val_acc: 0.9263\n",
      "Epoch 209/10000\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.2661 - auc_1: 0.9129 - acc: 0.8894 - val_loss: 0.2102 - val_auc_1: 0.8190 - val_acc: 0.9247\n",
      "Epoch 210/10000\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.2657 - auc_1: 0.9126 - acc: 0.8887 - val_loss: 0.2056 - val_auc_1: 0.8252 - val_acc: 0.9262\n",
      "Epoch 211/10000\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.2651 - auc_1: 0.9138 - acc: 0.8894 - val_loss: 0.2082 - val_auc_1: 0.8237 - val_acc: 0.9250\n",
      "Epoch 212/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.2650 - auc_1: 0.9131 - acc: 0.8902 - val_loss: 0.2081 - val_auc_1: 0.8221 - val_acc: 0.9249\n",
      "Epoch 213/10000\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.2644 - auc_1: 0.9148 - acc: 0.8896 - val_loss: 0.2052 - val_auc_1: 0.8193 - val_acc: 0.9270\n",
      "Epoch 214/10000\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.2641 - auc_1: 0.9140 - acc: 0.8898 - val_loss: 0.2028 - val_auc_1: 0.8249 - val_acc: 0.9271\n",
      "Epoch 215/10000\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.2647 - auc_1: 0.9140 - acc: 0.8897 - val_loss: 0.2056 - val_auc_1: 0.8221 - val_acc: 0.9260\n",
      "Epoch 216/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.2638 - auc_1: 0.9148 - acc: 0.8898 - val_loss: 0.2050 - val_auc_1: 0.8187 - val_acc: 0.9272\n",
      "Epoch 217/10000\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.2644 - auc_1: 0.9137 - acc: 0.8903 - val_loss: 0.2112 - val_auc_1: 0.8280 - val_acc: 0.9224\n",
      "Epoch 218/10000\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.2635 - auc_1: 0.9145 - acc: 0.8896 - val_loss: 0.2034 - val_auc_1: 0.8177 - val_acc: 0.9279\n",
      "Epoch 219/10000\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.2645 - auc_1: 0.9138 - acc: 0.8905 - val_loss: 0.2035 - val_auc_1: 0.8236 - val_acc: 0.9269\n",
      "Epoch 220/10000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2625 - auc_1: 0.9153 - acc: 0.8904 - val_loss: 0.2110 - val_auc_1: 0.8343 - val_acc: 0.9223\n",
      "Epoch 221/10000\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 0.2644 - auc_1: 0.9140 - acc: 0.8894 - val_loss: 0.2028 - val_auc_1: 0.8107 - val_acc: 0.9285\n",
      "Epoch 222/10000\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.2638 - auc_1: 0.9143 - acc: 0.8903 - val_loss: 0.2065 - val_auc_1: 0.8309 - val_acc: 0.9250\n",
      "Epoch 223/10000\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.2642 - auc_1: 0.9142 - acc: 0.8894 - val_loss: 0.2002 - val_auc_1: 0.8257 - val_acc: 0.9280\n",
      "Epoch 224/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2643 - auc_1: 0.9142 - acc: 0.8895 - val_loss: 0.2113 - val_auc_1: 0.8245 - val_acc: 0.9243\n",
      "Epoch 225/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2645 - auc_1: 0.9136 - acc: 0.8907 - val_loss: 0.2059 - val_auc_1: 0.8210 - val_acc: 0.9259\n",
      "Epoch 226/10000\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.2651 - auc_1: 0.9137 - acc: 0.8888 - val_loss: 0.2103 - val_auc_1: 0.8311 - val_acc: 0.9233\n",
      "Epoch 227/10000\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.2631 - auc_1: 0.9148 - acc: 0.8904 - val_loss: 0.2092 - val_auc_1: 0.8248 - val_acc: 0.9246\n",
      "Epoch 228/10000\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.2640 - auc_1: 0.9141 - acc: 0.8897 - val_loss: 0.2015 - val_auc_1: 0.8219 - val_acc: 0.9276\n",
      "Epoch 229/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.2646 - auc_1: 0.9139 - acc: 0.8900 - val_loss: 0.2038 - val_auc_1: 0.8234 - val_acc: 0.9279\n",
      "Epoch 230/10000\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.2636 - auc_1: 0.9145 - acc: 0.8901 - val_loss: 0.2066 - val_auc_1: 0.8237 - val_acc: 0.9247\n",
      "Epoch 231/10000\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.2641 - auc_1: 0.9140 - acc: 0.8900 - val_loss: 0.2065 - val_auc_1: 0.8138 - val_acc: 0.9273\n",
      "Epoch 232/10000\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.2646 - auc_1: 0.9143 - acc: 0.8897 - val_loss: 0.2089 - val_auc_1: 0.8305 - val_acc: 0.9245\n",
      "Epoch 233/10000\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.2652 - auc_1: 0.9136 - acc: 0.8897 - val_loss: 0.1966 - val_auc_1: 0.8195 - val_acc: 0.9307\n",
      "Epoch 234/10000\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.2635 - auc_1: 0.9151 - acc: 0.8906 - val_loss: 0.2181 - val_auc_1: 0.8211 - val_acc: 0.9209\n",
      "Epoch 235/10000\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.2644 - auc_1: 0.9138 - acc: 0.8891 - val_loss: 0.1979 - val_auc_1: 0.8308 - val_acc: 0.9285\n",
      "Epoch 236/10000\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.2641 - auc_1: 0.9138 - acc: 0.8901 - val_loss: 0.2133 - val_auc_1: 0.8066 - val_acc: 0.9240\n",
      "Epoch 237/10000\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 0.2627 - auc_1: 0.9156 - acc: 0.8900 - val_loss: 0.1938 - val_auc_1: 0.8318 - val_acc: 0.9313\n",
      "Epoch 238/10000\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.2655 - auc_1: 0.9131 - acc: 0.8897 - val_loss: 0.2095 - val_auc_1: 0.8168 - val_acc: 0.9247\n",
      "Epoch 239/10000\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.2634 - auc_1: 0.9147 - acc: 0.8902 - val_loss: 0.2091 - val_auc_1: 0.8176 - val_acc: 0.9252\n",
      "Epoch 240/10000\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.2629 - auc_1: 0.9154 - acc: 0.8901 - val_loss: 0.2141 - val_auc_1: 0.8282 - val_acc: 0.9215\n",
      "Epoch 241/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.2637 - auc_1: 0.9150 - acc: 0.8897 - val_loss: 0.2023 - val_auc_1: 0.8278 - val_acc: 0.9267\n",
      "Epoch 242/10000\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.2632 - auc_1: 0.9148 - acc: 0.8906 - val_loss: 0.2040 - val_auc_1: 0.8269 - val_acc: 0.9285\n",
      "Epoch 243/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.2630 - auc_1: 0.9153 - acc: 0.8903 - val_loss: 0.2104 - val_auc_1: 0.8191 - val_acc: 0.9250\n",
      "Epoch 244/10000\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.2633 - auc_1: 0.9145 - acc: 0.8897 - val_loss: 0.1985 - val_auc_1: 0.8278 - val_acc: 0.9284\n",
      "Epoch 245/10000\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.2629 - auc_1: 0.9150 - acc: 0.8904 - val_loss: 0.2138 - val_auc_1: 0.8211 - val_acc: 0.9234\n",
      "Epoch 246/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 522ms/step - loss: 0.2642 - auc_1: 0.9144 - acc: 0.8902 - val_loss: 0.2048 - val_auc_1: 0.8281 - val_acc: 0.9274\n",
      "Epoch 247/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.2634 - auc_1: 0.9143 - acc: 0.8910 - val_loss: 0.2097 - val_auc_1: 0.8215 - val_acc: 0.9239\n",
      "Epoch 248/10000\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.2629 - auc_1: 0.9152 - acc: 0.8900 - val_loss: 0.2020 - val_auc_1: 0.8200 - val_acc: 0.9285\n",
      "Epoch 249/10000\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.2619 - auc_1: 0.9157 - acc: 0.8906 - val_loss: 0.2050 - val_auc_1: 0.8314 - val_acc: 0.9263\n",
      "Epoch 250/10000\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.2637 - auc_1: 0.9145 - acc: 0.8903 - val_loss: 0.2065 - val_auc_1: 0.8157 - val_acc: 0.9263\n",
      "Epoch 251/10000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2639 - auc_1: 0.9143 - acc: 0.8895 - val_loss: 0.2133 - val_auc_1: 0.8353 - val_acc: 0.9208\n",
      "Epoch 252/10000\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.2639 - auc_1: 0.9147 - acc: 0.8904 - val_loss: 0.1970 - val_auc_1: 0.8228 - val_acc: 0.9318\n",
      "Epoch 253/10000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.2629 - auc_1: 0.9151 - acc: 0.8907 - val_loss: 0.2017 - val_auc_1: 0.8125 - val_acc: 0.9287\n",
      "Epoch 254/10000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2631 - auc_1: 0.9154 - acc: 0.8903 - val_loss: 0.2133 - val_auc_1: 0.8284 - val_acc: 0.9235\n",
      "Epoch 255/10000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.2620 - auc_1: 0.9156 - acc: 0.8906 - val_loss: 0.2109 - val_auc_1: 0.8304 - val_acc: 0.9229\n",
      "Epoch 256/10000\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.2640 - auc_1: 0.9142 - acc: 0.8895 - val_loss: 0.2041 - val_auc_1: 0.8209 - val_acc: 0.9277\n",
      "Epoch 257/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.2634 - auc_1: 0.9147 - acc: 0.8909 - val_loss: 0.1946 - val_auc_1: 0.8201 - val_acc: 0.9320\n",
      "Epoch 258/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.2643 - auc_1: 0.9144 - acc: 0.8901 - val_loss: 0.1994 - val_auc_1: 0.8258 - val_acc: 0.9305\n",
      "Epoch 259/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.2628 - auc_1: 0.9154 - acc: 0.8903 - val_loss: 0.2064 - val_auc_1: 0.8224 - val_acc: 0.9257\n",
      "Epoch 260/10000\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.2628 - auc_1: 0.9157 - acc: 0.8899 - val_loss: 0.2116 - val_auc_1: 0.8249 - val_acc: 0.9242\n",
      "Epoch 261/10000\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.2640 - auc_1: 0.9142 - acc: 0.8905 - val_loss: 0.2100 - val_auc_1: 0.8299 - val_acc: 0.9230\n",
      "Epoch 262/10000\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.2636 - auc_1: 0.9145 - acc: 0.8913 - val_loss: 0.2026 - val_auc_1: 0.8274 - val_acc: 0.9280\n",
      "Epoch 263/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2634 - auc_1: 0.9146 - acc: 0.8906 - val_loss: 0.2002 - val_auc_1: 0.8262 - val_acc: 0.9292\n",
      "Epoch 264/10000\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.2633 - auc_1: 0.9150 - acc: 0.8905 - val_loss: 0.2155 - val_auc_1: 0.8154 - val_acc: 0.9235\n",
      "Epoch 265/10000\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.2642 - auc_1: 0.9146 - acc: 0.8899 - val_loss: 0.1968 - val_auc_1: 0.8442 - val_acc: 0.9284\n",
      "Epoch 266/10000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.2632 - auc_1: 0.9148 - acc: 0.8900 - val_loss: 0.2058 - val_auc_1: 0.8191 - val_acc: 0.9264\n",
      "Epoch 267/10000\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.2638 - auc_1: 0.9146 - acc: 0.8899 - val_loss: 0.2042 - val_auc_1: 0.8268 - val_acc: 0.9282\n",
      "Epoch 268/10000\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.2630 - auc_1: 0.9149 - acc: 0.8900 - val_loss: 0.2103 - val_auc_1: 0.8215 - val_acc: 0.9242\n",
      "Evaluating model.\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.3483 - auc_1: 0.8475 - acc: 0.8435\n",
      "Done.\n",
      "Test loss: 0.3482820391654968\n",
      "Test accuracy: 0.8475049138069153\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 8)            0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " gcn_conv_10 (GCNConv)          (None, 64)           576         ['dropout_10[0][0]',             \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 64)           0           ['gcn_conv_10[0][0]']            \n",
      "                                                                                                  \n",
      " gcn_conv_11 (GCNConv)          (None, 64)           4160        ['dropout_11[0][0]',             \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 64)           0           ['gcn_conv_11[0][0]']            \n",
      "                                                                                                  \n",
      " gcn_conv_14 (GCNConv)          (None, 1)            65          ['dropout_12[0][0]',             \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,801\n",
      "Trainable params: 4,801\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6647 - auc_2: 0.4139 - acc: 0.6714WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, None, None).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.6647 - auc_2: 0.4139 - acc: 0.6714 - val_loss: 0.4532 - val_auc_2: 0.6292 - val_acc: 0.9254\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.5045 - auc_2: 0.6770 - acc: 0.8296 - val_loss: 0.3498 - val_auc_2: 0.6590 - val_acc: 0.9249\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.4141 - auc_2: 0.7858 - acc: 0.8398 - val_loss: 0.2897 - val_auc_2: 0.6722 - val_acc: 0.9227\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.3589 - auc_2: 0.8322 - acc: 0.8576 - val_loss: 0.2619 - val_auc_2: 0.6856 - val_acc: 0.9209\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 492ms/step - loss: 0.3304 - auc_2: 0.8533 - acc: 0.8694 - val_loss: 0.2608 - val_auc_2: 0.6865 - val_acc: 0.9176\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.3262 - auc_2: 0.8634 - acc: 0.8716 - val_loss: 0.2623 - val_auc_2: 0.6839 - val_acc: 0.9170\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.3354 - auc_2: 0.8682 - acc: 0.8701 - val_loss: 0.2735 - val_auc_2: 0.6949 - val_acc: 0.9136\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.3388 - auc_2: 0.8716 - acc: 0.8725 - val_loss: 0.2707 - val_auc_2: 0.6862 - val_acc: 0.9171\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.3355 - auc_2: 0.8752 - acc: 0.8727 - val_loss: 0.2727 - val_auc_2: 0.6906 - val_acc: 0.9163\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.3335 - auc_2: 0.8754 - acc: 0.8731 - val_loss: 0.2717 - val_auc_2: 0.7025 - val_acc: 0.9149\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.3307 - auc_2: 0.8744 - acc: 0.8727 - val_loss: 0.2635 - val_auc_2: 0.6940 - val_acc: 0.9167\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.3225 - auc_2: 0.8767 - acc: 0.8739 - val_loss: 0.2603 - val_auc_2: 0.7015 - val_acc: 0.9175\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.3176 - auc_2: 0.8766 - acc: 0.8724 - val_loss: 0.2590 - val_auc_2: 0.7004 - val_acc: 0.9172\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.3126 - auc_2: 0.8782 - acc: 0.8717 - val_loss: 0.2665 - val_auc_2: 0.6973 - val_acc: 0.9152\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.3102 - auc_2: 0.8793 - acc: 0.8725 - val_loss: 0.2601 - val_auc_2: 0.7178 - val_acc: 0.9180\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.3096 - auc_2: 0.8796 - acc: 0.8720 - val_loss: 0.2763 - val_auc_2: 0.7028 - val_acc: 0.9143\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.3115 - auc_2: 0.8800 - acc: 0.8715 - val_loss: 0.2743 - val_auc_2: 0.7143 - val_acc: 0.9132\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.3134 - auc_2: 0.8793 - acc: 0.8714 - val_loss: 0.2721 - val_auc_2: 0.7061 - val_acc: 0.9187\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.3133 - auc_2: 0.8795 - acc: 0.8719 - val_loss: 0.2784 - val_auc_2: 0.7247 - val_acc: 0.9115\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.3117 - auc_2: 0.8811 - acc: 0.8724 - val_loss: 0.2622 - val_auc_2: 0.7291 - val_acc: 0.9195\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.3097 - auc_2: 0.8817 - acc: 0.8703 - val_loss: 0.2605 - val_auc_2: 0.7110 - val_acc: 0.9181\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.3060 - auc_2: 0.8831 - acc: 0.8724 - val_loss: 0.2567 - val_auc_2: 0.7279 - val_acc: 0.9176\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.3048 - auc_2: 0.8827 - acc: 0.8731 - val_loss: 0.2540 - val_auc_2: 0.7165 - val_acc: 0.9160\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.3041 - auc_2: 0.8822 - acc: 0.8717 - val_loss: 0.2490 - val_auc_2: 0.7241 - val_acc: 0.9177\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.3016 - auc_2: 0.8844 - acc: 0.8732 - val_loss: 0.2500 - val_auc_2: 0.7375 - val_acc: 0.9131\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 0.3023 - auc_2: 0.8840 - acc: 0.8723 - val_loss: 0.2454 - val_auc_2: 0.7305 - val_acc: 0.9170\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.3031 - auc_2: 0.8835 - acc: 0.8729 - val_loss: 0.2406 - val_auc_2: 0.7301 - val_acc: 0.9184\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.3021 - auc_2: 0.8844 - acc: 0.8742 - val_loss: 0.2514 - val_auc_2: 0.7283 - val_acc: 0.9124\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.3025 - auc_2: 0.8845 - acc: 0.8733 - val_loss: 0.2408 - val_auc_2: 0.7422 - val_acc: 0.9174\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.3022 - auc_2: 0.8851 - acc: 0.8731 - val_loss: 0.2558 - val_auc_2: 0.7339 - val_acc: 0.9101\n",
      "Epoch 31/10000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.3021 - auc_2: 0.8856 - acc: 0.8735 - val_loss: 0.2408 - val_auc_2: 0.7319 - val_acc: 0.9170\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.3003 - auc_2: 0.8862 - acc: 0.8746 - val_loss: 0.2543 - val_auc_2: 0.7296 - val_acc: 0.9104\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2999 - auc_2: 0.8861 - acc: 0.8740 - val_loss: 0.2371 - val_auc_2: 0.7490 - val_acc: 0.9173\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.2990 - auc_2: 0.8874 - acc: 0.8744 - val_loss: 0.2538 - val_auc_2: 0.7293 - val_acc: 0.9117\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.2977 - auc_2: 0.8876 - acc: 0.8744 - val_loss: 0.2370 - val_auc_2: 0.7484 - val_acc: 0.9191\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.2990 - auc_2: 0.8868 - acc: 0.8742 - val_loss: 0.2543 - val_auc_2: 0.7332 - val_acc: 0.9100\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2979 - auc_2: 0.8872 - acc: 0.8750 - val_loss: 0.2372 - val_auc_2: 0.7391 - val_acc: 0.9182\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.2990 - auc_2: 0.8866 - acc: 0.8736 - val_loss: 0.2510 - val_auc_2: 0.7375 - val_acc: 0.9129\n",
      "Epoch 39/10000\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 0.2984 - auc_2: 0.8875 - acc: 0.8741 - val_loss: 0.2373 - val_auc_2: 0.7408 - val_acc: 0.9191\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 1s 515ms/step - loss: 0.2993 - auc_2: 0.8863 - acc: 0.8752 - val_loss: 0.2554 - val_auc_2: 0.7420 - val_acc: 0.9079\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.2993 - auc_2: 0.8862 - acc: 0.8748 - val_loss: 0.2419 - val_auc_2: 0.7491 - val_acc: 0.9153\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.2996 - auc_2: 0.8860 - acc: 0.8739 - val_loss: 0.2415 - val_auc_2: 0.7293 - val_acc: 0.9174\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.2991 - auc_2: 0.8866 - acc: 0.8734 - val_loss: 0.2419 - val_auc_2: 0.7525 - val_acc: 0.9141\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2985 - auc_2: 0.8867 - acc: 0.8756 - val_loss: 0.2538 - val_auc_2: 0.7280 - val_acc: 0.9109\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.2983 - auc_2: 0.8863 - acc: 0.8748 - val_loss: 0.2359 - val_auc_2: 0.7424 - val_acc: 0.9183\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.2971 - auc_2: 0.8877 - acc: 0.8752 - val_loss: 0.2426 - val_auc_2: 0.7437 - val_acc: 0.9146\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 0.2972 - auc_2: 0.8879 - acc: 0.8745 - val_loss: 0.2448 - val_auc_2: 0.7434 - val_acc: 0.9120\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2962 - auc_2: 0.8883 - acc: 0.8745 - val_loss: 0.2325 - val_auc_2: 0.7431 - val_acc: 0.9216\n",
      "Epoch 49/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 538ms/step - loss: 0.2973 - auc_2: 0.8874 - acc: 0.8742 - val_loss: 0.2445 - val_auc_2: 0.7518 - val_acc: 0.9107\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2974 - auc_2: 0.8878 - acc: 0.8747 - val_loss: 0.2495 - val_auc_2: 0.7374 - val_acc: 0.9127\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2975 - auc_2: 0.8875 - acc: 0.8749 - val_loss: 0.2386 - val_auc_2: 0.7379 - val_acc: 0.9155\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.2973 - auc_2: 0.8878 - acc: 0.8740 - val_loss: 0.2456 - val_auc_2: 0.7441 - val_acc: 0.9141\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.2961 - auc_2: 0.8889 - acc: 0.8753 - val_loss: 0.2448 - val_auc_2: 0.7345 - val_acc: 0.9150\n",
      "Epoch 54/10000\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.2964 - auc_2: 0.8886 - acc: 0.8753 - val_loss: 0.2441 - val_auc_2: 0.7683 - val_acc: 0.9117\n",
      "Epoch 55/10000\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2953 - auc_2: 0.8898 - acc: 0.8757 - val_loss: 0.2265 - val_auc_2: 0.7275 - val_acc: 0.9229\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.2964 - auc_2: 0.8887 - acc: 0.8750 - val_loss: 0.2467 - val_auc_2: 0.7268 - val_acc: 0.9126\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.2959 - auc_2: 0.8887 - acc: 0.8752 - val_loss: 0.2472 - val_auc_2: 0.7652 - val_acc: 0.9112\n",
      "Epoch 58/10000\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.2947 - auc_2: 0.8900 - acc: 0.8756 - val_loss: 0.2347 - val_auc_2: 0.7335 - val_acc: 0.9213\n",
      "Epoch 59/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2977 - auc_2: 0.8873 - acc: 0.8744 - val_loss: 0.2444 - val_auc_2: 0.7355 - val_acc: 0.9156\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2948 - auc_2: 0.8897 - acc: 0.8757 - val_loss: 0.2526 - val_auc_2: 0.7367 - val_acc: 0.9108\n",
      "Epoch 61/10000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.2952 - auc_2: 0.8900 - acc: 0.8742 - val_loss: 0.2448 - val_auc_2: 0.7529 - val_acc: 0.9142\n",
      "Epoch 62/10000\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.2955 - auc_2: 0.8892 - acc: 0.8752 - val_loss: 0.2350 - val_auc_2: 0.7439 - val_acc: 0.9189\n",
      "Epoch 63/10000\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.2945 - auc_2: 0.8910 - acc: 0.8747 - val_loss: 0.2430 - val_auc_2: 0.7437 - val_acc: 0.9132\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.2946 - auc_2: 0.8903 - acc: 0.8758 - val_loss: 0.2368 - val_auc_2: 0.7432 - val_acc: 0.9193\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.2944 - auc_2: 0.8903 - acc: 0.8765 - val_loss: 0.2370 - val_auc_2: 0.7586 - val_acc: 0.9167\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.2950 - auc_2: 0.8897 - acc: 0.8750 - val_loss: 0.2568 - val_auc_2: 0.7399 - val_acc: 0.9099\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.2947 - auc_2: 0.8902 - acc: 0.8754 - val_loss: 0.2420 - val_auc_2: 0.7355 - val_acc: 0.9137\n",
      "Epoch 68/10000\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.2956 - auc_2: 0.8898 - acc: 0.8756 - val_loss: 0.2336 - val_auc_2: 0.7416 - val_acc: 0.9205\n",
      "Epoch 69/10000\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.2948 - auc_2: 0.8902 - acc: 0.8747 - val_loss: 0.2382 - val_auc_2: 0.7585 - val_acc: 0.9147\n",
      "Epoch 70/10000\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.2954 - auc_2: 0.8895 - acc: 0.8754 - val_loss: 0.2508 - val_auc_2: 0.7268 - val_acc: 0.9126\n",
      "Epoch 71/10000\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.2973 - auc_2: 0.8877 - acc: 0.8750 - val_loss: 0.2306 - val_auc_2: 0.7580 - val_acc: 0.9205\n",
      "Epoch 72/10000\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.2949 - auc_2: 0.8900 - acc: 0.8769 - val_loss: 0.2456 - val_auc_2: 0.7368 - val_acc: 0.9129\n",
      "Epoch 73/10000\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.2940 - auc_2: 0.8910 - acc: 0.8756 - val_loss: 0.2401 - val_auc_2: 0.7436 - val_acc: 0.9174\n",
      "Epoch 74/10000\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.2949 - auc_2: 0.8898 - acc: 0.8763 - val_loss: 0.2305 - val_auc_2: 0.7675 - val_acc: 0.9168\n",
      "Epoch 75/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2953 - auc_2: 0.8897 - acc: 0.8764 - val_loss: 0.2487 - val_auc_2: 0.7367 - val_acc: 0.9155\n",
      "Epoch 76/10000\n",
      "1/1 [==============================] - 1s 506ms/step - loss: 0.2939 - auc_2: 0.8912 - acc: 0.8754 - val_loss: 0.2386 - val_auc_2: 0.7454 - val_acc: 0.9155\n",
      "Epoch 77/10000\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.2946 - auc_2: 0.8904 - acc: 0.8767 - val_loss: 0.2548 - val_auc_2: 0.7357 - val_acc: 0.9110\n",
      "Epoch 78/10000\n",
      "1/1 [==============================] - 1s 510ms/step - loss: 0.2934 - auc_2: 0.8909 - acc: 0.8764 - val_loss: 0.2343 - val_auc_2: 0.7529 - val_acc: 0.9175\n",
      "Epoch 79/10000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.2945 - auc_2: 0.8905 - acc: 0.8746 - val_loss: 0.2439 - val_auc_2: 0.7365 - val_acc: 0.9157\n",
      "Epoch 80/10000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.2940 - auc_2: 0.8906 - acc: 0.8761 - val_loss: 0.2457 - val_auc_2: 0.7512 - val_acc: 0.9124\n",
      "Epoch 81/10000\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.2944 - auc_2: 0.8903 - acc: 0.8761 - val_loss: 0.2353 - val_auc_2: 0.7581 - val_acc: 0.9173\n",
      "Epoch 82/10000\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.2941 - auc_2: 0.8913 - acc: 0.8761 - val_loss: 0.2420 - val_auc_2: 0.7317 - val_acc: 0.9164\n",
      "Epoch 83/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2924 - auc_2: 0.8919 - acc: 0.8772 - val_loss: 0.2381 - val_auc_2: 0.7495 - val_acc: 0.9177\n",
      "Epoch 84/10000\n",
      "1/1 [==============================] - 0s 500ms/step - loss: 0.2949 - auc_2: 0.8898 - acc: 0.8763 - val_loss: 0.2392 - val_auc_2: 0.7447 - val_acc: 0.9167\n",
      "Epoch 85/10000\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 0.2934 - auc_2: 0.8914 - acc: 0.8761 - val_loss: 0.2409 - val_auc_2: 0.7516 - val_acc: 0.9153\n",
      "Epoch 86/10000\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.2946 - auc_2: 0.8904 - acc: 0.8755 - val_loss: 0.2416 - val_auc_2: 0.7502 - val_acc: 0.9156\n",
      "Epoch 87/10000\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.2938 - auc_2: 0.8919 - acc: 0.8752 - val_loss: 0.2407 - val_auc_2: 0.7485 - val_acc: 0.9169\n",
      "Epoch 88/10000\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.2945 - auc_2: 0.8908 - acc: 0.8747 - val_loss: 0.2340 - val_auc_2: 0.7319 - val_acc: 0.9194\n",
      "Epoch 89/10000\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.2946 - auc_2: 0.8905 - acc: 0.8751 - val_loss: 0.2449 - val_auc_2: 0.7518 - val_acc: 0.9148\n",
      "Epoch 90/10000\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.2929 - auc_2: 0.8922 - acc: 0.8767 - val_loss: 0.2405 - val_auc_2: 0.7389 - val_acc: 0.9165\n",
      "Epoch 91/10000\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.2939 - auc_2: 0.8911 - acc: 0.8760 - val_loss: 0.2353 - val_auc_2: 0.7666 - val_acc: 0.9156\n",
      "Epoch 92/10000\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.2936 - auc_2: 0.8910 - acc: 0.8763 - val_loss: 0.2539 - val_auc_2: 0.7314 - val_acc: 0.9090\n",
      "Epoch 93/10000\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 0.2938 - auc_2: 0.8914 - acc: 0.8746 - val_loss: 0.2473 - val_auc_2: 0.7517 - val_acc: 0.9144\n",
      "Epoch 94/10000\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.2931 - auc_2: 0.8915 - acc: 0.8767 - val_loss: 0.2210 - val_auc_2: 0.7492 - val_acc: 0.9255\n",
      "Epoch 95/10000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.2939 - auc_2: 0.8910 - acc: 0.8752 - val_loss: 0.2357 - val_auc_2: 0.7573 - val_acc: 0.9192\n",
      "Epoch 96/10000\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.2926 - auc_2: 0.8920 - acc: 0.8764 - val_loss: 0.2488 - val_auc_2: 0.7259 - val_acc: 0.9131\n",
      "Epoch 97/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 510ms/step - loss: 0.2943 - auc_2: 0.8907 - acc: 0.8755 - val_loss: 0.2494 - val_auc_2: 0.7503 - val_acc: 0.9113\n",
      "Epoch 98/10000\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.2928 - auc_2: 0.8920 - acc: 0.8771 - val_loss: 0.2323 - val_auc_2: 0.7445 - val_acc: 0.9226\n",
      "Epoch 99/10000\n",
      "1/1 [==============================] - 1s 526ms/step - loss: 0.2935 - auc_2: 0.8912 - acc: 0.8761 - val_loss: 0.2442 - val_auc_2: 0.7578 - val_acc: 0.9112\n",
      "Epoch 100/10000\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.2939 - auc_2: 0.8912 - acc: 0.8763 - val_loss: 0.2337 - val_auc_2: 0.7368 - val_acc: 0.9203\n",
      "Epoch 101/10000\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.2939 - auc_2: 0.8908 - acc: 0.8760 - val_loss: 0.2471 - val_auc_2: 0.7392 - val_acc: 0.9146\n",
      "Epoch 102/10000\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.2935 - auc_2: 0.8913 - acc: 0.8768 - val_loss: 0.2384 - val_auc_2: 0.7572 - val_acc: 0.9165\n",
      "Epoch 103/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.2944 - auc_2: 0.8909 - acc: 0.8756 - val_loss: 0.2456 - val_auc_2: 0.7489 - val_acc: 0.9132\n",
      "Epoch 104/10000\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.2921 - auc_2: 0.8926 - acc: 0.8762 - val_loss: 0.2341 - val_auc_2: 0.7550 - val_acc: 0.9189\n",
      "Epoch 105/10000\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 0.2930 - auc_2: 0.8919 - acc: 0.8764 - val_loss: 0.2417 - val_auc_2: 0.7361 - val_acc: 0.9162\n",
      "Epoch 106/10000\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 0.2931 - auc_2: 0.8915 - acc: 0.8767 - val_loss: 0.2462 - val_auc_2: 0.7521 - val_acc: 0.9143\n",
      "Epoch 107/10000\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 0.2917 - auc_2: 0.8930 - acc: 0.8759 - val_loss: 0.2232 - val_auc_2: 0.7576 - val_acc: 0.9233\n",
      "Epoch 108/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.2942 - auc_2: 0.8902 - acc: 0.8758 - val_loss: 0.2410 - val_auc_2: 0.7298 - val_acc: 0.9163\n",
      "Epoch 109/10000\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.2925 - auc_2: 0.8920 - acc: 0.8766 - val_loss: 0.2512 - val_auc_2: 0.7547 - val_acc: 0.9107\n",
      "Epoch 110/10000\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.2925 - auc_2: 0.8924 - acc: 0.8759 - val_loss: 0.2320 - val_auc_2: 0.7460 - val_acc: 0.9215\n",
      "Epoch 111/10000\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.2927 - auc_2: 0.8919 - acc: 0.8759 - val_loss: 0.2348 - val_auc_2: 0.7487 - val_acc: 0.9176\n",
      "Epoch 112/10000\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.2908 - auc_2: 0.8936 - acc: 0.8767 - val_loss: 0.2472 - val_auc_2: 0.7489 - val_acc: 0.9131\n",
      "Epoch 113/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.2931 - auc_2: 0.8919 - acc: 0.8767 - val_loss: 0.2532 - val_auc_2: 0.7483 - val_acc: 0.9101\n",
      "Epoch 114/10000\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 0.2925 - auc_2: 0.8921 - acc: 0.8760 - val_loss: 0.2297 - val_auc_2: 0.7420 - val_acc: 0.9235\n",
      "Epoch 115/10000\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 0.2929 - auc_2: 0.8920 - acc: 0.8754 - val_loss: 0.2349 - val_auc_2: 0.7562 - val_acc: 0.9174\n",
      "Epoch 116/10000\n",
      "1/1 [==============================] - 1s 749ms/step - loss: 0.2928 - auc_2: 0.8920 - acc: 0.8775 - val_loss: 0.2465 - val_auc_2: 0.7407 - val_acc: 0.9154\n",
      "Epoch 117/10000\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.2921 - auc_2: 0.8927 - acc: 0.8756 - val_loss: 0.2266 - val_auc_2: 0.7355 - val_acc: 0.9215\n",
      "Epoch 118/10000\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 0.2921 - auc_2: 0.8927 - acc: 0.8762 - val_loss: 0.2555 - val_auc_2: 0.7553 - val_acc: 0.9082\n",
      "Epoch 119/10000\n",
      "1/1 [==============================] - 1s 776ms/step - loss: 0.2917 - auc_2: 0.8935 - acc: 0.8753 - val_loss: 0.2247 - val_auc_2: 0.7445 - val_acc: 0.9231\n",
      "Epoch 120/10000\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.2915 - auc_2: 0.8933 - acc: 0.8769 - val_loss: 0.2473 - val_auc_2: 0.7511 - val_acc: 0.9118\n",
      "Epoch 121/10000\n",
      "1/1 [==============================] - 1s 726ms/step - loss: 0.2920 - auc_2: 0.8927 - acc: 0.8765 - val_loss: 0.2345 - val_auc_2: 0.7430 - val_acc: 0.9196\n",
      "Epoch 122/10000\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 0.2926 - auc_2: 0.8923 - acc: 0.8763 - val_loss: 0.2431 - val_auc_2: 0.7541 - val_acc: 0.9144\n",
      "Epoch 123/10000\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 0.2929 - auc_2: 0.8915 - acc: 0.8760 - val_loss: 0.2333 - val_auc_2: 0.7494 - val_acc: 0.9201\n",
      "Epoch 124/10000\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.2906 - auc_2: 0.8941 - acc: 0.8772 - val_loss: 0.2559 - val_auc_2: 0.7361 - val_acc: 0.9097\n",
      "Epoch 125/10000\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.2915 - auc_2: 0.8935 - acc: 0.8764 - val_loss: 0.2286 - val_auc_2: 0.7691 - val_acc: 0.9185\n",
      "Epoch 126/10000\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.2917 - auc_2: 0.8930 - acc: 0.8766 - val_loss: 0.2464 - val_auc_2: 0.7309 - val_acc: 0.9144\n",
      "Epoch 127/10000\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 0.2933 - auc_2: 0.8914 - acc: 0.8764 - val_loss: 0.2354 - val_auc_2: 0.7714 - val_acc: 0.9167\n",
      "Epoch 128/10000\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 0.2916 - auc_2: 0.8928 - acc: 0.8765 - val_loss: 0.2427 - val_auc_2: 0.7446 - val_acc: 0.9161\n",
      "Epoch 129/10000\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 0.2902 - auc_2: 0.8947 - acc: 0.8778 - val_loss: 0.2353 - val_auc_2: 0.7577 - val_acc: 0.9184\n",
      "Epoch 130/10000\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.2921 - auc_2: 0.8924 - acc: 0.8770 - val_loss: 0.2385 - val_auc_2: 0.7386 - val_acc: 0.9175\n",
      "Epoch 131/10000\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.2925 - auc_2: 0.8920 - acc: 0.8765 - val_loss: 0.2354 - val_auc_2: 0.7608 - val_acc: 0.9180\n",
      "Epoch 132/10000\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 0.2909 - auc_2: 0.8937 - acc: 0.8771 - val_loss: 0.2461 - val_auc_2: 0.7451 - val_acc: 0.9154\n",
      "Epoch 133/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.2911 - auc_2: 0.8938 - acc: 0.8756 - val_loss: 0.2428 - val_auc_2: 0.7549 - val_acc: 0.9121\n",
      "Epoch 134/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.2911 - auc_2: 0.8934 - acc: 0.8766 - val_loss: 0.2365 - val_auc_2: 0.7463 - val_acc: 0.9186\n",
      "Epoch 135/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.2918 - auc_2: 0.8935 - acc: 0.8760 - val_loss: 0.2316 - val_auc_2: 0.7529 - val_acc: 0.9195\n",
      "Epoch 136/10000\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.2911 - auc_2: 0.8939 - acc: 0.8767 - val_loss: 0.2431 - val_auc_2: 0.7469 - val_acc: 0.9153\n",
      "Epoch 137/10000\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.2935 - auc_2: 0.8916 - acc: 0.8762 - val_loss: 0.2399 - val_auc_2: 0.7421 - val_acc: 0.9188\n",
      "Epoch 138/10000\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.2906 - auc_2: 0.8938 - acc: 0.8771 - val_loss: 0.2447 - val_auc_2: 0.7668 - val_acc: 0.9123\n",
      "Epoch 139/10000\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.2912 - auc_2: 0.8933 - acc: 0.8769 - val_loss: 0.2405 - val_auc_2: 0.7469 - val_acc: 0.9155\n",
      "Epoch 140/10000\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 0.2916 - auc_2: 0.8930 - acc: 0.8770 - val_loss: 0.2341 - val_auc_2: 0.7488 - val_acc: 0.9198\n",
      "Epoch 141/10000\n",
      "1/1 [==============================] - 1s 741ms/step - loss: 0.2913 - auc_2: 0.8931 - acc: 0.8780 - val_loss: 0.2385 - val_auc_2: 0.7514 - val_acc: 0.9168\n",
      "Epoch 142/10000\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 0.2914 - auc_2: 0.8928 - acc: 0.8768 - val_loss: 0.2457 - val_auc_2: 0.7468 - val_acc: 0.9151\n",
      "Epoch 143/10000\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.2909 - auc_2: 0.8935 - acc: 0.8766 - val_loss: 0.2388 - val_auc_2: 0.7542 - val_acc: 0.9164\n",
      "Epoch 144/10000\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 0.2919 - auc_2: 0.8930 - acc: 0.8764 - val_loss: 0.2409 - val_auc_2: 0.7586 - val_acc: 0.9139\n",
      "Epoch 145/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 747ms/step - loss: 0.2913 - auc_2: 0.8934 - acc: 0.8768 - val_loss: 0.2387 - val_auc_2: 0.7510 - val_acc: 0.9174\n",
      "Epoch 146/10000\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 0.2920 - auc_2: 0.8927 - acc: 0.8764 - val_loss: 0.2352 - val_auc_2: 0.7514 - val_acc: 0.9179\n",
      "Epoch 147/10000\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 0.2898 - auc_2: 0.8942 - acc: 0.8774 - val_loss: 0.2431 - val_auc_2: 0.7547 - val_acc: 0.9158\n",
      "Epoch 148/10000\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 0.2915 - auc_2: 0.8926 - acc: 0.8763 - val_loss: 0.2203 - val_auc_2: 0.7446 - val_acc: 0.9260\n",
      "Epoch 149/10000\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 0.2901 - auc_2: 0.8946 - acc: 0.8770 - val_loss: 0.2484 - val_auc_2: 0.7517 - val_acc: 0.9120\n",
      "Epoch 150/10000\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 0.2900 - auc_2: 0.8947 - acc: 0.8762 - val_loss: 0.2289 - val_auc_2: 0.7409 - val_acc: 0.9229\n",
      "Epoch 151/10000\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 0.2910 - auc_2: 0.8933 - acc: 0.8765 - val_loss: 0.2419 - val_auc_2: 0.7605 - val_acc: 0.9142\n",
      "Epoch 152/10000\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 0.2914 - auc_2: 0.8934 - acc: 0.8766 - val_loss: 0.2468 - val_auc_2: 0.7395 - val_acc: 0.9137\n",
      "Epoch 153/10000\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.2913 - auc_2: 0.8935 - acc: 0.8776 - val_loss: 0.2418 - val_auc_2: 0.7540 - val_acc: 0.9154\n",
      "Epoch 154/10000\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.2901 - auc_2: 0.8946 - acc: 0.8765 - val_loss: 0.2376 - val_auc_2: 0.7480 - val_acc: 0.9190\n",
      "Epoch 155/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.2909 - auc_2: 0.8935 - acc: 0.8766 - val_loss: 0.2483 - val_auc_2: 0.7511 - val_acc: 0.9116\n",
      "Epoch 156/10000\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.2906 - auc_2: 0.8937 - acc: 0.8757 - val_loss: 0.2280 - val_auc_2: 0.7599 - val_acc: 0.9220\n",
      "Epoch 157/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.2906 - auc_2: 0.8938 - acc: 0.8768 - val_loss: 0.2365 - val_auc_2: 0.7540 - val_acc: 0.9182\n",
      "Epoch 158/10000\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.2909 - auc_2: 0.8938 - acc: 0.8772 - val_loss: 0.2430 - val_auc_2: 0.7456 - val_acc: 0.9139\n",
      "Epoch 159/10000\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.2899 - auc_2: 0.8950 - acc: 0.8768 - val_loss: 0.2364 - val_auc_2: 0.7408 - val_acc: 0.9195\n",
      "Epoch 160/10000\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.2902 - auc_2: 0.8946 - acc: 0.8775 - val_loss: 0.2525 - val_auc_2: 0.7528 - val_acc: 0.9089\n",
      "Epoch 161/10000\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 0.2910 - auc_2: 0.8937 - acc: 0.8775 - val_loss: 0.2237 - val_auc_2: 0.7597 - val_acc: 0.9246\n",
      "Epoch 162/10000\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 0.2905 - auc_2: 0.8940 - acc: 0.8760 - val_loss: 0.2461 - val_auc_2: 0.7481 - val_acc: 0.9131\n",
      "Epoch 163/10000\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 0.2901 - auc_2: 0.8943 - acc: 0.8771 - val_loss: 0.2337 - val_auc_2: 0.7588 - val_acc: 0.9192\n",
      "Epoch 164/10000\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.2891 - auc_2: 0.8950 - acc: 0.8784 - val_loss: 0.2366 - val_auc_2: 0.7577 - val_acc: 0.9175\n",
      "Epoch 165/10000\n",
      "1/1 [==============================] - 1s 755ms/step - loss: 0.2914 - auc_2: 0.8929 - acc: 0.8773 - val_loss: 0.2455 - val_auc_2: 0.7497 - val_acc: 0.9137\n",
      "Epoch 166/10000\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.2904 - auc_2: 0.8943 - acc: 0.8758 - val_loss: 0.2314 - val_auc_2: 0.7580 - val_acc: 0.9203\n",
      "Epoch 167/10000\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.2896 - auc_2: 0.8949 - acc: 0.8774 - val_loss: 0.2347 - val_auc_2: 0.7363 - val_acc: 0.9216\n",
      "Epoch 168/10000\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.2893 - auc_2: 0.8950 - acc: 0.8770 - val_loss: 0.2456 - val_auc_2: 0.7571 - val_acc: 0.9131\n",
      "Epoch 169/10000\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 0.2901 - auc_2: 0.8937 - acc: 0.8778 - val_loss: 0.2397 - val_auc_2: 0.7471 - val_acc: 0.9151\n",
      "Epoch 170/10000\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 0.2906 - auc_2: 0.8945 - acc: 0.8760 - val_loss: 0.2337 - val_auc_2: 0.7569 - val_acc: 0.9197\n",
      "Epoch 171/10000\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 0.2899 - auc_2: 0.8944 - acc: 0.8770 - val_loss: 0.2426 - val_auc_2: 0.7607 - val_acc: 0.9140\n",
      "Epoch 172/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.2888 - auc_2: 0.8955 - acc: 0.8777 - val_loss: 0.2296 - val_auc_2: 0.7445 - val_acc: 0.9209\n",
      "Epoch 173/10000\n",
      "1/1 [==============================] - 1s 517ms/step - loss: 0.2906 - auc_2: 0.8940 - acc: 0.8773 - val_loss: 0.2327 - val_auc_2: 0.7516 - val_acc: 0.9193\n",
      "Epoch 174/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.2910 - auc_2: 0.8935 - acc: 0.8762 - val_loss: 0.2498 - val_auc_2: 0.7523 - val_acc: 0.9118\n",
      "Epoch 175/10000\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.2891 - auc_2: 0.8953 - acc: 0.8773 - val_loss: 0.2457 - val_auc_2: 0.7569 - val_acc: 0.9142\n",
      "Epoch 176/10000\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.2897 - auc_2: 0.8949 - acc: 0.8771 - val_loss: 0.2280 - val_auc_2: 0.7582 - val_acc: 0.9207\n",
      "Epoch 177/10000\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.2895 - auc_2: 0.8950 - acc: 0.8773 - val_loss: 0.2379 - val_auc_2: 0.7560 - val_acc: 0.9168\n",
      "Epoch 178/10000\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 0.2896 - auc_2: 0.8950 - acc: 0.8766 - val_loss: 0.2448 - val_auc_2: 0.7401 - val_acc: 0.9154\n",
      "Epoch 179/10000\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 0.2898 - auc_2: 0.8949 - acc: 0.8771 - val_loss: 0.2314 - val_auc_2: 0.7645 - val_acc: 0.9194\n",
      "Epoch 180/10000\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 0.2899 - auc_2: 0.8946 - acc: 0.8775 - val_loss: 0.2406 - val_auc_2: 0.7423 - val_acc: 0.9160\n",
      "Epoch 181/10000\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.2901 - auc_2: 0.8949 - acc: 0.8772 - val_loss: 0.2417 - val_auc_2: 0.7572 - val_acc: 0.9154\n",
      "Epoch 182/10000\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.2897 - auc_2: 0.8951 - acc: 0.8774 - val_loss: 0.2340 - val_auc_2: 0.7474 - val_acc: 0.9196\n",
      "Epoch 183/10000\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.2907 - auc_2: 0.8939 - acc: 0.8767 - val_loss: 0.2435 - val_auc_2: 0.7606 - val_acc: 0.9150\n",
      "Epoch 184/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.2888 - auc_2: 0.8961 - acc: 0.8770 - val_loss: 0.2323 - val_auc_2: 0.7506 - val_acc: 0.9197\n",
      "Epoch 185/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.2889 - auc_2: 0.8953 - acc: 0.8784 - val_loss: 0.2464 - val_auc_2: 0.7498 - val_acc: 0.9131\n",
      "Epoch 186/10000\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.2881 - auc_2: 0.8964 - acc: 0.8783 - val_loss: 0.2350 - val_auc_2: 0.7444 - val_acc: 0.9197\n",
      "Epoch 187/10000\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.2904 - auc_2: 0.8939 - acc: 0.8777 - val_loss: 0.2299 - val_auc_2: 0.7574 - val_acc: 0.9211\n",
      "Epoch 188/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.2899 - auc_2: 0.8944 - acc: 0.8774 - val_loss: 0.2408 - val_auc_2: 0.7529 - val_acc: 0.9145\n",
      "Epoch 189/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.2884 - auc_2: 0.8962 - acc: 0.8773 - val_loss: 0.2395 - val_auc_2: 0.7506 - val_acc: 0.9169\n",
      "Epoch 190/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.2890 - auc_2: 0.8956 - acc: 0.8771 - val_loss: 0.2343 - val_auc_2: 0.7594 - val_acc: 0.9177\n",
      "Epoch 191/10000\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.2888 - auc_2: 0.8957 - acc: 0.8770 - val_loss: 0.2408 - val_auc_2: 0.7466 - val_acc: 0.9159\n",
      "Epoch 192/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.2886 - auc_2: 0.8961 - acc: 0.8783 - val_loss: 0.2294 - val_auc_2: 0.7565 - val_acc: 0.9200\n",
      "Epoch 193/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 545ms/step - loss: 0.2889 - auc_2: 0.8957 - acc: 0.8768 - val_loss: 0.2482 - val_auc_2: 0.7481 - val_acc: 0.9129\n",
      "Epoch 194/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.2895 - auc_2: 0.8946 - acc: 0.8776 - val_loss: 0.2384 - val_auc_2: 0.7541 - val_acc: 0.9167\n",
      "Epoch 195/10000\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.2882 - auc_2: 0.8965 - acc: 0.8776 - val_loss: 0.2381 - val_auc_2: 0.7524 - val_acc: 0.9177\n",
      "Epoch 196/10000\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.2891 - auc_2: 0.8952 - acc: 0.8774 - val_loss: 0.2365 - val_auc_2: 0.7557 - val_acc: 0.9173\n",
      "Epoch 197/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.2898 - auc_2: 0.8943 - acc: 0.8768 - val_loss: 0.2367 - val_auc_2: 0.7548 - val_acc: 0.9167\n",
      "Epoch 198/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.2893 - auc_2: 0.8950 - acc: 0.8772 - val_loss: 0.2377 - val_auc_2: 0.7545 - val_acc: 0.9162\n",
      "Epoch 199/10000\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.2899 - auc_2: 0.8942 - acc: 0.8767 - val_loss: 0.2356 - val_auc_2: 0.7580 - val_acc: 0.9177\n",
      "Epoch 200/10000\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.2880 - auc_2: 0.8962 - acc: 0.8771 - val_loss: 0.2361 - val_auc_2: 0.7531 - val_acc: 0.9177\n",
      "Epoch 201/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.2896 - auc_2: 0.8949 - acc: 0.8775 - val_loss: 0.2397 - val_auc_2: 0.7530 - val_acc: 0.9161\n",
      "Epoch 202/10000\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.2895 - auc_2: 0.8952 - acc: 0.8763 - val_loss: 0.2347 - val_auc_2: 0.7531 - val_acc: 0.9181\n",
      "Epoch 203/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.2891 - auc_2: 0.8954 - acc: 0.8773 - val_loss: 0.2369 - val_auc_2: 0.7525 - val_acc: 0.9172\n",
      "Epoch 204/10000\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.2870 - auc_2: 0.8975 - acc: 0.8773 - val_loss: 0.2379 - val_auc_2: 0.7530 - val_acc: 0.9165\n",
      "Epoch 205/10000\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.2889 - auc_2: 0.8961 - acc: 0.8769 - val_loss: 0.2373 - val_auc_2: 0.7533 - val_acc: 0.9170\n",
      "Epoch 206/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.2894 - auc_2: 0.8950 - acc: 0.8779 - val_loss: 0.2375 - val_auc_2: 0.7554 - val_acc: 0.9170\n",
      "Epoch 207/10000\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.2874 - auc_2: 0.8974 - acc: 0.8768 - val_loss: 0.2402 - val_auc_2: 0.7523 - val_acc: 0.9160\n",
      "Epoch 208/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.2894 - auc_2: 0.8953 - acc: 0.8766 - val_loss: 0.2363 - val_auc_2: 0.7629 - val_acc: 0.9170\n",
      "Epoch 209/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.2891 - auc_2: 0.8952 - acc: 0.8773 - val_loss: 0.2391 - val_auc_2: 0.7519 - val_acc: 0.9161\n",
      "Epoch 210/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.2871 - auc_2: 0.8972 - acc: 0.8771 - val_loss: 0.2358 - val_auc_2: 0.7597 - val_acc: 0.9163\n",
      "Epoch 211/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.2887 - auc_2: 0.8960 - acc: 0.8774 - val_loss: 0.2348 - val_auc_2: 0.7486 - val_acc: 0.9187\n",
      "Epoch 212/10000\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 0.2889 - auc_2: 0.8954 - acc: 0.8775 - val_loss: 0.2427 - val_auc_2: 0.7629 - val_acc: 0.9128\n",
      "Epoch 213/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.2884 - auc_2: 0.8965 - acc: 0.8777 - val_loss: 0.2306 - val_auc_2: 0.7562 - val_acc: 0.9212\n",
      "Epoch 214/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.2886 - auc_2: 0.8958 - acc: 0.8774 - val_loss: 0.2394 - val_auc_2: 0.7473 - val_acc: 0.9163\n",
      "Epoch 215/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.2888 - auc_2: 0.8959 - acc: 0.8774 - val_loss: 0.2441 - val_auc_2: 0.7576 - val_acc: 0.9131\n",
      "Epoch 216/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.2900 - auc_2: 0.8946 - acc: 0.8769 - val_loss: 0.2326 - val_auc_2: 0.7526 - val_acc: 0.9193\n",
      "Epoch 217/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.2891 - auc_2: 0.8955 - acc: 0.8765 - val_loss: 0.2300 - val_auc_2: 0.7623 - val_acc: 0.9197\n",
      "Epoch 218/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.2870 - auc_2: 0.8973 - acc: 0.8786 - val_loss: 0.2392 - val_auc_2: 0.7518 - val_acc: 0.9157\n",
      "Epoch 219/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.2866 - auc_2: 0.8979 - acc: 0.8781 - val_loss: 0.2431 - val_auc_2: 0.7564 - val_acc: 0.9140\n",
      "Epoch 220/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.2870 - auc_2: 0.8972 - acc: 0.8790 - val_loss: 0.2376 - val_auc_2: 0.7439 - val_acc: 0.9187\n",
      "Epoch 221/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.2886 - auc_2: 0.8963 - acc: 0.8769 - val_loss: 0.2319 - val_auc_2: 0.7662 - val_acc: 0.9182\n",
      "Epoch 222/10000\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.2879 - auc_2: 0.8964 - acc: 0.8779 - val_loss: 0.2405 - val_auc_2: 0.7507 - val_acc: 0.9155\n",
      "Epoch 223/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.2880 - auc_2: 0.8965 - acc: 0.8775 - val_loss: 0.2401 - val_auc_2: 0.7509 - val_acc: 0.9149\n",
      "Epoch 224/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.2871 - auc_2: 0.8972 - acc: 0.8793 - val_loss: 0.2306 - val_auc_2: 0.7668 - val_acc: 0.9200\n",
      "Epoch 225/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.2870 - auc_2: 0.8974 - acc: 0.8780 - val_loss: 0.2415 - val_auc_2: 0.7556 - val_acc: 0.9155\n",
      "Epoch 226/10000\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.2887 - auc_2: 0.8956 - acc: 0.8777 - val_loss: 0.2320 - val_auc_2: 0.7575 - val_acc: 0.9182\n",
      "Epoch 227/10000\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.2886 - auc_2: 0.8952 - acc: 0.8786 - val_loss: 0.2353 - val_auc_2: 0.7557 - val_acc: 0.9184\n",
      "Epoch 228/10000\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.2879 - auc_2: 0.8960 - acc: 0.8786 - val_loss: 0.2360 - val_auc_2: 0.7643 - val_acc: 0.9161\n",
      "Epoch 229/10000\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.2885 - auc_2: 0.8960 - acc: 0.8772 - val_loss: 0.2463 - val_auc_2: 0.7562 - val_acc: 0.9122\n",
      "Epoch 230/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.2884 - auc_2: 0.8961 - acc: 0.8777 - val_loss: 0.2255 - val_auc_2: 0.7578 - val_acc: 0.9226\n",
      "Epoch 231/10000\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.2879 - auc_2: 0.8964 - acc: 0.8786 - val_loss: 0.2332 - val_auc_2: 0.7612 - val_acc: 0.9188\n",
      "Epoch 232/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.2886 - auc_2: 0.8961 - acc: 0.8772 - val_loss: 0.2376 - val_auc_2: 0.7443 - val_acc: 0.9175\n",
      "Epoch 233/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.2888 - auc_2: 0.8959 - acc: 0.8775 - val_loss: 0.2384 - val_auc_2: 0.7649 - val_acc: 0.9159\n",
      "Epoch 234/10000\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.2884 - auc_2: 0.8959 - acc: 0.8781 - val_loss: 0.2396 - val_auc_2: 0.7660 - val_acc: 0.9141\n",
      "Epoch 235/10000\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.2891 - auc_2: 0.8952 - acc: 0.8771 - val_loss: 0.2294 - val_auc_2: 0.7474 - val_acc: 0.9225\n",
      "Epoch 236/10000\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.2884 - auc_2: 0.8964 - acc: 0.8781 - val_loss: 0.2316 - val_auc_2: 0.7658 - val_acc: 0.9171\n",
      "Epoch 237/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.2881 - auc_2: 0.8962 - acc: 0.8778 - val_loss: 0.2317 - val_auc_2: 0.7529 - val_acc: 0.9193\n",
      "Epoch 238/10000\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.2865 - auc_2: 0.8979 - acc: 0.8780 - val_loss: 0.2373 - val_auc_2: 0.7606 - val_acc: 0.9169\n",
      "Epoch 239/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.2892 - auc_2: 0.8957 - acc: 0.8768 - val_loss: 0.2480 - val_auc_2: 0.7487 - val_acc: 0.9113\n",
      "Epoch 240/10000\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.2884 - auc_2: 0.8955 - acc: 0.8786 - val_loss: 0.2290 - val_auc_2: 0.7673 - val_acc: 0.9210\n",
      "Epoch 241/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 567ms/step - loss: 0.2881 - auc_2: 0.8963 - acc: 0.8772 - val_loss: 0.2380 - val_auc_2: 0.7507 - val_acc: 0.9160\n",
      "Epoch 242/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.2899 - auc_2: 0.8948 - acc: 0.8767 - val_loss: 0.2323 - val_auc_2: 0.7631 - val_acc: 0.9188\n",
      "Epoch 243/10000\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 0.2883 - auc_2: 0.8959 - acc: 0.8776 - val_loss: 0.2353 - val_auc_2: 0.7517 - val_acc: 0.9184\n",
      "Epoch 244/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.2869 - auc_2: 0.8975 - acc: 0.8781 - val_loss: 0.2321 - val_auc_2: 0.7628 - val_acc: 0.9179\n",
      "Epoch 245/10000\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.2865 - auc_2: 0.8982 - acc: 0.8780 - val_loss: 0.2424 - val_auc_2: 0.7585 - val_acc: 0.9147\n",
      "Epoch 246/10000\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.2873 - auc_2: 0.8966 - acc: 0.8783 - val_loss: 0.2297 - val_auc_2: 0.7656 - val_acc: 0.9184\n",
      "Epoch 247/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.2871 - auc_2: 0.8970 - acc: 0.8780 - val_loss: 0.2464 - val_auc_2: 0.7571 - val_acc: 0.9116\n",
      "Epoch 248/10000\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.2874 - auc_2: 0.8971 - acc: 0.8779 - val_loss: 0.2271 - val_auc_2: 0.7545 - val_acc: 0.9221\n",
      "Evaluating model.\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.3827 - auc_2: 0.8073 - acc: 0.8286\n",
      "Done.\n",
      "Test loss: 0.3827243149280548\n",
      "Test accuracy: 0.8073301911354065\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 8)            0           ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " gcn_conv_15 (GCNConv)          (None, 64)           576         ['dropout_15[0][0]',             \n",
      "                                                                  'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 64)           0           ['gcn_conv_15[0][0]']            \n",
      "                                                                                                  \n",
      " gcn_conv_16 (GCNConv)          (None, 64)           4160        ['dropout_16[0][0]',             \n",
      "                                                                  'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 64)           0           ['gcn_conv_16[0][0]']            \n",
      "                                                                                                  \n",
      " gcn_conv_19 (GCNConv)          (None, 1)            65          ['dropout_17[0][0]',             \n",
      "                                                                  'input_8[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,801\n",
      "Trainable params: 4,801\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8017 - auc_3: 0.6746 - acc: 0.2454WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_8', description=\"created by layer 'input_8'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8017 - auc_3: 0.6746 - acc: 0.2454 - val_loss: 0.5166 - val_auc_3: 0.5705 - val_acc: 0.9237\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 0.5559 - auc_3: 0.6223 - acc: 0.8231 - val_loss: 0.3757 - val_auc_3: 0.5681 - val_acc: 0.9246\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.4695 - auc_3: 0.6233 - acc: 0.8228 - val_loss: 0.3089 - val_auc_3: 0.5857 - val_acc: 0.9242\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.4341 - auc_3: 0.6973 - acc: 0.8226 - val_loss: 0.2807 - val_auc_3: 0.6008 - val_acc: 0.9238\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 1s 536ms/step - loss: 0.4089 - auc_3: 0.7658 - acc: 0.8233 - val_loss: 0.2710 - val_auc_3: 0.6130 - val_acc: 0.9236\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.3832 - auc_3: 0.8066 - acc: 0.8292 - val_loss: 0.2661 - val_auc_3: 0.6209 - val_acc: 0.9225\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.3604 - auc_3: 0.8297 - acc: 0.8462 - val_loss: 0.2728 - val_auc_3: 0.6268 - val_acc: 0.9177\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.3475 - auc_3: 0.8391 - acc: 0.8571 - val_loss: 0.2747 - val_auc_3: 0.6295 - val_acc: 0.9153\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3413 - auc_3: 0.8467 - acc: 0.8615 - val_loss: 0.2806 - val_auc_3: 0.6377 - val_acc: 0.9124\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.3461 - auc_3: 0.8484 - acc: 0.8599 - val_loss: 0.2845 - val_auc_3: 0.6422 - val_acc: 0.9105\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.3488 - auc_3: 0.8505 - acc: 0.8595 - val_loss: 0.2817 - val_auc_3: 0.6355 - val_acc: 0.9120\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.3505 - auc_3: 0.8529 - acc: 0.8577 - val_loss: 0.2987 - val_auc_3: 0.6443 - val_acc: 0.9022\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.3479 - auc_3: 0.8552 - acc: 0.8567 - val_loss: 0.2837 - val_auc_3: 0.6388 - val_acc: 0.9100\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.3442 - auc_3: 0.8566 - acc: 0.8573 - val_loss: 0.2888 - val_auc_3: 0.6412 - val_acc: 0.9068\n",
      "Epoch 15/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 605ms/step - loss: 0.3396 - auc_3: 0.8578 - acc: 0.8575 - val_loss: 0.2884 - val_auc_3: 0.6459 - val_acc: 0.9058\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 0.3347 - auc_3: 0.8595 - acc: 0.8598 - val_loss: 0.2794 - val_auc_3: 0.6515 - val_acc: 0.9110\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 0.3336 - auc_3: 0.8579 - acc: 0.8606 - val_loss: 0.2860 - val_auc_3: 0.6552 - val_acc: 0.9076\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 0.3289 - auc_3: 0.8612 - acc: 0.8609 - val_loss: 0.2786 - val_auc_3: 0.6514 - val_acc: 0.9122\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.3273 - auc_3: 0.8620 - acc: 0.8622 - val_loss: 0.2863 - val_auc_3: 0.6442 - val_acc: 0.9097\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.3257 - auc_3: 0.8634 - acc: 0.8626 - val_loss: 0.2831 - val_auc_3: 0.6513 - val_acc: 0.9122\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.3269 - auc_3: 0.8622 - acc: 0.8625 - val_loss: 0.2758 - val_auc_3: 0.6591 - val_acc: 0.9172\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.3249 - auc_3: 0.8647 - acc: 0.8623 - val_loss: 0.2783 - val_auc_3: 0.6581 - val_acc: 0.9161\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.3272 - auc_3: 0.8631 - acc: 0.8628 - val_loss: 0.2776 - val_auc_3: 0.6636 - val_acc: 0.9156\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.3258 - auc_3: 0.8647 - acc: 0.8619 - val_loss: 0.2814 - val_auc_3: 0.6566 - val_acc: 0.9162\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.3272 - auc_3: 0.8627 - acc: 0.8617 - val_loss: 0.2784 - val_auc_3: 0.6655 - val_acc: 0.9152\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3273 - auc_3: 0.8627 - acc: 0.8608 - val_loss: 0.2672 - val_auc_3: 0.6797 - val_acc: 0.9195\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.3256 - auc_3: 0.8642 - acc: 0.8614 - val_loss: 0.2873 - val_auc_3: 0.6730 - val_acc: 0.9098\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.3256 - auc_3: 0.8639 - acc: 0.8619 - val_loss: 0.2650 - val_auc_3: 0.6416 - val_acc: 0.9210\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.3268 - auc_3: 0.8627 - acc: 0.8616 - val_loss: 0.2675 - val_auc_3: 0.6818 - val_acc: 0.9158\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.3252 - auc_3: 0.8639 - acc: 0.8609 - val_loss: 0.2748 - val_auc_3: 0.6889 - val_acc: 0.9124\n",
      "Epoch 31/10000\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 0.3236 - auc_3: 0.8654 - acc: 0.8622 - val_loss: 0.2685 - val_auc_3: 0.6690 - val_acc: 0.9118\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.3240 - auc_3: 0.8645 - acc: 0.8618 - val_loss: 0.2739 - val_auc_3: 0.6729 - val_acc: 0.9128\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.3226 - auc_3: 0.8651 - acc: 0.8615 - val_loss: 0.2515 - val_auc_3: 0.6803 - val_acc: 0.9198\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3231 - auc_3: 0.8639 - acc: 0.8618 - val_loss: 0.2798 - val_auc_3: 0.6765 - val_acc: 0.9056\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.3218 - auc_3: 0.8659 - acc: 0.8622 - val_loss: 0.2672 - val_auc_3: 0.6622 - val_acc: 0.9128\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.3219 - auc_3: 0.8656 - acc: 0.8631 - val_loss: 0.2714 - val_auc_3: 0.6845 - val_acc: 0.9068\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.3219 - auc_3: 0.8648 - acc: 0.8629 - val_loss: 0.2562 - val_auc_3: 0.6897 - val_acc: 0.9163\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.3221 - auc_3: 0.8648 - acc: 0.8627 - val_loss: 0.2908 - val_auc_3: 0.6658 - val_acc: 0.8993\n",
      "Epoch 39/10000\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.3225 - auc_3: 0.8655 - acc: 0.8609 - val_loss: 0.2682 - val_auc_3: 0.6919 - val_acc: 0.9090\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.3226 - auc_3: 0.8652 - acc: 0.8613 - val_loss: 0.2718 - val_auc_3: 0.6607 - val_acc: 0.9080\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 0.3218 - auc_3: 0.8659 - acc: 0.8623 - val_loss: 0.2601 - val_auc_3: 0.6911 - val_acc: 0.9125\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 0.3221 - auc_3: 0.8656 - acc: 0.8620 - val_loss: 0.2739 - val_auc_3: 0.6660 - val_acc: 0.9072\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 0.3211 - auc_3: 0.8661 - acc: 0.8626 - val_loss: 0.2731 - val_auc_3: 0.6838 - val_acc: 0.9070\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 0.3208 - auc_3: 0.8671 - acc: 0.8622 - val_loss: 0.2732 - val_auc_3: 0.6846 - val_acc: 0.9045\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 0.3221 - auc_3: 0.8650 - acc: 0.8621 - val_loss: 0.2624 - val_auc_3: 0.6787 - val_acc: 0.9134\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 0.3211 - auc_3: 0.8663 - acc: 0.8615 - val_loss: 0.2583 - val_auc_3: 0.6714 - val_acc: 0.9155\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3219 - auc_3: 0.8652 - acc: 0.8624 - val_loss: 0.2685 - val_auc_3: 0.6961 - val_acc: 0.9081\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 0.3206 - auc_3: 0.8663 - acc: 0.8624 - val_loss: 0.2728 - val_auc_3: 0.6690 - val_acc: 0.9082\n",
      "Epoch 49/10000\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.3199 - auc_3: 0.8671 - acc: 0.8631 - val_loss: 0.2670 - val_auc_3: 0.6949 - val_acc: 0.9089\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.3215 - auc_3: 0.8654 - acc: 0.8630 - val_loss: 0.2710 - val_auc_3: 0.6729 - val_acc: 0.9077\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.3200 - auc_3: 0.8675 - acc: 0.8626 - val_loss: 0.2595 - val_auc_3: 0.6659 - val_acc: 0.9170\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3191 - auc_3: 0.8681 - acc: 0.8627 - val_loss: 0.2712 - val_auc_3: 0.6888 - val_acc: 0.9069\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.3209 - auc_3: 0.8659 - acc: 0.8633 - val_loss: 0.2570 - val_auc_3: 0.6955 - val_acc: 0.9142\n",
      "Epoch 54/10000\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.3205 - auc_3: 0.8665 - acc: 0.8626 - val_loss: 0.2741 - val_auc_3: 0.6874 - val_acc: 0.9072\n",
      "Epoch 55/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3209 - auc_3: 0.8664 - acc: 0.8623 - val_loss: 0.2613 - val_auc_3: 0.6888 - val_acc: 0.9137\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3198 - auc_3: 0.8672 - acc: 0.8630 - val_loss: 0.2710 - val_auc_3: 0.6792 - val_acc: 0.9066\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.3205 - auc_3: 0.8666 - acc: 0.8622 - val_loss: 0.2601 - val_auc_3: 0.6807 - val_acc: 0.9153\n",
      "Epoch 58/10000\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.3187 - auc_3: 0.8688 - acc: 0.8627 - val_loss: 0.2644 - val_auc_3: 0.6787 - val_acc: 0.9119\n",
      "Epoch 59/10000\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.3184 - auc_3: 0.8686 - acc: 0.8632 - val_loss: 0.2826 - val_auc_3: 0.6835 - val_acc: 0.8999\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.3193 - auc_3: 0.8676 - acc: 0.8631 - val_loss: 0.2518 - val_auc_3: 0.6790 - val_acc: 0.9209\n",
      "Epoch 61/10000\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 0.3181 - auc_3: 0.8691 - acc: 0.8636 - val_loss: 0.2620 - val_auc_3: 0.6875 - val_acc: 0.9115\n",
      "Epoch 62/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.3181 - auc_3: 0.8690 - acc: 0.8641 - val_loss: 0.2673 - val_auc_3: 0.6827 - val_acc: 0.9115\n",
      "Epoch 63/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 601ms/step - loss: 0.3196 - auc_3: 0.8673 - acc: 0.8638 - val_loss: 0.2652 - val_auc_3: 0.6844 - val_acc: 0.9103\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.3184 - auc_3: 0.8681 - acc: 0.8642 - val_loss: 0.2615 - val_auc_3: 0.6784 - val_acc: 0.9131\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.3187 - auc_3: 0.8684 - acc: 0.8630 - val_loss: 0.2818 - val_auc_3: 0.6799 - val_acc: 0.9027\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 0.3192 - auc_3: 0.8679 - acc: 0.8637 - val_loss: 0.2614 - val_auc_3: 0.6997 - val_acc: 0.9114\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.3188 - auc_3: 0.8680 - acc: 0.8636 - val_loss: 0.2605 - val_auc_3: 0.6855 - val_acc: 0.9142\n",
      "Epoch 68/10000\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.3182 - auc_3: 0.8689 - acc: 0.8622 - val_loss: 0.2752 - val_auc_3: 0.6780 - val_acc: 0.9047\n",
      "Epoch 69/10000\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.3202 - auc_3: 0.8669 - acc: 0.8621 - val_loss: 0.2588 - val_auc_3: 0.6799 - val_acc: 0.9153\n",
      "Epoch 70/10000\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.3182 - auc_3: 0.8690 - acc: 0.8630 - val_loss: 0.2609 - val_auc_3: 0.6949 - val_acc: 0.9110\n",
      "Epoch 71/10000\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.3176 - auc_3: 0.8691 - acc: 0.8638 - val_loss: 0.2840 - val_auc_3: 0.6711 - val_acc: 0.9055\n",
      "Epoch 72/10000\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.3181 - auc_3: 0.8689 - acc: 0.8629 - val_loss: 0.2542 - val_auc_3: 0.6931 - val_acc: 0.9146\n",
      "Epoch 73/10000\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.3183 - auc_3: 0.8686 - acc: 0.8629 - val_loss: 0.2583 - val_auc_3: 0.6730 - val_acc: 0.9160\n",
      "Epoch 74/10000\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.3184 - auc_3: 0.8686 - acc: 0.8628 - val_loss: 0.2677 - val_auc_3: 0.6811 - val_acc: 0.9110\n",
      "Epoch 75/10000\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.3194 - auc_3: 0.8677 - acc: 0.8626 - val_loss: 0.2746 - val_auc_3: 0.6994 - val_acc: 0.9039\n",
      "Epoch 76/10000\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.3174 - auc_3: 0.8691 - acc: 0.8639 - val_loss: 0.2586 - val_auc_3: 0.6843 - val_acc: 0.9155\n",
      "Epoch 77/10000\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.3189 - auc_3: 0.8677 - acc: 0.8638 - val_loss: 0.2683 - val_auc_3: 0.6809 - val_acc: 0.9125\n",
      "Epoch 78/10000\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.3179 - auc_3: 0.8689 - acc: 0.8634 - val_loss: 0.2544 - val_auc_3: 0.6888 - val_acc: 0.9159\n",
      "Epoch 79/10000\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.3176 - auc_3: 0.8694 - acc: 0.8645 - val_loss: 0.2614 - val_auc_3: 0.6690 - val_acc: 0.9154\n",
      "Epoch 80/10000\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.3185 - auc_3: 0.8678 - acc: 0.8636 - val_loss: 0.2687 - val_auc_3: 0.6948 - val_acc: 0.9086\n",
      "Epoch 81/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.3172 - auc_3: 0.8695 - acc: 0.8634 - val_loss: 0.2610 - val_auc_3: 0.6951 - val_acc: 0.9141\n",
      "Epoch 82/10000\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 0.3180 - auc_3: 0.8688 - acc: 0.8635 - val_loss: 0.2668 - val_auc_3: 0.6836 - val_acc: 0.9118\n",
      "Epoch 83/10000\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.3179 - auc_3: 0.8690 - acc: 0.8632 - val_loss: 0.2754 - val_auc_3: 0.6922 - val_acc: 0.9059\n",
      "Epoch 84/10000\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.3191 - auc_3: 0.8676 - acc: 0.8638 - val_loss: 0.2520 - val_auc_3: 0.6747 - val_acc: 0.9175\n",
      "Epoch 85/10000\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.3180 - auc_3: 0.8689 - acc: 0.8630 - val_loss: 0.2617 - val_auc_3: 0.6894 - val_acc: 0.9134\n",
      "Epoch 86/10000\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.3172 - auc_3: 0.8694 - acc: 0.8642 - val_loss: 0.2732 - val_auc_3: 0.6964 - val_acc: 0.9072\n",
      "Epoch 87/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.3186 - auc_3: 0.8680 - acc: 0.8633 - val_loss: 0.2609 - val_auc_3: 0.6598 - val_acc: 0.9140\n",
      "Epoch 88/10000\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 0.3168 - auc_3: 0.8698 - acc: 0.8645 - val_loss: 0.2648 - val_auc_3: 0.6926 - val_acc: 0.9115\n",
      "Epoch 89/10000\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.3164 - auc_3: 0.8705 - acc: 0.8636 - val_loss: 0.2805 - val_auc_3: 0.6835 - val_acc: 0.9050\n",
      "Epoch 90/10000\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.3173 - auc_3: 0.8695 - acc: 0.8630 - val_loss: 0.2471 - val_auc_3: 0.6820 - val_acc: 0.9219\n",
      "Epoch 91/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.3177 - auc_3: 0.8689 - acc: 0.8636 - val_loss: 0.2688 - val_auc_3: 0.6926 - val_acc: 0.9087\n",
      "Epoch 92/10000\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.3179 - auc_3: 0.8691 - acc: 0.8631 - val_loss: 0.2533 - val_auc_3: 0.6924 - val_acc: 0.9164\n",
      "Epoch 93/10000\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.3168 - auc_3: 0.8701 - acc: 0.8640 - val_loss: 0.2827 - val_auc_3: 0.6731 - val_acc: 0.9058\n",
      "Epoch 94/10000\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.3178 - auc_3: 0.8687 - acc: 0.8639 - val_loss: 0.2490 - val_auc_3: 0.6937 - val_acc: 0.9188\n",
      "Epoch 95/10000\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.3167 - auc_3: 0.8701 - acc: 0.8633 - val_loss: 0.2799 - val_auc_3: 0.6729 - val_acc: 0.9072\n",
      "Epoch 96/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3173 - auc_3: 0.8695 - acc: 0.8644 - val_loss: 0.2574 - val_auc_3: 0.6961 - val_acc: 0.9141\n",
      "Epoch 97/10000\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.3171 - auc_3: 0.8693 - acc: 0.8646 - val_loss: 0.2768 - val_auc_3: 0.7007 - val_acc: 0.9047\n",
      "Epoch 98/10000\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.3165 - auc_3: 0.8701 - acc: 0.8635 - val_loss: 0.2628 - val_auc_3: 0.6682 - val_acc: 0.9147\n",
      "Epoch 99/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3172 - auc_3: 0.8697 - acc: 0.8645 - val_loss: 0.2581 - val_auc_3: 0.6932 - val_acc: 0.9151\n",
      "Epoch 100/10000\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.3172 - auc_3: 0.8701 - acc: 0.8630 - val_loss: 0.2595 - val_auc_3: 0.6734 - val_acc: 0.9173\n",
      "Epoch 101/10000\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.3174 - auc_3: 0.8695 - acc: 0.8645 - val_loss: 0.2651 - val_auc_3: 0.7026 - val_acc: 0.9102\n",
      "Epoch 102/10000\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.3176 - auc_3: 0.8687 - acc: 0.8652 - val_loss: 0.2717 - val_auc_3: 0.6940 - val_acc: 0.9076\n",
      "Epoch 103/10000\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.3181 - auc_3: 0.8686 - acc: 0.8645 - val_loss: 0.2578 - val_auc_3: 0.6597 - val_acc: 0.9186\n",
      "Epoch 104/10000\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.3176 - auc_3: 0.8696 - acc: 0.8632 - val_loss: 0.2556 - val_auc_3: 0.7037 - val_acc: 0.9148\n",
      "Epoch 105/10000\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.3171 - auc_3: 0.8697 - acc: 0.8632 - val_loss: 0.2626 - val_auc_3: 0.6834 - val_acc: 0.9146\n",
      "Epoch 106/10000\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.3168 - auc_3: 0.8698 - acc: 0.8636 - val_loss: 0.2654 - val_auc_3: 0.6896 - val_acc: 0.9098\n",
      "Epoch 107/10000\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 0.3175 - auc_3: 0.8692 - acc: 0.8646 - val_loss: 0.2654 - val_auc_3: 0.6733 - val_acc: 0.9161\n",
      "Epoch 108/10000\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.3157 - auc_3: 0.8711 - acc: 0.8651 - val_loss: 0.2639 - val_auc_3: 0.6928 - val_acc: 0.9111\n",
      "Epoch 109/10000\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 0.3170 - auc_3: 0.8698 - acc: 0.8642 - val_loss: 0.2729 - val_auc_3: 0.6892 - val_acc: 0.9093\n",
      "Epoch 110/10000\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.3171 - auc_3: 0.8694 - acc: 0.8645 - val_loss: 0.2497 - val_auc_3: 0.7007 - val_acc: 0.9209\n",
      "Epoch 111/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 614ms/step - loss: 0.3162 - auc_3: 0.8704 - acc: 0.8641 - val_loss: 0.2659 - val_auc_3: 0.6777 - val_acc: 0.9126\n",
      "Epoch 112/10000\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.3174 - auc_3: 0.8696 - acc: 0.8640 - val_loss: 0.2699 - val_auc_3: 0.6892 - val_acc: 0.9100\n",
      "Epoch 113/10000\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 0.3163 - auc_3: 0.8705 - acc: 0.8629 - val_loss: 0.2725 - val_auc_3: 0.6931 - val_acc: 0.9080\n",
      "Epoch 114/10000\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.3158 - auc_3: 0.8709 - acc: 0.8644 - val_loss: 0.2465 - val_auc_3: 0.6628 - val_acc: 0.9254\n",
      "Epoch 115/10000\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.3172 - auc_3: 0.8696 - acc: 0.8641 - val_loss: 0.2746 - val_auc_3: 0.7092 - val_acc: 0.9056\n",
      "Epoch 116/10000\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.3153 - auc_3: 0.8717 - acc: 0.8650 - val_loss: 0.2583 - val_auc_3: 0.6596 - val_acc: 0.9196\n",
      "Epoch 117/10000\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 0.3173 - auc_3: 0.8692 - acc: 0.8635 - val_loss: 0.2784 - val_auc_3: 0.7153 - val_acc: 0.9028\n",
      "Epoch 118/10000\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.3163 - auc_3: 0.8707 - acc: 0.8639 - val_loss: 0.2640 - val_auc_3: 0.6691 - val_acc: 0.9148\n",
      "Epoch 119/10000\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.3169 - auc_3: 0.8700 - acc: 0.8632 - val_loss: 0.2545 - val_auc_3: 0.6784 - val_acc: 0.9193\n",
      "Epoch 120/10000\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 0.3173 - auc_3: 0.8692 - acc: 0.8631 - val_loss: 0.2648 - val_auc_3: 0.7074 - val_acc: 0.9107\n",
      "Epoch 121/10000\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.3153 - auc_3: 0.8722 - acc: 0.8640 - val_loss: 0.2699 - val_auc_3: 0.6839 - val_acc: 0.9119\n",
      "Epoch 122/10000\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.3160 - auc_3: 0.8711 - acc: 0.8657 - val_loss: 0.2615 - val_auc_3: 0.6845 - val_acc: 0.9151\n",
      "Epoch 123/10000\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.3144 - auc_3: 0.8728 - acc: 0.8654 - val_loss: 0.2773 - val_auc_3: 0.6891 - val_acc: 0.9072\n",
      "Epoch 124/10000\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.3145 - auc_3: 0.8726 - acc: 0.8637 - val_loss: 0.2462 - val_auc_3: 0.6614 - val_acc: 0.9234\n",
      "Epoch 125/10000\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.3145 - auc_3: 0.8721 - acc: 0.8653 - val_loss: 0.2720 - val_auc_3: 0.7008 - val_acc: 0.9098\n",
      "Epoch 126/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3145 - auc_3: 0.8726 - acc: 0.8649 - val_loss: 0.2666 - val_auc_3: 0.6997 - val_acc: 0.9100\n",
      "Epoch 127/10000\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.3158 - auc_3: 0.8716 - acc: 0.8645 - val_loss: 0.2527 - val_auc_3: 0.6833 - val_acc: 0.9199\n",
      "Epoch 128/10000\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.3157 - auc_3: 0.8713 - acc: 0.8645 - val_loss: 0.2591 - val_auc_3: 0.6983 - val_acc: 0.9146\n",
      "Epoch 129/10000\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.3153 - auc_3: 0.8717 - acc: 0.8636 - val_loss: 0.2670 - val_auc_3: 0.6837 - val_acc: 0.9125\n",
      "Epoch 130/10000\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 0.3152 - auc_3: 0.8713 - acc: 0.8645 - val_loss: 0.2626 - val_auc_3: 0.6743 - val_acc: 0.9156\n",
      "Epoch 131/10000\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.3153 - auc_3: 0.8714 - acc: 0.8644 - val_loss: 0.2673 - val_auc_3: 0.6981 - val_acc: 0.9119\n",
      "Epoch 132/10000\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.3152 - auc_3: 0.8715 - acc: 0.8640 - val_loss: 0.2624 - val_auc_3: 0.6931 - val_acc: 0.9129\n",
      "Epoch 133/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.3155 - auc_3: 0.8712 - acc: 0.8634 - val_loss: 0.2706 - val_auc_3: 0.6712 - val_acc: 0.9145\n",
      "Epoch 134/10000\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.3156 - auc_3: 0.8717 - acc: 0.8647 - val_loss: 0.2548 - val_auc_3: 0.6816 - val_acc: 0.9193\n",
      "Epoch 135/10000\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.3145 - auc_3: 0.8720 - acc: 0.8643 - val_loss: 0.2619 - val_auc_3: 0.7021 - val_acc: 0.9129\n",
      "Epoch 136/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.3147 - auc_3: 0.8722 - acc: 0.8644 - val_loss: 0.2685 - val_auc_3: 0.6981 - val_acc: 0.9118\n",
      "Epoch 137/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3147 - auc_3: 0.8720 - acc: 0.8655 - val_loss: 0.2525 - val_auc_3: 0.6781 - val_acc: 0.9204\n",
      "Epoch 138/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.3145 - auc_3: 0.8725 - acc: 0.8642 - val_loss: 0.2629 - val_auc_3: 0.6950 - val_acc: 0.9145\n",
      "Epoch 139/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3157 - auc_3: 0.8705 - acc: 0.8645 - val_loss: 0.2678 - val_auc_3: 0.6772 - val_acc: 0.9117\n",
      "Epoch 140/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.3147 - auc_3: 0.8721 - acc: 0.8645 - val_loss: 0.2718 - val_auc_3: 0.7052 - val_acc: 0.9084\n",
      "Epoch 141/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3154 - auc_3: 0.8716 - acc: 0.8640 - val_loss: 0.2580 - val_auc_3: 0.6903 - val_acc: 0.9152\n",
      "Epoch 142/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.3143 - auc_3: 0.8729 - acc: 0.8643 - val_loss: 0.2574 - val_auc_3: 0.6733 - val_acc: 0.9191\n",
      "Epoch 143/10000\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.3151 - auc_3: 0.8723 - acc: 0.8644 - val_loss: 0.2794 - val_auc_3: 0.7003 - val_acc: 0.9051\n",
      "Epoch 144/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.3147 - auc_3: 0.8726 - acc: 0.8641 - val_loss: 0.2562 - val_auc_3: 0.6808 - val_acc: 0.9181\n",
      "Epoch 145/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.3141 - auc_3: 0.8727 - acc: 0.8655 - val_loss: 0.2770 - val_auc_3: 0.6974 - val_acc: 0.9065\n",
      "Epoch 146/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.3125 - auc_3: 0.8745 - acc: 0.8654 - val_loss: 0.2419 - val_auc_3: 0.6685 - val_acc: 0.9267\n",
      "Epoch 147/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.3144 - auc_3: 0.8725 - acc: 0.8647 - val_loss: 0.2676 - val_auc_3: 0.7029 - val_acc: 0.9113\n",
      "Epoch 148/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.3137 - auc_3: 0.8729 - acc: 0.8652 - val_loss: 0.2660 - val_auc_3: 0.6722 - val_acc: 0.9141\n",
      "Epoch 149/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.3136 - auc_3: 0.8735 - acc: 0.8651 - val_loss: 0.2713 - val_auc_3: 0.6906 - val_acc: 0.9104\n",
      "Epoch 150/10000\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.3144 - auc_3: 0.8722 - acc: 0.8643 - val_loss: 0.2602 - val_auc_3: 0.6971 - val_acc: 0.9153\n",
      "Epoch 151/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.3140 - auc_3: 0.8726 - acc: 0.8650 - val_loss: 0.2523 - val_auc_3: 0.6989 - val_acc: 0.9198\n",
      "Epoch 152/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.3134 - auc_3: 0.8733 - acc: 0.8653 - val_loss: 0.2649 - val_auc_3: 0.6760 - val_acc: 0.9153\n",
      "Epoch 153/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.3136 - auc_3: 0.8735 - acc: 0.8652 - val_loss: 0.2737 - val_auc_3: 0.7079 - val_acc: 0.9072\n",
      "Epoch 154/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.3149 - auc_3: 0.8718 - acc: 0.8648 - val_loss: 0.2683 - val_auc_3: 0.6668 - val_acc: 0.9140\n",
      "Epoch 155/10000\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.3156 - auc_3: 0.8716 - acc: 0.8637 - val_loss: 0.2544 - val_auc_3: 0.7076 - val_acc: 0.9172\n",
      "Epoch 156/10000\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.3153 - auc_3: 0.8720 - acc: 0.8631 - val_loss: 0.2781 - val_auc_3: 0.6917 - val_acc: 0.9069\n",
      "Epoch 157/10000\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 0.3151 - auc_3: 0.8720 - acc: 0.8640 - val_loss: 0.2477 - val_auc_3: 0.6842 - val_acc: 0.9238\n",
      "Epoch 158/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.3152 - auc_3: 0.8719 - acc: 0.8649 - val_loss: 0.2686 - val_auc_3: 0.6856 - val_acc: 0.9124\n",
      "Epoch 159/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 549ms/step - loss: 0.3127 - auc_3: 0.8742 - acc: 0.8653 - val_loss: 0.2610 - val_auc_3: 0.6931 - val_acc: 0.9132\n",
      "Epoch 160/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.3144 - auc_3: 0.8724 - acc: 0.8649 - val_loss: 0.2646 - val_auc_3: 0.6874 - val_acc: 0.9139\n",
      "Epoch 161/10000\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.3125 - auc_3: 0.8747 - acc: 0.8653 - val_loss: 0.2713 - val_auc_3: 0.6968 - val_acc: 0.9094\n",
      "Epoch 162/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.3150 - auc_3: 0.8713 - acc: 0.8650 - val_loss: 0.2502 - val_auc_3: 0.6752 - val_acc: 0.9216\n",
      "Epoch 163/10000\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.3134 - auc_3: 0.8735 - acc: 0.8651 - val_loss: 0.2711 - val_auc_3: 0.6963 - val_acc: 0.9092\n",
      "Epoch 164/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.3124 - auc_3: 0.8743 - acc: 0.8660 - val_loss: 0.2564 - val_auc_3: 0.6734 - val_acc: 0.9195\n",
      "Epoch 165/10000\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.3144 - auc_3: 0.8724 - acc: 0.8642 - val_loss: 0.2729 - val_auc_3: 0.7092 - val_acc: 0.9075\n",
      "Epoch 166/10000\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.3149 - auc_3: 0.8722 - acc: 0.8647 - val_loss: 0.2595 - val_auc_3: 0.6897 - val_acc: 0.9168\n",
      "Epoch 167/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.3135 - auc_3: 0.8739 - acc: 0.8641 - val_loss: 0.2650 - val_auc_3: 0.6843 - val_acc: 0.9142\n",
      "Epoch 168/10000\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.3134 - auc_3: 0.8734 - acc: 0.8643 - val_loss: 0.2566 - val_auc_3: 0.7086 - val_acc: 0.9161\n",
      "Epoch 169/10000\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 0.3132 - auc_3: 0.8737 - acc: 0.8652 - val_loss: 0.2660 - val_auc_3: 0.6776 - val_acc: 0.9141\n",
      "Epoch 170/10000\n",
      "1/1 [==============================] - 1s 732ms/step - loss: 0.3137 - auc_3: 0.8728 - acc: 0.8651 - val_loss: 0.2659 - val_auc_3: 0.6970 - val_acc: 0.9118\n",
      "Epoch 171/10000\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 0.3140 - auc_3: 0.8727 - acc: 0.8651 - val_loss: 0.2677 - val_auc_3: 0.6863 - val_acc: 0.9133\n",
      "Epoch 172/10000\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.3143 - auc_3: 0.8735 - acc: 0.8641 - val_loss: 0.2458 - val_auc_3: 0.6872 - val_acc: 0.9242\n",
      "Epoch 173/10000\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 0.3148 - auc_3: 0.8727 - acc: 0.8649 - val_loss: 0.2811 - val_auc_3: 0.6922 - val_acc: 0.9056\n",
      "Epoch 174/10000\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.3158 - auc_3: 0.8717 - acc: 0.8638 - val_loss: 0.2510 - val_auc_3: 0.7083 - val_acc: 0.9206\n",
      "Epoch 175/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.3143 - auc_3: 0.8730 - acc: 0.8654 - val_loss: 0.2654 - val_auc_3: 0.6988 - val_acc: 0.9127\n",
      "Epoch 176/10000\n",
      "1/1 [==============================] - 1s 709ms/step - loss: 0.3140 - auc_3: 0.8731 - acc: 0.8642 - val_loss: 0.2684 - val_auc_3: 0.6710 - val_acc: 0.9145\n",
      "Epoch 177/10000\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 0.3138 - auc_3: 0.8732 - acc: 0.8651 - val_loss: 0.2545 - val_auc_3: 0.6998 - val_acc: 0.9181\n",
      "Epoch 178/10000\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 0.3142 - auc_3: 0.8721 - acc: 0.8651 - val_loss: 0.2667 - val_auc_3: 0.6886 - val_acc: 0.9137\n",
      "Epoch 179/10000\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 0.3126 - auc_3: 0.8746 - acc: 0.8665 - val_loss: 0.2578 - val_auc_3: 0.6861 - val_acc: 0.9184\n",
      "Epoch 180/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.3140 - auc_3: 0.8730 - acc: 0.8649 - val_loss: 0.2688 - val_auc_3: 0.6868 - val_acc: 0.9124\n",
      "Epoch 181/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.3140 - auc_3: 0.8724 - acc: 0.8654 - val_loss: 0.2588 - val_auc_3: 0.7016 - val_acc: 0.9158\n",
      "Epoch 182/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.3137 - auc_3: 0.8732 - acc: 0.8652 - val_loss: 0.2547 - val_auc_3: 0.6812 - val_acc: 0.9202\n",
      "Epoch 183/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3120 - auc_3: 0.8750 - acc: 0.8661 - val_loss: 0.2612 - val_auc_3: 0.7033 - val_acc: 0.9151\n",
      "Epoch 184/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.3134 - auc_3: 0.8733 - acc: 0.8646 - val_loss: 0.2640 - val_auc_3: 0.6737 - val_acc: 0.9149\n",
      "Epoch 185/10000\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.3134 - auc_3: 0.8739 - acc: 0.8654 - val_loss: 0.2681 - val_auc_3: 0.7005 - val_acc: 0.9115\n",
      "Epoch 186/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3130 - auc_3: 0.8739 - acc: 0.8649 - val_loss: 0.2623 - val_auc_3: 0.6922 - val_acc: 0.9151\n",
      "Epoch 187/10000\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.3137 - auc_3: 0.8731 - acc: 0.8649 - val_loss: 0.2688 - val_auc_3: 0.6824 - val_acc: 0.9126\n",
      "Epoch 188/10000\n",
      "1/1 [==============================] - 1s 709ms/step - loss: 0.3134 - auc_3: 0.8735 - acc: 0.8656 - val_loss: 0.2574 - val_auc_3: 0.6922 - val_acc: 0.9181\n",
      "Epoch 189/10000\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 0.3138 - auc_3: 0.8729 - acc: 0.8645 - val_loss: 0.2603 - val_auc_3: 0.6996 - val_acc: 0.9151\n",
      "Epoch 190/10000\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.3129 - auc_3: 0.8743 - acc: 0.8650 - val_loss: 0.2621 - val_auc_3: 0.6994 - val_acc: 0.9148\n",
      "Epoch 191/10000\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.3143 - auc_3: 0.8719 - acc: 0.8659 - val_loss: 0.2714 - val_auc_3: 0.6858 - val_acc: 0.9117\n",
      "Epoch 192/10000\n",
      "1/1 [==============================] - 1s 752ms/step - loss: 0.3124 - auc_3: 0.8741 - acc: 0.8656 - val_loss: 0.2590 - val_auc_3: 0.6884 - val_acc: 0.9170\n",
      "Epoch 193/10000\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 0.3122 - auc_3: 0.8744 - acc: 0.8654 - val_loss: 0.2631 - val_auc_3: 0.6810 - val_acc: 0.9155\n",
      "Epoch 194/10000\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 0.3134 - auc_3: 0.8735 - acc: 0.8645 - val_loss: 0.2580 - val_auc_3: 0.6955 - val_acc: 0.9169\n",
      "Epoch 195/10000\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.3111 - auc_3: 0.8756 - acc: 0.8653 - val_loss: 0.2557 - val_auc_3: 0.6949 - val_acc: 0.9182\n",
      "Epoch 196/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3125 - auc_3: 0.8741 - acc: 0.8649 - val_loss: 0.2686 - val_auc_3: 0.6869 - val_acc: 0.9125\n",
      "Epoch 197/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.3119 - auc_3: 0.8753 - acc: 0.8660 - val_loss: 0.2630 - val_auc_3: 0.6912 - val_acc: 0.9152\n",
      "Epoch 198/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.3115 - auc_3: 0.8755 - acc: 0.8656 - val_loss: 0.2582 - val_auc_3: 0.6882 - val_acc: 0.9180\n",
      "Epoch 199/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.3115 - auc_3: 0.8753 - acc: 0.8661 - val_loss: 0.2624 - val_auc_3: 0.6906 - val_acc: 0.9146\n",
      "Epoch 200/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.3133 - auc_3: 0.8732 - acc: 0.8657 - val_loss: 0.2670 - val_auc_3: 0.6940 - val_acc: 0.9129\n",
      "Epoch 201/10000\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 0.3123 - auc_3: 0.8745 - acc: 0.8652 - val_loss: 0.2621 - val_auc_3: 0.6916 - val_acc: 0.9157\n",
      "Epoch 202/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3137 - auc_3: 0.8730 - acc: 0.8650 - val_loss: 0.2612 - val_auc_3: 0.6950 - val_acc: 0.9158\n",
      "Epoch 203/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.3134 - auc_3: 0.8738 - acc: 0.8659 - val_loss: 0.2602 - val_auc_3: 0.6900 - val_acc: 0.9170\n",
      "Epoch 204/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3142 - auc_3: 0.8726 - acc: 0.8647 - val_loss: 0.2627 - val_auc_3: 0.6926 - val_acc: 0.9151\n",
      "Epoch 205/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3124 - auc_3: 0.8741 - acc: 0.8663 - val_loss: 0.2617 - val_auc_3: 0.6933 - val_acc: 0.9156\n",
      "Epoch 206/10000\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.3115 - auc_3: 0.8748 - acc: 0.8666 - val_loss: 0.2608 - val_auc_3: 0.6904 - val_acc: 0.9161\n",
      "Epoch 207/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 546ms/step - loss: 0.3119 - auc_3: 0.8759 - acc: 0.8655 - val_loss: 0.2600 - val_auc_3: 0.6941 - val_acc: 0.9161\n",
      "Epoch 208/10000\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.3117 - auc_3: 0.8746 - acc: 0.8661 - val_loss: 0.2614 - val_auc_3: 0.6908 - val_acc: 0.9161\n",
      "Epoch 209/10000\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.3134 - auc_3: 0.8735 - acc: 0.8637 - val_loss: 0.2633 - val_auc_3: 0.6910 - val_acc: 0.9147\n",
      "Epoch 210/10000\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.3130 - auc_3: 0.8743 - acc: 0.8664 - val_loss: 0.2641 - val_auc_3: 0.6996 - val_acc: 0.9142\n",
      "Epoch 211/10000\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.3136 - auc_3: 0.8739 - acc: 0.8647 - val_loss: 0.2580 - val_auc_3: 0.6846 - val_acc: 0.9184\n",
      "Epoch 212/10000\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.3113 - auc_3: 0.8755 - acc: 0.8666 - val_loss: 0.2610 - val_auc_3: 0.6895 - val_acc: 0.9168\n",
      "Epoch 213/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3114 - auc_3: 0.8756 - acc: 0.8648 - val_loss: 0.2641 - val_auc_3: 0.6955 - val_acc: 0.9137\n",
      "Epoch 214/10000\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.3135 - auc_3: 0.8735 - acc: 0.8653 - val_loss: 0.2564 - val_auc_3: 0.6887 - val_acc: 0.9196\n",
      "Epoch 215/10000\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.3135 - auc_3: 0.8732 - acc: 0.8654 - val_loss: 0.2673 - val_auc_3: 0.6944 - val_acc: 0.9124\n",
      "Epoch 216/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.3114 - auc_3: 0.8760 - acc: 0.8649 - val_loss: 0.2588 - val_auc_3: 0.6968 - val_acc: 0.9169\n",
      "Epoch 217/10000\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.3124 - auc_3: 0.8743 - acc: 0.8649 - val_loss: 0.2652 - val_auc_3: 0.6862 - val_acc: 0.9143\n",
      "Epoch 218/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.3133 - auc_3: 0.8735 - acc: 0.8667 - val_loss: 0.2608 - val_auc_3: 0.7047 - val_acc: 0.9149\n",
      "Epoch 219/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.3124 - auc_3: 0.8745 - acc: 0.8659 - val_loss: 0.2556 - val_auc_3: 0.6906 - val_acc: 0.9191\n",
      "Epoch 220/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3122 - auc_3: 0.8750 - acc: 0.8654 - val_loss: 0.2688 - val_auc_3: 0.6888 - val_acc: 0.9124\n",
      "Epoch 221/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.3131 - auc_3: 0.8740 - acc: 0.8652 - val_loss: 0.2549 - val_auc_3: 0.6941 - val_acc: 0.9193\n",
      "Epoch 222/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3122 - auc_3: 0.8747 - acc: 0.8648 - val_loss: 0.2667 - val_auc_3: 0.6922 - val_acc: 0.9134\n",
      "Epoch 223/10000\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.3121 - auc_3: 0.8750 - acc: 0.8655 - val_loss: 0.2579 - val_auc_3: 0.6893 - val_acc: 0.9173\n",
      "Epoch 224/10000\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.3117 - auc_3: 0.8751 - acc: 0.8644 - val_loss: 0.2674 - val_auc_3: 0.7098 - val_acc: 0.9124\n",
      "Epoch 225/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.3110 - auc_3: 0.8763 - acc: 0.8662 - val_loss: 0.2633 - val_auc_3: 0.6746 - val_acc: 0.9165\n",
      "Epoch 226/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.3135 - auc_3: 0.8734 - acc: 0.8650 - val_loss: 0.2583 - val_auc_3: 0.7070 - val_acc: 0.9167\n",
      "Epoch 227/10000\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.3123 - auc_3: 0.8746 - acc: 0.8645 - val_loss: 0.2578 - val_auc_3: 0.6977 - val_acc: 0.9168\n",
      "Epoch 228/10000\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.3126 - auc_3: 0.8742 - acc: 0.8658 - val_loss: 0.2571 - val_auc_3: 0.6852 - val_acc: 0.9200\n",
      "Epoch 229/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3114 - auc_3: 0.8756 - acc: 0.8661 - val_loss: 0.2631 - val_auc_3: 0.6931 - val_acc: 0.9144\n",
      "Epoch 230/10000\n",
      "1/1 [==============================] - 1s 554ms/step - loss: 0.3125 - auc_3: 0.8742 - acc: 0.8658 - val_loss: 0.2700 - val_auc_3: 0.6914 - val_acc: 0.9124\n",
      "Epoch 231/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.3110 - auc_3: 0.8762 - acc: 0.8661 - val_loss: 0.2580 - val_auc_3: 0.7096 - val_acc: 0.9158\n",
      "Epoch 232/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.3115 - auc_3: 0.8754 - acc: 0.8659 - val_loss: 0.2600 - val_auc_3: 0.6785 - val_acc: 0.9191\n",
      "Epoch 233/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.3122 - auc_3: 0.8747 - acc: 0.8658 - val_loss: 0.2590 - val_auc_3: 0.6941 - val_acc: 0.9159\n",
      "Epoch 234/10000\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.3125 - auc_3: 0.8744 - acc: 0.8654 - val_loss: 0.2647 - val_auc_3: 0.6889 - val_acc: 0.9150\n",
      "Epoch 235/10000\n",
      "1/1 [==============================] - 1s 548ms/step - loss: 0.3125 - auc_3: 0.8743 - acc: 0.8658 - val_loss: 0.2582 - val_auc_3: 0.7091 - val_acc: 0.9170\n",
      "Epoch 236/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.3110 - auc_3: 0.8762 - acc: 0.8655 - val_loss: 0.2655 - val_auc_3: 0.6968 - val_acc: 0.9133\n",
      "Epoch 237/10000\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.3136 - auc_3: 0.8737 - acc: 0.8651 - val_loss: 0.2607 - val_auc_3: 0.7021 - val_acc: 0.9153\n",
      "Epoch 238/10000\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.3124 - auc_3: 0.8742 - acc: 0.8661 - val_loss: 0.2646 - val_auc_3: 0.6896 - val_acc: 0.9142\n",
      "Epoch 239/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.3130 - auc_3: 0.8738 - acc: 0.8657 - val_loss: 0.2530 - val_auc_3: 0.6924 - val_acc: 0.9198\n",
      "Epoch 240/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.3112 - auc_3: 0.8762 - acc: 0.8661 - val_loss: 0.2553 - val_auc_3: 0.6914 - val_acc: 0.9205\n",
      "Epoch 241/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3117 - auc_3: 0.8753 - acc: 0.8664 - val_loss: 0.2556 - val_auc_3: 0.7015 - val_acc: 0.9176\n",
      "Epoch 242/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.3119 - auc_3: 0.8757 - acc: 0.8661 - val_loss: 0.2775 - val_auc_3: 0.6870 - val_acc: 0.9089\n",
      "Epoch 243/10000\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.3110 - auc_3: 0.8759 - acc: 0.8669 - val_loss: 0.2572 - val_auc_3: 0.6918 - val_acc: 0.9187\n",
      "Epoch 244/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3116 - auc_3: 0.8751 - acc: 0.8652 - val_loss: 0.2552 - val_auc_3: 0.6826 - val_acc: 0.9177\n",
      "Epoch 245/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3121 - auc_3: 0.8750 - acc: 0.8660 - val_loss: 0.2727 - val_auc_3: 0.7067 - val_acc: 0.9105\n",
      "Epoch 246/10000\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.3130 - auc_3: 0.8742 - acc: 0.8655 - val_loss: 0.2730 - val_auc_3: 0.6775 - val_acc: 0.9113\n",
      "Evaluating model.\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4087 - auc_3: 0.7686 - acc: 0.8201\n",
      "Done.\n",
      "Test loss: 0.40866854786872864\n",
      "Test accuracy: 0.7686364650726318\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 8)            0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " gcn_conv_20 (GCNConv)          (None, 64)           576         ['dropout_20[0][0]',             \n",
      "                                                                  'input_10[0][0]']               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_21 (Dropout)           (None, 64)           0           ['gcn_conv_20[0][0]']            \n",
      "                                                                                                  \n",
      " gcn_conv_21 (GCNConv)          (None, 64)           4160        ['dropout_21[0][0]',             \n",
      "                                                                  'input_10[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 64)           0           ['gcn_conv_21[0][0]']            \n",
      "                                                                                                  \n",
      " gcn_conv_24 (GCNConv)          (None, 1)            65          ['dropout_22[0][0]',             \n",
      "                                                                  'input_10[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,801\n",
      "Trainable params: 4,801\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6374 - auc_4: 0.7603 - acc: 0.7092WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=SparseTensorSpec(TensorShape([None, None]), tf.float64), name='input_10', description=\"created by layer 'input_10'\"), but it was called on an input with incompatible shape (None, None, None).\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6374 - auc_4: 0.7603 - acc: 0.7092 - val_loss: 0.4032 - val_auc_4: 0.5338 - val_acc: 0.9236\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.4799 - auc_4: 0.6317 - acc: 0.8223 - val_loss: 0.3195 - val_auc_4: 0.5408 - val_acc: 0.9237\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.4470 - auc_4: 0.6585 - acc: 0.8228 - val_loss: 0.2923 - val_auc_4: 0.5634 - val_acc: 0.9225\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.4201 - auc_4: 0.7381 - acc: 0.8235 - val_loss: 0.2815 - val_auc_4: 0.5748 - val_acc: 0.9231\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.3923 - auc_4: 0.7856 - acc: 0.8318 - val_loss: 0.2895 - val_auc_4: 0.5803 - val_acc: 0.9166\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.3721 - auc_4: 0.8083 - acc: 0.8463 - val_loss: 0.2922 - val_auc_4: 0.5935 - val_acc: 0.9112\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3637 - auc_4: 0.8225 - acc: 0.8510 - val_loss: 0.3032 - val_auc_4: 0.5897 - val_acc: 0.9047\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.3692 - auc_4: 0.8258 - acc: 0.8467 - val_loss: 0.3143 - val_auc_4: 0.5941 - val_acc: 0.8988\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3722 - auc_4: 0.8323 - acc: 0.8443 - val_loss: 0.3072 - val_auc_4: 0.5978 - val_acc: 0.9010\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.3709 - auc_4: 0.8349 - acc: 0.8444 - val_loss: 0.3220 - val_auc_4: 0.5920 - val_acc: 0.8944\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3652 - auc_4: 0.8386 - acc: 0.8463 - val_loss: 0.3127 - val_auc_4: 0.5952 - val_acc: 0.8989\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3584 - auc_4: 0.8401 - acc: 0.8489 - val_loss: 0.3047 - val_auc_4: 0.6009 - val_acc: 0.9037\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.3532 - auc_4: 0.8407 - acc: 0.8502 - val_loss: 0.3036 - val_auc_4: 0.6030 - val_acc: 0.9042\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.3504 - auc_4: 0.8401 - acc: 0.8530 - val_loss: 0.3028 - val_auc_4: 0.6156 - val_acc: 0.9035\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.3463 - auc_4: 0.8417 - acc: 0.8530 - val_loss: 0.2987 - val_auc_4: 0.5943 - val_acc: 0.9115\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 0.3472 - auc_4: 0.8408 - acc: 0.8521 - val_loss: 0.2962 - val_auc_4: 0.6118 - val_acc: 0.9115\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3456 - auc_4: 0.8414 - acc: 0.8537 - val_loss: 0.2970 - val_auc_4: 0.6097 - val_acc: 0.9122\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.3462 - auc_4: 0.8402 - acc: 0.8540 - val_loss: 0.2984 - val_auc_4: 0.6147 - val_acc: 0.9135\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3476 - auc_4: 0.8396 - acc: 0.8525 - val_loss: 0.2953 - val_auc_4: 0.6074 - val_acc: 0.9156\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 0.3464 - auc_4: 0.8415 - acc: 0.8545 - val_loss: 0.2966 - val_auc_4: 0.6186 - val_acc: 0.9151\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.3463 - auc_4: 0.8411 - acc: 0.8544 - val_loss: 0.3125 - val_auc_4: 0.6326 - val_acc: 0.9054\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.3439 - auc_4: 0.8450 - acc: 0.8551 - val_loss: 0.2951 - val_auc_4: 0.6150 - val_acc: 0.9159\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.3450 - auc_4: 0.8430 - acc: 0.8548 - val_loss: 0.2926 - val_auc_4: 0.6243 - val_acc: 0.9155\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.3440 - auc_4: 0.8440 - acc: 0.8545 - val_loss: 0.3020 - val_auc_4: 0.6229 - val_acc: 0.9075\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.3430 - auc_4: 0.8443 - acc: 0.8540 - val_loss: 0.2816 - val_auc_4: 0.6421 - val_acc: 0.9162\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.3428 - auc_4: 0.8442 - acc: 0.8552 - val_loss: 0.2941 - val_auc_4: 0.6294 - val_acc: 0.9076\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3406 - auc_4: 0.8463 - acc: 0.8548 - val_loss: 0.2932 - val_auc_4: 0.6225 - val_acc: 0.9071\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3392 - auc_4: 0.8475 - acc: 0.8554 - val_loss: 0.2940 - val_auc_4: 0.6320 - val_acc: 0.9029\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.3414 - auc_4: 0.8450 - acc: 0.8544 - val_loss: 0.2830 - val_auc_4: 0.6328 - val_acc: 0.9089\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.3399 - auc_4: 0.8469 - acc: 0.8544 - val_loss: 0.2866 - val_auc_4: 0.6199 - val_acc: 0.9082\n",
      "Epoch 31/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 565ms/step - loss: 0.3402 - auc_4: 0.8473 - acc: 0.8548 - val_loss: 0.2788 - val_auc_4: 0.6341 - val_acc: 0.9079\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.3401 - auc_4: 0.8476 - acc: 0.8544 - val_loss: 0.2930 - val_auc_4: 0.6328 - val_acc: 0.9023\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.3398 - auc_4: 0.8475 - acc: 0.8548 - val_loss: 0.2915 - val_auc_4: 0.6403 - val_acc: 0.9023\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3388 - auc_4: 0.8488 - acc: 0.8546 - val_loss: 0.2772 - val_auc_4: 0.6339 - val_acc: 0.9089\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.3397 - auc_4: 0.8476 - acc: 0.8538 - val_loss: 0.2961 - val_auc_4: 0.6125 - val_acc: 0.9040\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.3383 - auc_4: 0.8488 - acc: 0.8536 - val_loss: 0.2847 - val_auc_4: 0.6513 - val_acc: 0.9036\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.3395 - auc_4: 0.8475 - acc: 0.8541 - val_loss: 0.2940 - val_auc_4: 0.6231 - val_acc: 0.9022\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.3385 - auc_4: 0.8486 - acc: 0.8542 - val_loss: 0.2812 - val_auc_4: 0.6391 - val_acc: 0.9086\n",
      "Epoch 39/10000\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.3393 - auc_4: 0.8480 - acc: 0.8546 - val_loss: 0.2958 - val_auc_4: 0.6424 - val_acc: 0.9002\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.3372 - auc_4: 0.8488 - acc: 0.8552 - val_loss: 0.2863 - val_auc_4: 0.6398 - val_acc: 0.9066\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.3381 - auc_4: 0.8483 - acc: 0.8552 - val_loss: 0.2871 - val_auc_4: 0.6330 - val_acc: 0.9080\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3375 - auc_4: 0.8492 - acc: 0.8562 - val_loss: 0.2934 - val_auc_4: 0.6379 - val_acc: 0.9019\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.3363 - auc_4: 0.8501 - acc: 0.8552 - val_loss: 0.2786 - val_auc_4: 0.6545 - val_acc: 0.9096\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.3376 - auc_4: 0.8489 - acc: 0.8549 - val_loss: 0.2797 - val_auc_4: 0.6257 - val_acc: 0.9119\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 0.3379 - auc_4: 0.8485 - acc: 0.8563 - val_loss: 0.2866 - val_auc_4: 0.6373 - val_acc: 0.9061\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3371 - auc_4: 0.8490 - acc: 0.8558 - val_loss: 0.2830 - val_auc_4: 0.6444 - val_acc: 0.9090\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.3383 - auc_4: 0.8481 - acc: 0.8545 - val_loss: 0.2790 - val_auc_4: 0.6426 - val_acc: 0.9111\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.3368 - auc_4: 0.8496 - acc: 0.8556 - val_loss: 0.2867 - val_auc_4: 0.6476 - val_acc: 0.9070\n",
      "Epoch 49/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3363 - auc_4: 0.8499 - acc: 0.8567 - val_loss: 0.2814 - val_auc_4: 0.6336 - val_acc: 0.9097\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 0.3360 - auc_4: 0.8503 - acc: 0.8557 - val_loss: 0.2819 - val_auc_4: 0.6352 - val_acc: 0.9107\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.3356 - auc_4: 0.8511 - acc: 0.8561 - val_loss: 0.2933 - val_auc_4: 0.6565 - val_acc: 0.9022\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3339 - auc_4: 0.8522 - acc: 0.8571 - val_loss: 0.2857 - val_auc_4: 0.6228 - val_acc: 0.9096\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.3356 - auc_4: 0.8504 - acc: 0.8560 - val_loss: 0.2772 - val_auc_4: 0.6472 - val_acc: 0.9115\n",
      "Epoch 54/10000\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.3360 - auc_4: 0.8502 - acc: 0.8561 - val_loss: 0.2849 - val_auc_4: 0.6163 - val_acc: 0.9105\n",
      "Epoch 55/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.3340 - auc_4: 0.8522 - acc: 0.8551 - val_loss: 0.2844 - val_auc_4: 0.6627 - val_acc: 0.9051\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.3373 - auc_4: 0.8486 - acc: 0.8554 - val_loss: 0.2857 - val_auc_4: 0.6366 - val_acc: 0.9065\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3356 - auc_4: 0.8497 - acc: 0.8570 - val_loss: 0.2851 - val_auc_4: 0.6401 - val_acc: 0.9087\n",
      "Epoch 58/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3365 - auc_4: 0.8496 - acc: 0.8565 - val_loss: 0.2723 - val_auc_4: 0.6286 - val_acc: 0.9161\n",
      "Epoch 59/10000\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.3340 - auc_4: 0.8527 - acc: 0.8561 - val_loss: 0.2918 - val_auc_4: 0.6485 - val_acc: 0.9041\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.3354 - auc_4: 0.8505 - acc: 0.8557 - val_loss: 0.2814 - val_auc_4: 0.6266 - val_acc: 0.9117\n",
      "Epoch 61/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.3354 - auc_4: 0.8513 - acc: 0.8552 - val_loss: 0.2971 - val_auc_4: 0.6485 - val_acc: 0.9012\n",
      "Epoch 62/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.3351 - auc_4: 0.8509 - acc: 0.8564 - val_loss: 0.2720 - val_auc_4: 0.6362 - val_acc: 0.9178\n",
      "Epoch 63/10000\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.3354 - auc_4: 0.8506 - acc: 0.8566 - val_loss: 0.2772 - val_auc_4: 0.6464 - val_acc: 0.9124\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.3349 - auc_4: 0.8514 - acc: 0.8568 - val_loss: 0.2721 - val_auc_4: 0.6609 - val_acc: 0.9144\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.3365 - auc_4: 0.8497 - acc: 0.8555 - val_loss: 0.3022 - val_auc_4: 0.6290 - val_acc: 0.9009\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.3349 - auc_4: 0.8511 - acc: 0.8582 - val_loss: 0.2719 - val_auc_4: 0.6286 - val_acc: 0.9181\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3357 - auc_4: 0.8500 - acc: 0.8566 - val_loss: 0.2832 - val_auc_4: 0.6628 - val_acc: 0.9079\n",
      "Epoch 68/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3357 - auc_4: 0.8499 - acc: 0.8572 - val_loss: 0.2754 - val_auc_4: 0.6474 - val_acc: 0.9135\n",
      "Epoch 69/10000\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.3357 - auc_4: 0.8504 - acc: 0.8561 - val_loss: 0.2934 - val_auc_4: 0.6415 - val_acc: 0.9055\n",
      "Epoch 70/10000\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.3346 - auc_4: 0.8514 - acc: 0.8575 - val_loss: 0.2839 - val_auc_4: 0.6345 - val_acc: 0.9101\n",
      "Epoch 71/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3336 - auc_4: 0.8522 - acc: 0.8570 - val_loss: 0.2714 - val_auc_4: 0.6253 - val_acc: 0.9180\n",
      "Epoch 72/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.3339 - auc_4: 0.8522 - acc: 0.8571 - val_loss: 0.2984 - val_auc_4: 0.6414 - val_acc: 0.9008\n",
      "Epoch 73/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.3334 - auc_4: 0.8530 - acc: 0.8571 - val_loss: 0.2673 - val_auc_4: 0.6255 - val_acc: 0.9196\n",
      "Epoch 74/10000\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.3331 - auc_4: 0.8530 - acc: 0.8574 - val_loss: 0.2833 - val_auc_4: 0.6644 - val_acc: 0.9078\n",
      "Epoch 75/10000\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.3334 - auc_4: 0.8522 - acc: 0.8583 - val_loss: 0.2662 - val_auc_4: 0.6356 - val_acc: 0.9190\n",
      "Epoch 76/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.3340 - auc_4: 0.8514 - acc: 0.8572 - val_loss: 0.2976 - val_auc_4: 0.6339 - val_acc: 0.9037\n",
      "Epoch 77/10000\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.3342 - auc_4: 0.8513 - acc: 0.8571 - val_loss: 0.2750 - val_auc_4: 0.6657 - val_acc: 0.9119\n",
      "Epoch 78/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3334 - auc_4: 0.8527 - acc: 0.8570 - val_loss: 0.2885 - val_auc_4: 0.6250 - val_acc: 0.9092\n",
      "Epoch 79/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 589ms/step - loss: 0.3353 - auc_4: 0.8510 - acc: 0.8556 - val_loss: 0.2761 - val_auc_4: 0.6550 - val_acc: 0.9131\n",
      "Epoch 80/10000\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.3327 - auc_4: 0.8535 - acc: 0.8583 - val_loss: 0.2798 - val_auc_4: 0.6537 - val_acc: 0.9106\n",
      "Epoch 81/10000\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.3331 - auc_4: 0.8532 - acc: 0.8565 - val_loss: 0.2875 - val_auc_4: 0.6212 - val_acc: 0.9095\n",
      "Epoch 82/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.3307 - auc_4: 0.8554 - acc: 0.8593 - val_loss: 0.2741 - val_auc_4: 0.6626 - val_acc: 0.9128\n",
      "Epoch 83/10000\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.3327 - auc_4: 0.8537 - acc: 0.8578 - val_loss: 0.2760 - val_auc_4: 0.6282 - val_acc: 0.9175\n",
      "Epoch 84/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3320 - auc_4: 0.8540 - acc: 0.8585 - val_loss: 0.2848 - val_auc_4: 0.6461 - val_acc: 0.9082\n",
      "Epoch 85/10000\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.3320 - auc_4: 0.8540 - acc: 0.8586 - val_loss: 0.2854 - val_auc_4: 0.6475 - val_acc: 0.9108\n",
      "Epoch 86/10000\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.3335 - auc_4: 0.8527 - acc: 0.8579 - val_loss: 0.2763 - val_auc_4: 0.6382 - val_acc: 0.9132\n",
      "Epoch 87/10000\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.3335 - auc_4: 0.8529 - acc: 0.8577 - val_loss: 0.2724 - val_auc_4: 0.6468 - val_acc: 0.9145\n",
      "Epoch 88/10000\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.3339 - auc_4: 0.8529 - acc: 0.8562 - val_loss: 0.2880 - val_auc_4: 0.6525 - val_acc: 0.9087\n",
      "Epoch 89/10000\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.3326 - auc_4: 0.8533 - acc: 0.8576 - val_loss: 0.2658 - val_auc_4: 0.6526 - val_acc: 0.9195\n",
      "Epoch 90/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.3336 - auc_4: 0.8529 - acc: 0.8567 - val_loss: 0.2897 - val_auc_4: 0.6276 - val_acc: 0.9091\n",
      "Epoch 91/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.3343 - auc_4: 0.8519 - acc: 0.8569 - val_loss: 0.2801 - val_auc_4: 0.6473 - val_acc: 0.9114\n",
      "Epoch 92/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3335 - auc_4: 0.8524 - acc: 0.8576 - val_loss: 0.2735 - val_auc_4: 0.6368 - val_acc: 0.9176\n",
      "Epoch 93/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.3339 - auc_4: 0.8527 - acc: 0.8574 - val_loss: 0.2819 - val_auc_4: 0.6554 - val_acc: 0.9098\n",
      "Epoch 94/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.3308 - auc_4: 0.8558 - acc: 0.8589 - val_loss: 0.2863 - val_auc_4: 0.6445 - val_acc: 0.9090\n",
      "Epoch 95/10000\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.3326 - auc_4: 0.8533 - acc: 0.8582 - val_loss: 0.2682 - val_auc_4: 0.6334 - val_acc: 0.9202\n",
      "Epoch 96/10000\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.3321 - auc_4: 0.8542 - acc: 0.8586 - val_loss: 0.2795 - val_auc_4: 0.6526 - val_acc: 0.9117\n",
      "Epoch 97/10000\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 0.3319 - auc_4: 0.8547 - acc: 0.8575 - val_loss: 0.2887 - val_auc_4: 0.6452 - val_acc: 0.9089\n",
      "Epoch 98/10000\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 0.3325 - auc_4: 0.8535 - acc: 0.8573 - val_loss: 0.2750 - val_auc_4: 0.6494 - val_acc: 0.9146\n",
      "Epoch 99/10000\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.3332 - auc_4: 0.8528 - acc: 0.8574 - val_loss: 0.2804 - val_auc_4: 0.6492 - val_acc: 0.9120\n",
      "Epoch 100/10000\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.3325 - auc_4: 0.8533 - acc: 0.8588 - val_loss: 0.2755 - val_auc_4: 0.6457 - val_acc: 0.9135\n",
      "Epoch 101/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3334 - auc_4: 0.8532 - acc: 0.8582 - val_loss: 0.2869 - val_auc_4: 0.6360 - val_acc: 0.9111\n",
      "Epoch 102/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.3325 - auc_4: 0.8541 - acc: 0.8578 - val_loss: 0.2666 - val_auc_4: 0.6611 - val_acc: 0.9160\n",
      "Epoch 103/10000\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 0.3328 - auc_4: 0.8536 - acc: 0.8566 - val_loss: 0.2851 - val_auc_4: 0.6373 - val_acc: 0.9118\n",
      "Epoch 104/10000\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.3334 - auc_4: 0.8532 - acc: 0.8574 - val_loss: 0.2893 - val_auc_4: 0.6262 - val_acc: 0.9094\n",
      "Epoch 105/10000\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 0.3314 - auc_4: 0.8549 - acc: 0.8579 - val_loss: 0.2617 - val_auc_4: 0.6658 - val_acc: 0.9191\n",
      "Epoch 106/10000\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 0.3337 - auc_4: 0.8521 - acc: 0.8579 - val_loss: 0.2859 - val_auc_4: 0.6550 - val_acc: 0.9094\n",
      "Epoch 107/10000\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 0.3328 - auc_4: 0.8535 - acc: 0.8580 - val_loss: 0.2810 - val_auc_4: 0.6429 - val_acc: 0.9123\n",
      "Epoch 108/10000\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 0.3333 - auc_4: 0.8528 - acc: 0.8570 - val_loss: 0.2878 - val_auc_4: 0.6456 - val_acc: 0.9085\n",
      "Epoch 109/10000\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 0.3310 - auc_4: 0.8554 - acc: 0.8584 - val_loss: 0.2681 - val_auc_4: 0.6213 - val_acc: 0.9211\n",
      "Epoch 110/10000\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.3315 - auc_4: 0.8547 - acc: 0.8578 - val_loss: 0.2851 - val_auc_4: 0.6569 - val_acc: 0.9088\n",
      "Epoch 111/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.3311 - auc_4: 0.8555 - acc: 0.8587 - val_loss: 0.2675 - val_auc_4: 0.6582 - val_acc: 0.9186\n",
      "Epoch 112/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.3323 - auc_4: 0.8537 - acc: 0.8575 - val_loss: 0.2884 - val_auc_4: 0.6425 - val_acc: 0.9075\n",
      "Epoch 113/10000\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.3308 - auc_4: 0.8557 - acc: 0.8590 - val_loss: 0.2710 - val_auc_4: 0.6482 - val_acc: 0.9177\n",
      "Epoch 114/10000\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.3321 - auc_4: 0.8549 - acc: 0.8577 - val_loss: 0.2789 - val_auc_4: 0.6342 - val_acc: 0.9149\n",
      "Epoch 115/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.3321 - auc_4: 0.8541 - acc: 0.8574 - val_loss: 0.2957 - val_auc_4: 0.6389 - val_acc: 0.9050\n",
      "Epoch 116/10000\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.3319 - auc_4: 0.8543 - acc: 0.8583 - val_loss: 0.2794 - val_auc_4: 0.6621 - val_acc: 0.9129\n",
      "Epoch 117/10000\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.3319 - auc_4: 0.8549 - acc: 0.8581 - val_loss: 0.2803 - val_auc_4: 0.6498 - val_acc: 0.9128\n",
      "Epoch 118/10000\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.3315 - auc_4: 0.8548 - acc: 0.8580 - val_loss: 0.2902 - val_auc_4: 0.6452 - val_acc: 0.9071\n",
      "Epoch 119/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.3327 - auc_4: 0.8548 - acc: 0.8571 - val_loss: 0.2785 - val_auc_4: 0.6491 - val_acc: 0.9138\n",
      "Epoch 120/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3309 - auc_4: 0.8554 - acc: 0.8600 - val_loss: 0.2625 - val_auc_4: 0.6372 - val_acc: 0.9217\n",
      "Epoch 121/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3331 - auc_4: 0.8535 - acc: 0.8579 - val_loss: 0.2839 - val_auc_4: 0.6494 - val_acc: 0.9108\n",
      "Epoch 122/10000\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 0.3301 - auc_4: 0.8561 - acc: 0.8585 - val_loss: 0.2955 - val_auc_4: 0.6483 - val_acc: 0.9058\n",
      "Epoch 123/10000\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.3305 - auc_4: 0.8557 - acc: 0.8580 - val_loss: 0.2574 - val_auc_4: 0.6487 - val_acc: 0.9228\n",
      "Epoch 124/10000\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.3319 - auc_4: 0.8550 - acc: 0.8578 - val_loss: 0.2954 - val_auc_4: 0.6460 - val_acc: 0.9057\n",
      "Epoch 125/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.3311 - auc_4: 0.8556 - acc: 0.8591 - val_loss: 0.2647 - val_auc_4: 0.6454 - val_acc: 0.9191\n",
      "Epoch 126/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.3310 - auc_4: 0.8552 - acc: 0.8582 - val_loss: 0.2724 - val_auc_4: 0.6419 - val_acc: 0.9162\n",
      "Epoch 127/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3305 - auc_4: 0.8561 - acc: 0.8578 - val_loss: 0.2868 - val_auc_4: 0.6338 - val_acc: 0.9112\n",
      "Epoch 128/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.3299 - auc_4: 0.8564 - acc: 0.8583 - val_loss: 0.2746 - val_auc_4: 0.6670 - val_acc: 0.9132\n",
      "Epoch 129/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.3314 - auc_4: 0.8559 - acc: 0.8580 - val_loss: 0.2859 - val_auc_4: 0.6304 - val_acc: 0.9108\n",
      "Epoch 130/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3311 - auc_4: 0.8560 - acc: 0.8580 - val_loss: 0.2766 - val_auc_4: 0.6593 - val_acc: 0.9128\n",
      "Epoch 131/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3313 - auc_4: 0.8550 - acc: 0.8582 - val_loss: 0.2767 - val_auc_4: 0.6549 - val_acc: 0.9137\n",
      "Epoch 132/10000\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.3294 - auc_4: 0.8570 - acc: 0.8584 - val_loss: 0.2783 - val_auc_4: 0.6497 - val_acc: 0.9117\n",
      "Epoch 133/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.3320 - auc_4: 0.8544 - acc: 0.8584 - val_loss: 0.2598 - val_auc_4: 0.6234 - val_acc: 0.9247\n",
      "Epoch 134/10000\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 0.3322 - auc_4: 0.8541 - acc: 0.8577 - val_loss: 0.3012 - val_auc_4: 0.6531 - val_acc: 0.8996\n",
      "Epoch 135/10000\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.3304 - auc_4: 0.8559 - acc: 0.8579 - val_loss: 0.2717 - val_auc_4: 0.6507 - val_acc: 0.9169\n",
      "Epoch 136/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.3307 - auc_4: 0.8559 - acc: 0.8579 - val_loss: 0.2826 - val_auc_4: 0.6564 - val_acc: 0.9099\n",
      "Epoch 137/10000\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.3314 - auc_4: 0.8546 - acc: 0.8590 - val_loss: 0.2901 - val_auc_4: 0.6551 - val_acc: 0.9067\n",
      "Epoch 138/10000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.3315 - auc_4: 0.8556 - acc: 0.8569 - val_loss: 0.2803 - val_auc_4: 0.6264 - val_acc: 0.9127\n",
      "Epoch 139/10000\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.3300 - auc_4: 0.8564 - acc: 0.8591 - val_loss: 0.2749 - val_auc_4: 0.6532 - val_acc: 0.9152\n",
      "Epoch 140/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.3297 - auc_4: 0.8562 - acc: 0.8584 - val_loss: 0.2815 - val_auc_4: 0.6629 - val_acc: 0.9096\n",
      "Epoch 141/10000\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.3311 - auc_4: 0.8561 - acc: 0.8577 - val_loss: 0.2765 - val_auc_4: 0.6294 - val_acc: 0.9157\n",
      "Epoch 142/10000\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.3305 - auc_4: 0.8563 - acc: 0.8575 - val_loss: 0.2797 - val_auc_4: 0.6499 - val_acc: 0.9139\n",
      "Epoch 143/10000\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.3293 - auc_4: 0.8573 - acc: 0.8599 - val_loss: 0.2813 - val_auc_4: 0.6508 - val_acc: 0.9104\n",
      "Epoch 144/10000\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 0.3303 - auc_4: 0.8566 - acc: 0.8576 - val_loss: 0.2805 - val_auc_4: 0.6427 - val_acc: 0.9129\n",
      "Epoch 145/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.3283 - auc_4: 0.8584 - acc: 0.8598 - val_loss: 0.2717 - val_auc_4: 0.6549 - val_acc: 0.9148\n",
      "Epoch 146/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.3308 - auc_4: 0.8561 - acc: 0.8579 - val_loss: 0.2804 - val_auc_4: 0.6479 - val_acc: 0.9117\n",
      "Epoch 147/10000\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 0.3299 - auc_4: 0.8567 - acc: 0.8591 - val_loss: 0.2940 - val_auc_4: 0.6439 - val_acc: 0.9054\n",
      "Epoch 148/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.3300 - auc_4: 0.8570 - acc: 0.8586 - val_loss: 0.2701 - val_auc_4: 0.6395 - val_acc: 0.9183\n",
      "Epoch 149/10000\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 0.3312 - auc_4: 0.8552 - acc: 0.8591 - val_loss: 0.2857 - val_auc_4: 0.6600 - val_acc: 0.9083\n",
      "Epoch 150/10000\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.3301 - auc_4: 0.8568 - acc: 0.8586 - val_loss: 0.2587 - val_auc_4: 0.6459 - val_acc: 0.9233\n",
      "Epoch 151/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.3295 - auc_4: 0.8569 - acc: 0.8591 - val_loss: 0.2955 - val_auc_4: 0.6559 - val_acc: 0.9037\n",
      "Epoch 152/10000\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.3319 - auc_4: 0.8549 - acc: 0.8574 - val_loss: 0.2741 - val_auc_4: 0.6522 - val_acc: 0.9145\n",
      "Epoch 153/10000\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.3316 - auc_4: 0.8555 - acc: 0.8575 - val_loss: 0.2951 - val_auc_4: 0.6419 - val_acc: 0.9046\n",
      "Epoch 154/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.3299 - auc_4: 0.8571 - acc: 0.8588 - val_loss: 0.2643 - val_auc_4: 0.6489 - val_acc: 0.9196\n",
      "Epoch 155/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3283 - auc_4: 0.8582 - acc: 0.8590 - val_loss: 0.2839 - val_auc_4: 0.6434 - val_acc: 0.9106\n",
      "Epoch 156/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3300 - auc_4: 0.8567 - acc: 0.8589 - val_loss: 0.2744 - val_auc_4: 0.6501 - val_acc: 0.9145\n",
      "Epoch 157/10000\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.3307 - auc_4: 0.8554 - acc: 0.8590 - val_loss: 0.2831 - val_auc_4: 0.6364 - val_acc: 0.9129\n",
      "Epoch 158/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3309 - auc_4: 0.8559 - acc: 0.8580 - val_loss: 0.2879 - val_auc_4: 0.6581 - val_acc: 0.9076\n",
      "Epoch 159/10000\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.3297 - auc_4: 0.8573 - acc: 0.8587 - val_loss: 0.2731 - val_auc_4: 0.6513 - val_acc: 0.9149\n",
      "Epoch 160/10000\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.3310 - auc_4: 0.8558 - acc: 0.8579 - val_loss: 0.2622 - val_auc_4: 0.6491 - val_acc: 0.9222\n",
      "Epoch 161/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.3297 - auc_4: 0.8568 - acc: 0.8584 - val_loss: 0.2911 - val_auc_4: 0.6445 - val_acc: 0.9063\n",
      "Epoch 162/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3298 - auc_4: 0.8571 - acc: 0.8600 - val_loss: 0.2737 - val_auc_4: 0.6507 - val_acc: 0.9143\n",
      "Epoch 163/10000\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 0.3289 - auc_4: 0.8574 - acc: 0.8589 - val_loss: 0.2872 - val_auc_4: 0.6503 - val_acc: 0.9093\n",
      "Epoch 164/10000\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 0.3292 - auc_4: 0.8569 - acc: 0.8591 - val_loss: 0.2716 - val_auc_4: 0.6478 - val_acc: 0.9172\n",
      "Epoch 165/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3289 - auc_4: 0.8581 - acc: 0.8588 - val_loss: 0.2809 - val_auc_4: 0.6409 - val_acc: 0.9122\n",
      "Epoch 166/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3276 - auc_4: 0.8597 - acc: 0.8600 - val_loss: 0.2919 - val_auc_4: 0.6589 - val_acc: 0.9049\n",
      "Epoch 167/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.3297 - auc_4: 0.8569 - acc: 0.8590 - val_loss: 0.2600 - val_auc_4: 0.6546 - val_acc: 0.9210\n",
      "Epoch 168/10000\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.3282 - auc_4: 0.8587 - acc: 0.8593 - val_loss: 0.2921 - val_auc_4: 0.6381 - val_acc: 0.9069\n",
      "Epoch 169/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3301 - auc_4: 0.8570 - acc: 0.8587 - val_loss: 0.2742 - val_auc_4: 0.6595 - val_acc: 0.9149\n",
      "Epoch 170/10000\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.3294 - auc_4: 0.8573 - acc: 0.8591 - val_loss: 0.2728 - val_auc_4: 0.6562 - val_acc: 0.9142\n",
      "Epoch 171/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.3286 - auc_4: 0.8582 - acc: 0.8577 - val_loss: 0.2815 - val_auc_4: 0.6433 - val_acc: 0.9110\n",
      "Epoch 172/10000\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 0.3275 - auc_4: 0.8596 - acc: 0.8599 - val_loss: 0.2751 - val_auc_4: 0.6543 - val_acc: 0.9141\n",
      "Epoch 173/10000\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.3287 - auc_4: 0.8586 - acc: 0.8589 - val_loss: 0.2871 - val_auc_4: 0.6434 - val_acc: 0.9088\n",
      "Epoch 174/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.3287 - auc_4: 0.8586 - acc: 0.8587 - val_loss: 0.2679 - val_auc_4: 0.6460 - val_acc: 0.9181\n",
      "Epoch 175/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3297 - auc_4: 0.8565 - acc: 0.8582 - val_loss: 0.2916 - val_auc_4: 0.6668 - val_acc: 0.9042\n",
      "Epoch 176/10000\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 0.3296 - auc_4: 0.8567 - acc: 0.8584 - val_loss: 0.2776 - val_auc_4: 0.6307 - val_acc: 0.9156\n",
      "Epoch 177/10000\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.3282 - auc_4: 0.8587 - acc: 0.8586 - val_loss: 0.2777 - val_auc_4: 0.6494 - val_acc: 0.9126\n",
      "Epoch 178/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.3310 - auc_4: 0.8560 - acc: 0.8579 - val_loss: 0.2796 - val_auc_4: 0.6536 - val_acc: 0.9115\n",
      "Epoch 179/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3309 - auc_4: 0.8557 - acc: 0.8586 - val_loss: 0.2881 - val_auc_4: 0.6518 - val_acc: 0.9078\n",
      "Epoch 180/10000\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 0.3294 - auc_4: 0.8569 - acc: 0.8587 - val_loss: 0.2660 - val_auc_4: 0.6405 - val_acc: 0.9187\n",
      "Epoch 181/10000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.3287 - auc_4: 0.8582 - acc: 0.8590 - val_loss: 0.2827 - val_auc_4: 0.6615 - val_acc: 0.9100\n",
      "Epoch 182/10000\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.3292 - auc_4: 0.8574 - acc: 0.8601 - val_loss: 0.2713 - val_auc_4: 0.6473 - val_acc: 0.9165\n",
      "Epoch 183/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3276 - auc_4: 0.8591 - acc: 0.8595 - val_loss: 0.2814 - val_auc_4: 0.6623 - val_acc: 0.9097\n",
      "Epoch 184/10000\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.3278 - auc_4: 0.8591 - acc: 0.8588 - val_loss: 0.2773 - val_auc_4: 0.6425 - val_acc: 0.9141\n",
      "Epoch 185/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.3286 - auc_4: 0.8581 - acc: 0.8592 - val_loss: 0.2792 - val_auc_4: 0.6518 - val_acc: 0.9119\n",
      "Epoch 186/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3291 - auc_4: 0.8579 - acc: 0.8581 - val_loss: 0.2799 - val_auc_4: 0.6478 - val_acc: 0.9114\n",
      "Epoch 187/10000\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 0.3284 - auc_4: 0.8578 - acc: 0.8592 - val_loss: 0.2810 - val_auc_4: 0.6509 - val_acc: 0.9109\n",
      "Epoch 188/10000\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.3280 - auc_4: 0.8588 - acc: 0.8595 - val_loss: 0.2763 - val_auc_4: 0.6514 - val_acc: 0.9140\n",
      "Epoch 189/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3288 - auc_4: 0.8577 - acc: 0.8589 - val_loss: 0.2799 - val_auc_4: 0.6554 - val_acc: 0.9114\n",
      "Epoch 190/10000\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 0.3292 - auc_4: 0.8571 - acc: 0.8594 - val_loss: 0.2807 - val_auc_4: 0.6470 - val_acc: 0.9117\n",
      "Epoch 191/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.3275 - auc_4: 0.8592 - acc: 0.8594 - val_loss: 0.2775 - val_auc_4: 0.6494 - val_acc: 0.9132\n",
      "Epoch 192/10000\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.3288 - auc_4: 0.8575 - acc: 0.8603 - val_loss: 0.2720 - val_auc_4: 0.6535 - val_acc: 0.9155\n",
      "Epoch 193/10000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 0.3281 - auc_4: 0.8586 - acc: 0.8584 - val_loss: 0.2770 - val_auc_4: 0.6547 - val_acc: 0.9120\n",
      "Epoch 194/10000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 0.3275 - auc_4: 0.8587 - acc: 0.8596 - val_loss: 0.2763 - val_auc_4: 0.6576 - val_acc: 0.9124\n",
      "Epoch 195/10000\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.3288 - auc_4: 0.8580 - acc: 0.8584 - val_loss: 0.2848 - val_auc_4: 0.6415 - val_acc: 0.9103\n",
      "Epoch 196/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.3284 - auc_4: 0.8581 - acc: 0.8597 - val_loss: 0.2681 - val_auc_4: 0.6479 - val_acc: 0.9182\n",
      "Epoch 197/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3276 - auc_4: 0.8587 - acc: 0.8600 - val_loss: 0.2842 - val_auc_4: 0.6501 - val_acc: 0.9101\n",
      "Epoch 198/10000\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.3285 - auc_4: 0.8584 - acc: 0.8588 - val_loss: 0.2792 - val_auc_4: 0.6505 - val_acc: 0.9134\n",
      "Epoch 199/10000\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.3277 - auc_4: 0.8593 - acc: 0.8600 - val_loss: 0.2748 - val_auc_4: 0.6576 - val_acc: 0.9141\n",
      "Epoch 200/10000\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 0.3285 - auc_4: 0.8584 - acc: 0.8601 - val_loss: 0.2797 - val_auc_4: 0.6416 - val_acc: 0.9137\n",
      "Epoch 201/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.3295 - auc_4: 0.8572 - acc: 0.8593 - val_loss: 0.2840 - val_auc_4: 0.6544 - val_acc: 0.9097\n",
      "Epoch 202/10000\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 0.3279 - auc_4: 0.8591 - acc: 0.8590 - val_loss: 0.2772 - val_auc_4: 0.6469 - val_acc: 0.9142\n",
      "Epoch 203/10000\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 0.3283 - auc_4: 0.8584 - acc: 0.8593 - val_loss: 0.2810 - val_auc_4: 0.6532 - val_acc: 0.9116\n",
      "Epoch 204/10000\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.3287 - auc_4: 0.8577 - acc: 0.8591 - val_loss: 0.2779 - val_auc_4: 0.6510 - val_acc: 0.9132\n",
      "Epoch 205/10000\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.3274 - auc_4: 0.8590 - acc: 0.8597 - val_loss: 0.2774 - val_auc_4: 0.6509 - val_acc: 0.9132\n",
      "Epoch 206/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.3292 - auc_4: 0.8577 - acc: 0.8593 - val_loss: 0.2765 - val_auc_4: 0.6515 - val_acc: 0.9135\n",
      "Epoch 207/10000\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.3288 - auc_4: 0.8578 - acc: 0.8592 - val_loss: 0.2783 - val_auc_4: 0.6499 - val_acc: 0.9129\n",
      "Epoch 208/10000\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.3284 - auc_4: 0.8585 - acc: 0.8585 - val_loss: 0.2801 - val_auc_4: 0.6501 - val_acc: 0.9117\n",
      "Epoch 209/10000\n",
      "1/1 [==============================] - 1s 553ms/step - loss: 0.3285 - auc_4: 0.8573 - acc: 0.8592 - val_loss: 0.2792 - val_auc_4: 0.6512 - val_acc: 0.9125\n",
      "Epoch 210/10000\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.3286 - auc_4: 0.8585 - acc: 0.8588 - val_loss: 0.2757 - val_auc_4: 0.6484 - val_acc: 0.9140\n",
      "Epoch 211/10000\n",
      "1/1 [==============================] - 1s 563ms/step - loss: 0.3282 - auc_4: 0.8585 - acc: 0.8601 - val_loss: 0.2814 - val_auc_4: 0.6518 - val_acc: 0.9110\n",
      "Epoch 212/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3277 - auc_4: 0.8591 - acc: 0.8595 - val_loss: 0.2791 - val_auc_4: 0.6466 - val_acc: 0.9125\n",
      "Epoch 213/10000\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.3279 - auc_4: 0.8589 - acc: 0.8597 - val_loss: 0.2756 - val_auc_4: 0.6542 - val_acc: 0.9132\n",
      "Epoch 214/10000\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.3290 - auc_4: 0.8577 - acc: 0.8588 - val_loss: 0.2784 - val_auc_4: 0.6543 - val_acc: 0.9126\n",
      "Epoch 215/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.3270 - auc_4: 0.8596 - acc: 0.8599 - val_loss: 0.2819 - val_auc_4: 0.6500 - val_acc: 0.9106\n",
      "Epoch 216/10000\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.3291 - auc_4: 0.8576 - acc: 0.8588 - val_loss: 0.2704 - val_auc_4: 0.6478 - val_acc: 0.9170\n",
      "Epoch 217/10000\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.3286 - auc_4: 0.8585 - acc: 0.8589 - val_loss: 0.2782 - val_auc_4: 0.6517 - val_acc: 0.9119\n",
      "Epoch 218/10000\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.3273 - auc_4: 0.8590 - acc: 0.8609 - val_loss: 0.2819 - val_auc_4: 0.6483 - val_acc: 0.9107\n",
      "Epoch 219/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3290 - auc_4: 0.8574 - acc: 0.8601 - val_loss: 0.2764 - val_auc_4: 0.6538 - val_acc: 0.9128\n",
      "Epoch 220/10000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.3286 - auc_4: 0.8580 - acc: 0.8593 - val_loss: 0.2769 - val_auc_4: 0.6542 - val_acc: 0.9135\n",
      "Epoch 221/10000\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.3271 - auc_4: 0.8595 - acc: 0.8600 - val_loss: 0.2836 - val_auc_4: 0.6506 - val_acc: 0.9099\n",
      "Epoch 222/10000\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 0.3268 - auc_4: 0.8601 - acc: 0.8606 - val_loss: 0.2742 - val_auc_4: 0.6587 - val_acc: 0.9135\n",
      "Epoch 223/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 573ms/step - loss: 0.3271 - auc_4: 0.8595 - acc: 0.8602 - val_loss: 0.2770 - val_auc_4: 0.6433 - val_acc: 0.9144\n",
      "Evaluating model.\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4254 - auc_4: 0.7383 - acc: 0.8173\n",
      "Done.\n",
      "Test loss: 0.4253664016723633\n",
      "Test accuracy: 0.7383022308349609\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = []\n",
    "for ahead in range(max_ahead):\n",
    "\n",
    "\n",
    "    graph_train, graph_val, graph_test = Split_Data(Truth_Graph_List[ahead])\n",
    "\n",
    "    data_tr = MyDataset(graph_train)\n",
    "    data_va = MyDataset(graph_val)\n",
    "    data_te = MyDataset(graph_test)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    This script is a proof of concept to train GCN as fast as possible and with as\n",
    "    little lines of code as possible.\n",
    "    It uses a custom training function instead of the standard Keras fit(), and\n",
    "    can train GCN for 200 epochs in a few tenths of a second (~0.20 on a GTX 1050).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # tr_load = BatchLoader(data_tr)\n",
    "    # va_load = BatchLoader(data_va)\n",
    "    # te_load = BatchLoader(data_te)\n",
    "\n",
    "    tf.random.set_seed(seed=0)  # make weight initialization reproducible\n",
    "\n",
    "\n",
    "    # Parameters\n",
    "    channels = 64  # Number of channels in the first layer\n",
    "    K = 2  # Max degree of the Chebyshev polynomials\n",
    "    n_attn_heads = 8  # Number of attention heads in first GAT layer\n",
    "    iterations = 1  # Number of iterations to approximate each ARMA(1)\n",
    "    order = 2  # Order of the ARMA filter (number of parallel stacks)\n",
    "    share_weights = True  # Share weights in each ARMA stack\n",
    "    dropout_skip = 0  # Dropout rate for the internal skip connection of ARMA\n",
    "    dropout = 0.2  # Dropout rate for the features\n",
    "    l2_reg = 5e-5  # L2 regularization rate\n",
    "    learning_rate = 1e-2  # Learning rate\n",
    "    epochs = 10000  # Number of training epochs\n",
    "    patience = 100  # Patience for early stopping\n",
    "    a_dtype = data_tr[0].a.dtype  # Only needed for TF 2.1\n",
    "\n",
    "    N = data_tr.n_nodes  # Number of nodes in the graph\n",
    "    F = data_tr.n_node_features  # Original size of node features\n",
    "    n_out = data_tr.n_labels  # Number of classes\n",
    "\n",
    "    # Model definition\n",
    "    x_in = Input(shape=(F,))\n",
    "    a_in = Input((N,), sparse=True, dtype=a_dtype)\n",
    "\n",
    "    # Load data\n",
    "\n",
    "    # Model definition\n",
    "    do_1 = Dropout(dropout)(x_in)\n",
    "    gc_1 = GCNConv(channels, activation=\"relu\", dropout_rate=0, use_bias=True)([do_1, a_in])\n",
    "    do_2 = Dropout(dropout)(gc_1)\n",
    "    gc_2 = GCNConv(channels, activation=\"relu\", dropout_rate=0, use_bias=True)([do_2, a_in])\n",
    "    do_3 = Dropout(dropout)(gc_2)\n",
    "    gc_3 = GCNConv(channels, activation=\"relu\", dropout_rate=0, use_bias=True)([do_3, a_in])\n",
    "    do_4 = Dropout(dropout)(gc_3)\n",
    "    gc_4 = GCNConv(channels, activation=\"relu\", dropout_rate=0, use_bias=True)([do_4, a_in])\n",
    "    do_5 = Dropout(dropout)(gc_4)\n",
    "    gc_5 = GCNConv(n_out, activation=\"sigmoid\", dropout_rate=0, use_bias=True)([do_3, a_in])\n",
    "\n",
    "\n",
    "\n",
    "    model = Model(inputs=[x_in, a_in], outputs=gc_5)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"BinaryCrossentropy\", metrics=[tf.keras.metrics.AUC()], weighted_metrics=[\"acc\"]\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    # Train model\n",
    "    loader_tr = BatchLoader(data_tr, batch_size=10000, epochs=1000)\n",
    "    loader_va = BatchLoader(data_va)\n",
    "    model.fit(\n",
    "        loader_tr.load(),\n",
    "        steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "        validation_data=loader_va.load(),\n",
    "        validation_steps=loader_va.steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)]\n",
    "    )\n",
    "\n",
    "    # Evaluate model\n",
    "    print(\"Evaluating model.\")\n",
    "    loader_te = BatchLoader(data_te)\n",
    "    eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\n",
    "    print(\"Done.\\n\" \"Test loss: {}\\n\" \"Test accuracy: {}\".format(*eval_results))\n",
    "                   \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, model in enumerate(models):\n",
    "    model.save_weights(f\"TF_Models/Model_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Hour - ROC Curve - Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "1 Hour Lookahead AUC:  0.9122664312784916\n",
      "Threshold Selected:  0.23338602\n",
      "FPR Selected:  0.1465282658449118\n",
      "TPR Selected:  0.8411189322607185\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "2 Hour Lookahead AUC:  0.8855510719298294\n",
      "Threshold Selected:  0.21358792\n",
      "FPR Selected:  0.17277821824996395\n",
      "TPR Selected:  0.8062465703310774\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "3 Hour Lookahead AUC:  0.8637263480705657\n",
      "Threshold Selected:  0.19565955\n",
      "FPR Selected:  0.19751373750112602\n",
      "TPR Selected:  0.7809153318077803\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "4 Hour Lookahead AUC:  0.8403488531910587\n",
      "Threshold Selected:  0.17847908\n",
      "FPR Selected:  0.22459291015202826\n",
      "TPR Selected:  0.757742349276159\n",
      "--------------------------\n",
      "\n",
      "--------------------------\n",
      "5 Hour Lookahead AUC:  0.8200909169935631\n",
      "Threshold Selected:  0.18590237\n",
      "FPR Selected:  0.22229325745569803\n",
      "TPR Selected:  0.7149146945514584\n",
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAGwCAYAAAC99fF4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAA9hAAAPYQGoP6dpAAClmklEQVR4nOzdd3xV5f3A8c/dyc3ee0PYew8FVEBx71mr1tFqna3W1g5o6+yvinvV1l2tCxQBARkqe28CISFk731v7jy/P064NyE7JITxfb9emDOec85zDyH5+ozvo1EURUEIIYQQQjSj7esKCCGEEEKciiRIEkIIIYRohQRJQgghhBCtkCBJCCGEEKIVEiQJIYQQQrRCgiQhhBBCiFZIkCSEEEII0Qp9X1fgVOB2uykoKCAgIACNRtPX1RFCCCFEJyiKQm1tLbGxsWi1Pd/uI0ESUFBQQEJCQl9XQwghhBDdkJubS3x8fI/fV4IkICAgAFBfcmBgYI/f3+FwsGzZMmbNmoXBYOjx+4vWyXvvG/Le+468+74h773vVFRUkJKS4vk93tMkSAJPF1tgYGCvBUlms5nAwED5B3QSyXvvG/Le+468+74h773vOBwOgF4bKiMDt4UQQgghWiFBkhBCCCFEKyRIEkIIIYRohQRJQgghhBCtkCBJCCGEEKIVEiQJIYQQQrRCgiQhhBBCiFZIkCSEEEII0QoJkoQQQgghWiFBkhBCCCFEKyRIEkIIIYRoRZ8GST/88AOXXnopsbGxaDQaFixY0Oy8oijMnTuX2NhYfH19mT59Onv37m1Wxmazcf/99xMeHo6fnx+XXXYZeXl5J/FTCCGEEOJM1KdBUn19PSNGjOCVV15p9fxzzz3H888/zyuvvMLmzZuJjo5m5syZ1NbWeso89NBDfPXVV3zyySf89NNP1NXVcckll+ByuU7WxxBCCCHEGUjflw+/6KKLuOiii1o9pygK8+fP54knnuCqq64C4L333iMqKoqPP/6Ye+65h+rqat555x0++OADLrjgAgA+/PBDEhISWLFiBbNnzz5pn0UIIYQ4U7jdCg63G4dLweZwYXO6cbkVHE4XLpcLh9NJXYMdt8uKw1KLs8GK02bFbamlqqoao8aGYrPhdjhQbBa0tTZcLgVtRTUOvQ8NTgW3A3QaDYobNC49ilWDYnKjuLU4cIEmCZ2rBJMN3FotLp0OFA2gxWFIwuAswWqr7fCznIg+DZLak52dTVFREbNmzfIcM5lMTJs2jXXr1nHPPfewdetWHA5HszKxsbEMHTqUdevWtRkk2Ww2bDabZ7+mpgYAh8OBw+Ho8c9y7J69cW/RNnnvfUPee9+Rd983TvS9u9wKNQ0O7E41KHG43NQ2ONFowOlWcDX+cbgUyupslNfb0Wo0KIqinne5wWGloLwCo8aC015ORU0poeZatO4abEo5OpcNi7UKU6WTcF0N9W4TeoeTYEct9U4Dplo7PgYNikuHqyEQk8YPnRKAhhj8rC70SgwNBjtaNzh80/G1FFMZOgizpYSawGRMDRXYfEKBgMY/3eDb+LVJH5dLNwC7sY33po+kQVvfvWd10ikbJBUVFQEQFRXV7HhUVBQ5OTmeMkajkZCQkBZljl3fmqeffpp58+a1OL5s2TLMZvOJVr1Ny5cv77V7i7bJe+8b8t77jrz73udWwOEGmwsaGv+88tkKrC71uNWpHrO5NJ5jdhfUO6HYqsGgVai3OQjAio/Ghh82/LHgr2nAX1NLoiELi95GgK4Kg6GMCiWQCE0B2a4AHDaocymEW9zo6rRE17sJrtSAn4bUYjNVfkZ8nWbiKvRYTUFo0VJvjkPnisRh8KM8dDC+1lJceh8cBn90AYnodXW4MaIYjeiM4ET9A9AQ2PLz1/nHA1ATmAzQGCCdeU7ZIOkYjUbTbF9RlBbHjtdRmd///vc88sgjnv2amhoSEhKYNWsWgYGtfDecIIfDwfLly5k5cyYGg6HH7y9aJ++9b8h77zvy7rvG5nRjsTspq7VTVm+jyuKg0uLA4XKzNaeK7LJ6jAa1WWNXntrj4GvQYne5MbobCKWWUE0t4ZpqwjXV+GMlEAtBmnqCNHUEYMWsqadB58BoLKbIAEW+JooDFYxuqHbqsDi1+FVrMVTp8G9QSCyBBiMEWMDfqpBcaiI3IgwfVwg6JYl0UzB1fjG4tQYqg9Nx6UwoJj21cSZ0QE6w+tmqgaLktj97XUBCs32nwf/EX6jiRueqwaUPRu/Iwo0LHQpoFFzaaHxth2jwDUDrKEdntuPQ2jFq9Oj1GrRa0KBD0Tgx+vmg0+tB60JvDESrB50WdGZf9EY9Wp0OncGATq+j3t4A/znxqrfllA2SoqOjAbW1KCYmxnO8pKTE07oUHR2N3W6nsrKyWWtSSUkJkydPbvPeJpMJk8nU4rjBYOjVHyy9fX/ROnnvfUPee98509+9y61Q1+DE4nBSWe/A6nBSXGPDandRWG3lSLmFELOBHw6WkRrhR5XFQb3did3pbgyE7Nic7iZ3VDDhIJB6wjS1RGsqCKKOaZpKztNtJ12TR4PJSIymAgCrXkOFTkudRkuDVkONVkuVTkuGwUiVQ0eOXU94nUK1xYDWoSGmQiHIEkRwvcLYSgipP/ZUDVbfcKy+EVQF9cOt1eHS+eA2p1IREUsFcHRg779PndaJy63HZHDg56/D16zFUg+J/f0x+RtR9EZC44PRGg2Yg4zoDFr0Bi0mswGjjw69UdfKXc/r/YoD5eXlvXr/UzZISklJITo6muXLlzNq1CgA7HY7a9as4dlnnwVgzJgxGAwGli9fznXXXQdAYWEhe/bs4bnnnuuzugshhGjO6XJTb3dRY3VgdbiotjrILq3HrSjU213UNjjYmlNJhL+JmgYnO3KrcCsKiqIQ5GvgSLkFAL1Wg9OttPssDW6CqSNAY6WgRA160jWVGHAyTJuNr8aGr8GGDjeTdfsAcADVWi3VOi11Wi1VWi1Fej1r9Xq+dRvZa/clsiyemEoFoxPiyqDeByYeULAHQIQN+qlVREFDg08otf4J1Pup/5NfE5BEfYSZ7f3Seu0d+wdoqKtViEvzxy/Mj5qyBmLTg7HW2IlIDMDtVgiJMuMbYMToq8NkNmDw0aHTScrEtvRpkFRXV0dmZqZnPzs7mx07dhAaGkpiYiIPPfQQTz31FP3796d///489dRTmM1mbrrpJgCCgoL4xS9+wW9+8xvCwsIIDQ3lt7/9LcOGDfPMdhNCCHHiLHYnpbU28iut5FSo0UBGUS2+Rh37CmoIMRtQgFUHShgeH0yDw0WdzUmVxUF1Y2DUXZUWB6AQTB3RSiWx2jJCNbVEUYmChiBNHZGaKsKp5hzdHs91DRoNlVot2QYDVq2GA0Yj6wx6inU6anRacvQGdMTjdGuIL4MBeQrxZQpRlWDxgUkHFIZ77qY0/gGX1oDNFIzVJ5yc5CE4DP4cDB+BwVGHotFiNwV3+7O2JiolEI1GQ1CELyExZky+ekJj/QkI88Hkq8fgo+twGIronj4NkrZs2cKMGTM8+8fGCf385z/n3Xff5bHHHsNqtXLvvfdSWVnJhAkTWLZsGQEB3pHzL7zwAnq9nuuuuw6r1cr555/Pu+++i07XWvOfEEIIl1uhxuogq6yOg8V1ON0K+wtrcDjdZJfVE2w2sOZgKQBmox6L3YnD1X7rTVM/ZZZ1qpwGN+FUE6WpJFxTTbKmmIna/RhwEqWpJElTzFElkmBNHeGaGkx4Z4+5UVt+DhsN5Oj1FOl1fOnry70+ia0/y60QUwlxBQqpxQojshTSC1xYTGCyg67x4ylosBsDsPpGUBrmh9UcQUnEaAyOWhp8wqj3i23z89h0XR+8HJ7gj+JWSB4eTkRiAEERZkxmPeZAIzq9tPD0tT4NkqZPn46itP0PT6PRMHfuXObOndtmGR8fH15++WVefvnlXqihEEKcPpwuNxU2WHOwlHqHQlmdnYyiGjZlV1BY3XDcOJzOqbZ2N52AQpS2hoG+VSQZqknVlZCq5IHexJj6Nfi5arBrfTG6rW0/W6vBYiwiU68nX29mra8PmUYD/m43pTodynGtJya7QkKJQniNQqAFwmphyj43fg0QWtf83i6tgcqgJCzmKMrDhqrdYopCg08IivbExnOFxPih0UB4vD9+wSaCo8yERPvhG2DAHGCUlp/TyCk7JkkIIQQ4XG4KqxooqLaSW2GhweEit9KKzeGivN5ORb2daquDvQU1aDSgKHrYtr1Hnu1v0lNnczIoJpAAHz0hZgMWu4swPyP9AxwM8avG4Kgm1l1EcPFGjBoX5iMr0Li8eehwNf5phaJYOarXs8tkZJ/JSLVWS7lOR7FeR6ax9eQ4GkUhrkjH6CKFsFo3wXWQUqyQWNr6M1xaI7X+8eTHxFAV3I+y8BG4dC0n7nSWX7AJ/xATNeUN9BsTSWiMH4ERJrbuXcsll885owfMn40kSBJCiD7idiuU1No4XFrHxuwKqi12lu0rpsriICbIh2qrg/J6e6fv107DfAtGnZZLRsRg0usINhsYHheEQaclLshAiM5KmC0fQ30h1BZD2SqoyAK/cHDmwdEDYOncrCI3UKvVUK7TkWMwsMdo5L+BAdR2MFhY41YIr4GBeQqT9yno3BBoUYitAJ9WGrdcWgNW3whq/eOxmKOo84+j1j+hW+ODEoeEYg4yodFAdGoQwZFm/IJNBISa0LZSb4fDgfZglx8jTgMSJAkhRC9wuRVyKywUVFspqGqgtNbGnvxqXG6F3fnVFFRb0aAmJWxNVlnnMwlrNRDub6Le7iRU72TyoHiKa+1cOCSacH8TfiY9KWFmotxFaGoKoLYQ8reCKQDqSiB3F2zYCqZAsNV0+bNWa7XsMhnZ7mMiR6+nUqejVqvlgKmNVMnHCapXSCpWiC+DC3a4sRk1pBW2HfG5NTos5ihKIkZTETIAmym4y8kM/UNNGIw64tJDSBgcSmC4D6Exfq0GQeLsJUGSEEJ0g8utUFBl5XBpHQeLa1l5oITaBic6rYZdedWNXV/t36Ojhh+tBobGBREd6ENciC8BJj02l5uB0QEE+xpJjfAjxM9IgEmPRqPBUVXIxkXvMSk2F13eesi0Qc56sNeB0onZZe0ESPUadXbYbpMRq8mfIr8QvtbU4+zwU6j8rAr9CxQiqmF8hkJ6gYJvm41kiue/dmMQNYHJ1PnFUBQ1HocpEKfOt60Lm9HptYTF+REcZSYszp/I5EDC4/wx+ellTJDoFAmShBCiCUVRqLU5OVpuIbusHovdyaHiOhQgp7yeino7245WdRgEdRQgBfroqWlwMmNABImhZvpFBRDhb2RgdCBBvgZC/I5rhXHaoa4Iyg/Dofehtgh0BqgpgCM/AmAApgJkHv+0TtBoqdEo5MYOI9/owyGjkS/thUT7hLHL2toyT3WtHIOQWoWYCoUJGQqjszXU+usIq3IRUtP2oHEFGvMKJWIxR1EUPQGN4vbkGOoMk5+esFh1oHS/MZFEJAbgH2KSYEicEAmShBBnFZvTxdYjlWSW1lFjdZBTbsHicLEus6wxH0/ndCYICvUzMjY5lKhAE+lRAcQF+xLqZyQuxBeT/rg0JYoClgqoyoCibKjMgYNLIXdjNz5l69xAflgSucmTWatzUOKoxao3UuKoZ3/1sciqSo1aGsdel7QaIKn1DauFfgUK1/7oJqZKg8ZkQl/f0LQQURXNgyM1y3QE1YHJlIcOocE3DKtPOA5j1xZFDQjzITDchyHnxJE0JAyjr/w6Ez1PvquEEGcUu9NNfpWVwior23OrcLoU8iotrDlYSkmtreMbdEFkgIlLhscyMCaA+GBfgswGogN9CPUztt+C4bRD6WEo2gXZa6A6Hw5/3/2KGMzgFwFVOTTogzAOnIU1oh+bzH4c1bj4sWwXG4s3Y9absTgtULG2a7d3KAyqNDMg182lmxXcwQGYs4uPK6WAs6HZEbdGS01AMrUBiRAdT37QSCzuznWVHeMXbCJ+QAgJg0IITwwgOMosGaLFSSNBkhDitKEo6mywgiorW3MqsdhdFFY38MPBUhJDzWSX1VNU09Dxjdqg1YCPQYfV4SIx1MyQ2ECCfI2MTQpBq4W4YDOhfkYSQ80Y20v0pyhQXw7Fe6BkH1grIfsH8AmGg0tA7wvOtvMDtSn9QgiIBoMfJE7AFZpKtsbJ17mrcCkuiuuL2Z+3n6P1G6G+ZQuUxWlp89aRvpFE+0VT21DNxNpIJleGE5ZThWHDLpSqaqDWW7iy5X3cGi1W3wjqRsym0JSK0xRAjc3nuEJtf7S49GAikwIJiTETGuNPSIwZo4/8ihJ9S74DhRCnnHqbunbX7vxq9hfWsHBHASa9tt1kiPlVHQcdWo06mywx1Mw5/cMZFBNIelQAIWYD8SFmfFtdqLMd1koo2KGOCdLooDpPDYyKdrV/XWsBksEPogaDwwqDLoPQVAhNgdBUXD5B5NTmcKjyEHvL9rIqdxVHNn/Ttbo2CjIFcWW/K4nzjyPYJ5iBxkTC8+ux7d5DyZ+PrXl52FO+rV5Fh96X+vGXUaSJp8CQCprjCrfTaBcSbSYg1IeEwaHE9g8mIjFAxg6JU5IESUKIk87pclNU08DRcgubjlSw5UglPgYd+wtr2gx2OpstelBMIFGBJiotDi4dHoOvUcfgmEBSI/wJ9OnGrCa3G6qPQlkmHFqmtgRVHaVlVNBFUcMgfTaEp0PkQIgaigsoshRRXF/M4erD7D26iMxdmews3dmlWwcYAgjzDcOluLii3xVMjp1Mqi4KsvNwlhRjWbYNZ+lGapcsxQrktnMvBQ2O5CFU+iXhGjSeOn0IeUWtBJNtvIqweH+iUwIJjjIT0y+YkGhpIRKnD/lOFUL0mmqLgwNFNRwoquVohYUtRyo4WmHp0gDp401Lj8DqcDEmKYTYYF+GxgYS5mci0FdPsLlzeXla5Xars8fKDsKeL9UWnYNL25kW306AFJwIwUlgDoWGakg+B6KHQWAcRAwEnR6H28GR6iMcrT3KmqwvKN/3Fj/k/dDlak+JnUKtvZaZSTOZEDWBPWv3cOk55+HYuZOGPXup+ffXuKs/JKe0jZTUx30ii28kdf7xuM69hBxrNFZLk8/ZiSXZxl6cTHicP4HhvoTG+sn6Y+K0JkGSEOKEOFxuiqobKKiysmRPEfsKqtl0RM+D65d1+54RASaCfA1cNDSaMD8jU/uHkxbh33NdMvVlcHQ9HN2gJlM8uh6q22tPacfon0NQPPgEQcJ4CEkB3+AWxSoaKvg261sOZP6XfeX7yKzq/Dz9MJ8wBoUNQkHhyn5XMjh0MLH+sei0OhS3G8umTTRs2EP91pfpv3cv2Y//uVP3VdBQF9Gf8uRzyPYbhUKT91uulmiNzqAlKMIXW72D8ZelEpUcSGisn3SZiTOOBElCiA653Ar5lVYOFNVQXGtjc3YF+wtrOFTSeq6cjmg14GfSMyAqgFGJwYT5m5icFkZSmB9Bvj249lVtMVQchqzV6sBphwUKu9Z1RWAc1OSrrUGp0yFpMkQPB5N/q8XdipuC2jyK6ovIrMpkcfZiDlQcwNrJgdrDw4cTZAoiOSiZKbFTGBExAn+j91mKy0XD/gNUrl+KZeMmLBs3oji8LXNtrUpmTErCd+RILIovZTFjKa31oahCj72hE0kmgbTREUQmB5I6MoKgcF80WgmIxJlPgiQhRDO5FRYyimr535ZcduVVYzbqyK+ydmsFeYAwPyOT0sJIi/BndFIII+KDTqxbrDW2OsjbDOWZUJENOT9B4S66NGYoIAbs9Wp32KhbICQZYkeBT2Cbl1idVvaW7WVdwTqqbFV8dvAzjFojdnfH660lByaTFpyG3WVnZtJM0kPTGRAyAL22+Y9ld3099ds2ULtsGfWbNuHIy0dpaH8Gn8ZsJviKy7H7hFAz8FzqFH92r85H59ZgrXWApwex9QApZUQ4/cdFERbnT0i0WVqIxFlLgiQhzlKV9XZ25lWRVVrPgh35ZJfVU9vg7Na9ksPMJIf7MTktjPRIPwr3buTqSy/C2MZK7t3mdqmDpvO3Qs46Ndv0wSXdqPA5YKuFfhdA2nnqeKF2giGH28HRmqMcqDhAYX0he8v2suLoilbLthYgadCgoHDLoFsYFj6Mc+PPbdY6dIzidNKQeZDqL7+ibtUqNEYjtkOH2v0o2qAgfIcMwZiaimHoUFbl20hNH8+ODSWUZ9VBVjmNfWetv4rh4cT0CyI0xo+EQaEyhkiIJiRIEuIMpygKBdUNZBTVsL+wllUHSjhQVEudrWsB0QWDIkkK80OrgUlpYcSHmEkMNeNjaD7TyeFwsDiDE2t9cLvVMUL5W6DsEBz4Vs1GXZPX+XtoDaDRQOIkSJoC8WMgbgz4hrR5ic1lY1fpLn7K/4lFhxdhdVkxaA1UNFR0+rFBpiB8dD6cn3g+iYGJDAodxLDwYRh0LbsRHYWF1C5fjj3nKLUrV+IsLOzUM8yTJhJw3vnoh4+i2B5G7tE6So/WULqmFrvVRfHurFav02g1KG6FIefGERTuy9BpcRhMXUx7IMRZRIIkIc4wbrfClpxKNmWX8+3uIkprbZTVdT7TdLi/kbI6O49fNJBxyaEMiwtqP3HiiVIUqDwCmSug9ADsX6TOMusKrV7tHosZAf1mQso54B+lrm3WBqfbyeGqw6wtWMvGwo2sK1iHTqPD1ZmFYPG2DiUEJDAnZQ7DwocxImIEwT7BLT+iy0XtylU4S0up/uZr3PUW7EeOoFg7N04p6Mor8Rk1CntsOhWaCDIOVJK7o4KGtcXA8ZmvvQLDfQgM9yV5WDjxA0NkcLUQXSRBkhCnubI6G9/sLODNNVnU252d6jI7tjjrJcNj8DPquWxkLENjgwj07eXV0V0ONSDa/TnkbVKX46grUqfJd1xrQIGAWHUAdep0iBgAkYNB3363ntVpZXfpbg5WHmRB5gIyKjNar14bAVJKUApOt5M4/ziGRwznvITzSAtOw0fv02p5AMu2bZS9/ga4nNSvW9+Jz6fyHT0aQ3QUwddcgz1+IDkH6/j22yPYVzpRu83a7joz+enRmBsYOj6N+PRQYtODJSgS4gRIkCTEaUJRFKqtDg4W17H5SAWbsitYc7Dj3DcAA6MDmNIvnGFxQSSEmhkYHYCfqZf/+budcGSjOr0+b6s6dkirV493JDQVKrJg/D0QFKeOGwpNA6O5w0sVRWF32W6WHllKbm0uq3NXd6nasX6x3DrkVgaFDiI9JL3VsUOtPdO6fQcNu3dR+b/PcBYW4ra0vQTIMb6jR+M7aiS6gED8pk7FNGgQRVnVHN1XwU+ryinL3dHu9QGhPhh99QyaEkPqyAh8AnQsXryY0RcmYjD04CxBIc5SEiQJcYpqcLhYvq+Y/YU1fLu7kJzyjn/pHpMUZuaS4TGc0z+CEfHBXV9uoztstVC4E92qp7k85yfY3kqZtgKklHPVmWSxoyD5XPAL6/Rjy6xlbCzcyPqC9ewq20V2dXaXqn1Z2mVc0e8KBoYOJKCTK9ErdjsN+/dj3bWbup9+xLZvP84OkjX6TTsXfXAIAbNm4jt6NPoQdWyU0+4i70Al+/dWcOi9terss3YMPy+euPQQwuL8CYpovlisw9H9JJ1CiJYkSBLiFGGxO1m0q5Dssnr2F9awOqNzrUTHvHzjKM7pH97z0+vbUl8OO/8LJfshd4M6/R5od/SSXyTojDD8OogcpAZFoWmg7dyYJ0VRWFewjpyaHA5VHWJFzgqqbFUdXudv8MfmsnHjwBuZkTCDwWGDMRs6bpVq+lz74cNYtmzBun07davX4KruuIsw5OabCb7uOkz90tDodJ57leXWsfHjneTsLkdn0OJytJ5eITDCl9j+wQyfHk94Qg8m0xRCdIoESUL0kYIqK9/sLGDzkQqyyurJLqtH6SCtz/jkUNDAuf3DGRAdSEq4H2kRJ2kwbnU+5KxVEzPu+Kjz1w25Cib+Sg2KTJ1rqWmqsK6QN3e96clS7XB33FoS6hNK/5D+XJxyMVPiphBpjuzyc111ddQuXYpl6zZqvvsOpZ3uM42vL+ZRI/EdPQbz+HH4jhiB1uRN61hTZmXPD/nsXp2H0948IGoaIGm1GuIGBBOdFsyACdEEhvtIYCREH5IgSYiTpLLezudb8zhSXs/KAyUUVrefEDDQR8856RHEBvlw3dgE+kd1PcA4YXUlamvRtvc9LUVtCh8A5lBcCZNZWRnL9Ct/3q1xMcX1xfyY/yO7SnexvWQ7R2qOtFt+SNgQgkxBXJ52OYPDBpMUmNStwEJxu7EdOoRlwwYsW7dRu6ydZVV0OvzPPRfzmNGYx4/HZ9iwFs+sr7axf10hR3aVUZzd1vpvKr1By/m3DSZuQDC+/iepJVAI0SEJkoToJYqicLi0jq+257M2s5wduVUdXnNO/3AuGxHLoJhABsUEojvZSz/Y6tTcRNs+gILt6pIerdEZ1QzVOgNMug+G3+AZVO12OLAsXtypxymKwr6KfWwq3MTzW5/HrDdjcbY/9iopMInzEs5jUuwkRkSM6FK32fEcxcVUf/UVtsNZ1HzzTbtlfUePxhAfR/CVV+I7ciRaX98WZeqrbRxYX0jegUryD1ahuFtvGtTqNQyfkcDAidGExXU8MFwI0TckSBKihxTXNLA7r5rssnrWHi7rcEzR6MRgxiSFEBFg4ryBUSev26ypqlx1Kn7WasjfBsV72i4bPkCdZRaR3iwo6gqn28mesj2syFnBusJ1VNuqKbGUeM63FiANCh3ExNiJTImdwtiosei0JzYIvWH/fvIffRR7ZhsBYCNtYCCBF16I36SJ+J9/Pto2socXZFZxdG852787iruNoCggzIfUUREMmBBNREIftAgKIbpFgiQhusnhcrPqQAnv/JRNTrmFopr2u89CzAZmDY5maHwQlw2PJcjcB1O07RbI3QhZq2D/N+o0+45M+CWM+hlED+3WI8usZby/932+zPySaltn8iHBncPuJMgYxHUDrjuhliIAW2Ym9evWUbNkKdbtrU258zL170fAzFn4n38ePunpaNroLqyvspG5tYT96wooz69vtYw50Ejy8HCGz4iX1iIhTlMSJAnRBSW1DSzeVci+whoWbC/A7mp70Vd/k57IQBMpYX78ZtYABse2vTZYr7FUwJEf1e6zzOUdlw9OVKfjx4+HfudDUHy3HlvsKmb+9vlsL93O7rLd7ZaN9Yvl6vSrGRs1lmERwzBoTyx4VBQF26FDVH36PyybNmI71P5YKvOECQRdfjmBcy5C69N2cshj+YtydpdRklPbapmQaDNBEb6MvjCZmLSgE/ocQoi+J0GSEB3IKq3jww1H+XJ7HlWWtmdW+Ri0nDcwkiBfA9eMSWBUQjDakz2myGmDQ8th4xvgsKgLwbYnonEaftIk6D8bAqK6/egGZwNLspfw5aEv2VG7A/a3Xi7SHMmQsCHMSJjB7OTZJ9xSBOC226n55huqv1mELSMDV2Vlm2V9hg7F75ypBF99Ncb49oNAp8PF/rWF7FtbQFluXatlwuL8iUoNZNQFiQRHnfhnEUKcOiRIEuI4xTUNnqn5uRVW9hW2PTNpzrBoxiaFct24BPx7O4N1W6rzYff/4OAyddC1q+Uq9M1ED4Mxt8Ogy8A/4oQeXWuvZVPRJpZkL2FN7hoaXC27HCN9I5mdMpspsVOYGDPxhMcUHdOwbx8N+/Zh2byF2u+/x13XehBjiIsj6Mor8Z92Lj6DBqHRt//3pCgKR/dVkLmlmJw95a0mdwyOMpM0LIz0cVFEJvVBC6EQ4qSQIEkI4FBxLW//mMX/trS/yvygmEAiAkyc2z+cG8cn9v7SHq1x2iBnnTquaO2LHZcffSvEjYGBl3Ypk3Vbcmtz+Xj/x+TU5LChcEOreYt8Nb7cNeIuZqXMIikw6YSfCeCqqaH6q6+oW7Om47XQDAbC776boMsuxZjUuefXVjRwcFMRB9YXUVXccgC5OdDIiPMTiB8YQkRigOQvEuIsIEGSOGsdKKph3tf7OFhcS3l9260vqeF+XDs2gWvGxBMRYGqzXK+qOqoOtC7YDge+VbvSWhMYBynTIH22OrbIHNojj99bvpfVuat5Y+cbbZbRaXRcknoJFyZdSNnWMi4efPEJrx+mOBxUfPQR1V98if3IEZQ2lt3Q+PgQMHMmfpMn4z99mmfJj47YLA6ydpRyYH0RBYeqWi2TOCSMYdPjSBoaJoGREGcZCZLEWUNRFPbk1/DZ1lz+tyWXhjaWggCY0i+MX8/oz6CYgJO3zMfxqo7C5nfg8Eoo2tV+2RE3wtRH1On5PURRFFbmruT9ve+zrWRbm+WuSb+GCTETmBY/DV+9Lw6Hg8WazuVJaot1z17K336b2u++a7ec79gxBF95JQEzZ6IL7Fy3l7XWzsHNxRzeVkJhZuuz7UJj/Rg+I55+YyIx9cUsRCHEKUGCJHHGK6uz8dm2IyzYkU9WaevTtQEenT2A8wdFMjC6j8aYuN3qTLT1r8Kh9oMDBl8Bgy6FhAkQnNCj1SiuL+brw1/z9u63sTqtLc6nBaXhZ/DjhoE3MCdlTo+MMVJcLurXraN6wUJqvv22zXI+Q4YQ8rNbCJg+HV1wcJeeUZ5fx7ZlORzcWNzq+cBwH1JHRtBvbBRRyTLOSAghQZI4gx0pr+dfB7T8dtMPOFwtk/xpNHDXOancdU5q33WjARTvVccWFeyAsozWyxj9YdydkDQFkqeA0a9Hq7C/fD+fH/ycJUeWUGtvOb09wBjAFf2u4Jr0a0gNSu2x5zZkHKT8rbewbN2Ks6ioZQGDAd/hwwm8eA7B11zTZkLHNu9f7+DgpmIOrC+k9GjLzxUY7kNsv2Bi04MZODEGzcmejSiEOKVJkCTOOBuyynnp+0OsO1yOuia9N0AaHh/EZSNimTEwkrSIPkrw53apCR23faC2HFXntl02dTrM/BvEDO/xamRXZ/P14a9Zm7+W/RVtzNcHfjv2t/xs8M/QarQ98lxbdjZVn39O9cKvcZWVtVrGEB+P/7RpRDz4QKe70Y5RFIVDW4rZuiSHisL6pn/9AOj0WgZMimbgxBiiUwNlnJEQok0SJIkzgtut8MW2PP76zT5qbc4W56f2C+dvVwwlJbxnW2C6pCILtvwb1r3cfrkLn4Xh1/XYoOumiuqLWJS1iM8Pfk5+XX6b5abFT+P+UfczIHTACT9TURRsBw5Q9fkXVH70UZvlDPHxhP/ql/iOGo0pNaXLz3HaXRzYUMSO5UepLm3ZTWgOMjLknDhGnJ+AyVd+9AkhOiY/KcRpzeVWWLqniJe+P0RGcfPulAAfPRPC7Pz5xukkhvfRelm2Wtj8L1gxt+0yISkw9na1Ky12FPRQHqFjcmtyWX50OatzV7O9pPVlOeL847g49WKmxU9jWHjLFe27w5GXR/WKFZS9/gaKpfXZeIbYWIKuuorAC2dj6tevy89wuxUKM6s4uLGI7F1lreY0Covz49wbBxCTFiStRkKILpEgSZyWahscvLwyk7d+aLn2WLDZwPXjEnj4vDS+W7qEmKC2l5roNbmbYNv7sPMTaCWPEElTIH4sTLr/hBM6tiavNo9FWYtYkLmgzRYjs97M7UNv59K0S4n1i+2xAMKybj3Jzz5HTkVFq+d9RgzHZ/BgQm+5BVNaWreeUV1qYceKXA5tLsZmadlyGJ0axPAZ8aSOjEBn6JluQiHE2UeCJHFasTvdzF9xkHfXHcFidzU7lxDqy6OzB3Lp8Bg0Gg2ONnLq9ApFURM85m2GPV+0PWV/8BVwwV8gtOcGPx9zuOowb+56kyXZS9osE+YTxsjIkdww8AYmRE/o0ZYV686dlL3+BnWrV3P88Gqf4cPRBQcRM3cuhtjYbt3f5XKTuaWEjI1F5O5rJQDTQFz/YCZekUZ0qqybJoQ4cRIkiT6RVVrHdW+u53/3TCK1EwOo621OPt+ax3/WZnOkvHnXTWSAiccvGsilI2Ix6E5iq4GiwNEN6sy08kNQ3spCqlo9DLsOxv1CbTnq0ccrrMlbw7Ijy9havJWC+oI2y16Tfg3XpF/DkLAhPVoHZ1kZ1Qu/puqrL7FnHm5x3m/auYTffTfmMWO6/Qx7g5MdK3LZvCi71fMJg0MZMD6KpGHh+PhJTiMhRM+RIEn0iYU7Ciirs/P1zgIeuqDtBIgut8KHG3J4eeUhyuqaZ8W+anQcv5yWRnrUSR5vpCiw4XX47vdtl4kYpAZGw64B385lf+4sp9vJ+/ve54WtL7RbbkL0BG4dcivnxJ3Toy1GitNJ7fLl1K5aRc3X37Q4rwsNoWjiJCb+7a8Y/bo3UN7lclNwqIo9a/I5sqsM93EpHExmPekTohl3cTK+/n2U7FMIccaTIEn0iUW7Chq/FrYaJCmKwrJ9xfxl4V6Kapovmjo8Pog/XjyY8Sk9P/urXXYL7PlcHWeUs7bleXM4jL8LBsxRF5Ht4UHCu0t388WhL/ji0Betnh8cNpjx0eO5aeBNxPjH9OizAWyZmVR9+RVVX3yBu7plpmpTejpBV1yB/zVXs3/VKjRdzGkEUF5Qx9YlOeRlVGKtablUTFCEL2MvTmbA+GjJaSSE6HUSJImT7nBpHYcbM19nltSRVVrn6XJzuNy8/WMW/910lNyK5tO4pw+I4JGZ6QyPDz55lVUUKNoN296D7R+Cs+Uq98x4AoZfDyE9s5BrUw6Xg9V5q3lv73vsLN3Z4nyQKYifDfoZ1w+4nmCf4B5/vrO8nLLX36Dq00/bXDfNPG4c4ffdh9/ECWqduzgWzOVys/+nAravyKWmlan7Rh8d/cdHM+ScWCIS+miWohDirCRBkjjplu4pQqsBtwJaDSzZU8R9M/qxJ7+aR/63g4PFdc3Kh/sbeeH6kZzTv+dngbVJUeDgd/DZz1sPjALjYdpjMPrWHm8xAsiqzuK5zc+xNr+VFitgSNgQ7hx2JxckXdDjz1YcDqoWLKDqv5/QsG9fq2X8Z8wg6LJL8ZsypcvJHo+pLKpnx/e5ZG0rpaG+ZWAV0y+IwVNjSRsdicHYs2kRhBCiMyRIEifdNzsLUBqHmLgVWLgjn8ySOr7a3nKq+jNXDeP6cQknL7+NrQ52fAxb34WSvc3PaXQw9Cq11SjtvB7PZ+RwO1h+ZDmv7HiF3NqWWbhDfUL52eCfcUnqJUT7Rffos0FtNar++hsqP/gAR0HLQeBasxnfMWOIffop9OHh3XpGQ72DPWvyKMquIWd3eatlRs5MZPiMeAJC+yB1gxBCNCFBkuhxDQ4XewuqPYFQU1UWBweKmid9PFhc16z1KNjXwL0z0hidGIJGAzanGx9DL7YkKApkrYZd/4O9X7ZsOQpKhNRpcP5feiWnUWZlJp8f+pwl2UuoaGg+td2oNTIkfAg3DbyJWcmzemxpkKZshw5R8IcnaNi9u9XzQZdfRvC112Ie273ZefYGJxkbiji0pZiSnFpcDnez81q9huRh4QycGE3y8HBJ+CiEOGVIkCR63CebjjL3m9a7aUDtnWotgDqmyurgqcUHPPtzLx3MbVO6vkxFh9wu2LcQNrym5jc6XtQwmHy/OkOth1uNau21fHbwM9blr2Nj0cZWy1w/4HruH3U/Qaaez/njtlqpWbyYor8/iWJtOQ7INHgQkQ8+iN+UKWj03fsxUXq0lszNZexbW9AiMDpm3MXJjJyZiNFHfhQJIU498pNJ9LgbxieSXVbPe+tz0NBifdF2A6Rjjl132+Rkbhif2LMVdLth27uw+LGW2bB1Jhh0KUy8F+K7n9unLUX1Rbyx8402Z6hNi5/GJamXMDt5dq+0qDgrK6l45x0qP/0f7trmLXoas5mgiy8m+Npr8B3evQV1FbfC3h8KKF5r5qslO1otE9s/mPGXpBDTLwjtycxrJYQQXSRBkuhxPgYd8y4fytT+Efzmfzuot7twuTsRGTXSaTX4GXU8f91ILhgc1XMVc7vgwLew8m9QdrD5udA0mPIADL0aTD0/g6rWXss/t/yThYcX4nS3XEbj/lH3c236tYT49GxOpWNshw5R9vrr1CxumY3bEBuLz/DhxD79FFpf327d31JjZ9uyHA6sK2xcJqR5y1va6EhSRoSTODgU3wDJaySEOD1IkCR6zczBUSx7eBoP/Hcbm45Udvq6sUkhvHjDKKJ7as01Wy2seVkdjG09bjmL0DQ474/qciHanm/VKKgr4JXtr/BNVvOkixo0XJh8IdMTpjMreRZ6bc//U1QUhbqVK6n44EMsGza0OB8waxYhN92IeUL3lycpzq5h/YLD5Ge0/Pv1DTAw5Jw4BkyIJjjK3K37CyFEX5IgSfSq6CAf/nP7eK55Yx37C2vbLasBfjt7AL+cloauJxIFKgoppSvQv/YwWI6bSRUxCM7/k5r4sRe6tXJrcnlj1xsszl7couVodORo/m/a/xFh7p2UBva8PGq++YbSF19q9bxp4EDi/vl/3V5ctqHewZHdZexfW0jBoaoW56NTA7EHFnP1HVMxdiOhpBBCnCokSBK9qqLezo1vbSCjuP0ACQAN3DAuofUAqSwT/nMh3L4Uwvt1fK/aYnTfPMjwvOO6l9LOg9E/h0GX9UrLkd1l5x+b/8EnGZ80O67T6JiTMoc7ht5Bv5BO1L+rz83Lo3b5CurXr6P+hx9bnNeYTITdeSchN97Q7en79gYnGxZksXt1XotzJrOe5OHhjJqZSGCkicWLF8ssNSHEaU+CJNFrMktq+fm/N5Nf1XL2VGsUBZbtK+bG1gZq7/4M6kvVZUGmP972TRwN8P1fYcNraJsOGU+/SG05iurZBV6PsTgsLMhcwNObnm5x7uZBN3PH0DuINEf26DMVRcF28BDFzzyNZX3L7jQAn+HDMY8bS+RDD6ExdG/x16oSC/vXFrJvbQENdc0HuvsGGhk9K5HBU2Ix+qo/TrqacVsIIU5VEiSJXrFwRz6/+d9OnI0Dtg06DU6X4glbdFoNLrfi+Qpq9u1vdxW2HiTt/VL9uufLtoOk7B/hi19AXXGzw87LXkM/+uae+FgtlFnL+Prw160uNhtgCOBfs//F4LDBPfpMV1091V98TvHTz7R6XhccTOCcOYTcfFO3u9QAqootbFiYxeHtJc2mKGo0kDw8nEGTY0gaFo5W1lATQpyhJEgSPW7B9nwe+d8Ojk1oSwjxJa/S6vk9q9FAvwh/fnfRAJ5ZcoBDJXUoipp9e93hMqotDoLMTVo9yg55Z6OVZahdb0273Eoz4Ls/QOaKZvVwp0xnhfkyZgy7rsc/4+Gqw/z3wH/5NOPTFueSApO4PO1y7hp+V48+056TQ9kbb1KzaFGr66j5DB5M9Lx5+Awc0O1WI4D8g5XsX1tIxsaiFucSh4Qx8fJUIhJlDTUhxJlPgiTRo95cc5hnlh7w5EIaGB3ATRMS+fPCvc1yHz1+0UBMeh2T08J5dukB/rP2CBrUQGn5/mKuGRPvvem+haDRguJWv+5fCOf8Ru2fW/k3+PGfzSvhGwpXvI4r9Xysixf36OfbWbqTx394nLy6luNyJsdO5hdDf8H4mPE9+sz6jZsoefbZVtdRM8THY0xNIWbePAwxMd1+hqIo5OwuZ8uSIxRn1zQ7pzdoGTYjnsFTYmWWmhDirCJBkugRNqeLX324jZUHSjzHLhgUyeu3jOHu97cAEOCjZ/4NIzlvoDf3kY9Bx18uHcLUfuE8/OkOahqcLN5d2DxI2vuVNwOl4la73MbdCcv+CNveb16R2U/B+HtAp4ceHBtT2VDJ81ufZ0HmgmbH9Ro9U+Km8KsRv2JIeM+Od6r6agHVX32FZdOmZsc1RiOBl1xCyA3X4zNs2AkNkK4pt3JoczEHNxVTUVDf4ny/MZFMvrqfrKMmhDgrSZAkTliDw8UVr65ttibbzycl8ZdLh6DVasgormViahgv3TCSyMBWftk6Gjjf7wirr/dl/oqDlBQcgaMu9Zy1Eor3NC9fvAdeGg2WMu+xkBS48BnwDQG3Uw2SekC1rZrXdrzGwsMLqXd4gwiz3sxFKRfx61G/Jty3e7PF2mI7fJj8R36DLSOj2XFtUBAh111L6K23oo84sfQB1jo7O5YfZdt3R1uc8w00MmB8FCNnJuIXZDqh5wghxOlMgiRxQpwuN7f/Z3OzAOmf147g6iYtQcsfnobZqGu7xWPbe7DkMUKBvx479u8m5491tTXVNEACqMyG/16vbl/0HEy4pzsfx8PpdvJpxqe8uO1FrE7v7DydRsevRvyK24fejlHXczmAFEWhbtUqSl9+Bdv+/S3ORzzyCGG333ZCY40AyvLq2PNDPgfWFeJyNn+nobF+jJqZSPr4KFkuRAghkCBJnACny80vP9zK+ixvosbnrxvBVaPjm5XzM3XwbTb651CeCZvegtZWezs+QGpV43Xj71Hv101Wp5UFmQt4e9fblFpLm52L9I3kwzkfEuPf/bE/x1MUhbrvv6f83Xexbtna7JzGYCD8gfsJ+8Uv0JxATifFrbB/fSGZW0vI3dc847hGq2HQ5BjSx0URmx4suY2EEKKJUzpIcjqdzJ07l48++oiioiJiYmK47bbb+OMf/4i28ZeGoijMmzePt956i8rKSiZMmMCrr77KkCG9kw9HqJwuN4/8bycr9nvHIL1xyxguHBrd9ZsZfGDOPyB1Biz4Jdjr1S6zztLowOQPV74JAy4C4Ej1Ee5eejf3+dzXqVscazl6c+ebVNqaL7ExPX46D415iLTg7k+nP57bbqfinXeoXrAQe05Os3PaoCD8Jk8i+s9/Rh/S/bXcrHV2tn13lB3LW3apoYEBE6IZOyeZ4EgZjC2EEK05pYOkZ599ljfeeIP33nuPIUOGsGXLFm6//XaCgoJ48MEHAXjuued4/vnneffdd0lPT+fvf/87M2fOJCMjg4AAmabcGxRF4c73t7A6Q21p0Ws1vHLTqO4FSE0NnAP3boDPfwFH13X+usSJcPW/IDDWc2hx9mIqGiqgE+ON/5fxP97c9SYllpJmx8dHj+fu4XczIWZC5+vSAevu3dQs+paqL7/EXds8C7k2MJCIBx4g+Oqrur3QLIDT7mLbsqNsX5aD0968FU5v1DLu4hQGTIjGL1jGGwkhRHtO6SBp/fr1XH755Vx88cUAJCcn89///pctW9TZUoqiMH/+fJ544gmuuuoqAN577z2ioqL4+OOPueee1sel2Gw2bDabZ7+mRp3y7HA4eiVb8LF7nimZiF9eddgTIAE8ecVgzh8Q3jOfzzcCbv4KzYJ70O1fQNPOHxc63Bp9k7XWNDDtMZh4L2h1zWazfZ/9PUbUMUNt1etg5UFe2P4CG4s2Njs+NnIs9464l5ERI9u9vrMURcG6YSNVH32IZc0PLQvo9UTOm0vAnDlo9HpcgKsbz1QUhcNbS9nwVTaWGnuzcwmDQkgYHMKQc2PRNCZ/7K3vxzPt+/10Iu++b8h77zu9/c41iqIoHRfrG8888wxvvPEGy5YtIz09nZ07dzJr1izmz5/PjTfeSFZWFmlpaWzbto1Ro0Z5rrv88ssJDg7mvffea/W+c+fOZd68eS2Of/zxx5jN0vXQnh3lGv5zUOfZvznNxfjInv0WGljwOQOKv/bsuzQGtifeSX7opB65v8VtYVXDKjbaN+LG29KSpEviXJ9zSden98zYHEUhcOtWQleuwlhe3uJ0zfDhVE8YjzUt7YQW2VXc0FCqo+awCUe1rtk53xgHgf1tGPxO2X/mQgjRbRaLhZtuuonq6moCAwN7/P6ndEvS7373O6qrqxk4cCA6nQ6Xy8WTTz7JjTfeCEBRkZoROCoqqtl1UVFR5Bw3zqOp3//+9zzyyCOe/ZqaGhISEpg1a1avvGSHw8Hy5cuZOXMmhhOcndSXMkvq+N0bG6AxsLj7nGQenZXeo8/Q/vRPdNu9AZIbDW40jMj9DyNy/9PygouehZHNlxx5b+97vLXrLfSKnt8F/47yxHJ+NvRnKIrCyryVvLD5Bcrt3qAl2hzNr0f8mjkpc3rkMygOB7WLFlHx+hs4Cwubf76AAAKvvJKgn92CIfoEuyeBnN3lbFiQTXVJ8/XxYvoHMfmqVMLi/U/4GV11pny/n47k3fcNee99p7yV/wHtSad0kPTpp5/y4Ycf8vHHHzNkyBB27NjBQw89RGxsLD//uXcG0/H/168oSrstASaTCZOp5XgMg8HQq9/gvX3/3pRbYeH297bR4FADpPMHRvL4RYN7bt0uRYF1L8GapgvEatCioFXs6uBst0vtVnM35lDS6GD/Ahh3W7NbLTm6hAalwdPdtvzocq4YdAVPbXyK74585ymn1+q5bcht3D38bnz13R8D1FTd2rXk/epeFHvz7i5jWhpht99G4KWXom3le68rFEUhd18FG7/JpuRI8+zY/iEmJlyeyoAJ0X0+U+10/n4/3cm77xvy3k++3n7fp3SQ9Oijj/L4449zww03ADBs2DBycnJ4+umn+fnPf0504/+JH5v5dkxJSUmL1iVxYn7/5W6KahoASA334/nrR/ZcgORywKKHYPuHTQ42SQWg0UD4ALhgLiz/C7byA+w3GNSzBRsg9wcwqYP0q23VHKw86L214mJ/9X4u+OwCHG5v3/XQ8KHcMfQOInwj0GpOPCeQoiiUv/EGpS++1PyEXk/c8/8kcNasE35GdamFw9tLOby1hJKc5oO+w+L9GXdxMinDwyXHkRBC9JBTOkiyWCyeqf7H6HQ63G61NSMlJYXo6GiWL1/uGZNkt9tZs2YNzz777Emv75nq3z9l81Ommrwx1M/Ix3dNJMi3h6J3pw3+Mwfyt3iPJU6Co+vx5j76JcycB3oTpEzj869/zjN1TdYxW9l8mr8GDQoKbty8VfcWLly4jrU+NdpTtodHVqtdro+Pf5ybBzXvsusK6569FD/9NNat3jxHpkGDCP35rQRdfvkJt+hUFNSzZckRDm0ubnHOP8TE2DnJDJ7iHZAthBCiZ5zSQdKll17Kk08+SWJiIkOGDGH79u08//zz3HHHHYDazfbQQw/x1FNP0b9/f/r3789TTz2F2Wzmpptu6uPanxn+/VM2f13kDUj+dMkgooN6aB2v+nL4+LrmAdKlL8GBReq2TxBc9Rakz/aeN/hwzRXvc3T5g3xcvFbtpju+u7WxBcqBg3xXfrtVuGngTVyTfg0Atuxscm75GUkffoApJaXD6iuKQuV//0vx3/7uXVsOCLvrTiIeeOCEsmMrikLOnnJ2rcwld39li/NBkb6MmpnIwIkx6AzSciSEEL3hlA6SXn75Zf70pz9x7733UlJSQmxsLPfccw9//vOfPWUee+wxrFYr9957ryeZ5LJlyyRHUg/YnVfNP77zrh927Zh4rhwV384VXVCRBe9fDlWNiQ51RrjuAxhwIfzwD0g+R819FNBycLNJZ+L3F77BxIwveWL9XCyKG1cXWmt0Gh1mvZmnznmK6QnTPcdrFn2Lq7ycmm8XE/Hr9pNQ1q1ZQ8k/n8d20Nu1pwsNJXruX06oa01RFLJ3lrF9WQ5FWTUtzkcmBTDpyjTiB4Z2+xlCCCE655QOkgICApg/fz7z589vs4xGo2Hu3LnMnTv3pNXrbFBRb+eO9zZjdajdVBNTQ3n26uE9c/PKI/DeZVCdq+5rtHDjJ9DvfHX/3g1g9OtwWvyMAVfxVfxkHlvzKNtKd7RaZqB+IFnOLOx4B1KPjBzJs+c8S5Rf83FrNYsXe762FSS5LRaK5v2V6oULmx0PueUWIh/97QkNyi7Lq2X1RxkUZzcPjnwDDAycGMOASdGExZ782WpCCHG2OqWDJNE3FEXhd1/sorRWTbg5ICqAd34+rmcGah/dCP+9AayNa4iZw+H2xRAxwFvG1PlAIMovmjdmvsWcr+ZQZm2+6K0BA7f438Lfqv4GqGOV7h91P3cMvQOdtnk+IVtWNvbsbADsWVnYsrObdbkpikL1Vwsofuop3HV1za6NeeZpgq+4otN1Pp69wcnaLzLZ92NBs+MBoT6Mnp3IwMkx6A26Nq4WQgjRWyRIEi28sPwgy/epg4RNei3/uX1cx4vUdkbuZnjvUnA1ZjsPiIXbFkFY99dEO1h5kEfXPNoiQALQ0nKsztXpV7cIkABqly0DrRbcbtBqqV22HNM9dwPgLCuj8M9/oW7lSu8FOh3hv/oVYXf+Aq1P98ZoOe0uNizMYuf3uc2Om8x6Jl/Vj4GTY3puBqEQQogukyBJNPPToTJeWpnp2f/HtSOIDe6BHEL7voYFv/IGSDEj4IaPIah7Y5wUReE/e//DC1tf6Pw1KKw8utIzULupmiVLvIOv3W5qliwh7O67qF6wkJL/+z9cTRKWmSdOJOr3v8dnQPcTaWbvLOWnzw5RU9bQ7PjYOcmMmpWI0Uf+aQohRF+Tn8TCo6DKyoOfbPfs339ePy4bEdvOFZ10aAX872fe/YSJ8LMv1XFH3VBrr2Xe+nnNEkMatAacbqdnZptOo/OkWQIwOBXSijXsXvkZc+pSm93PVVWNLSOj2THbgQMcueFGGnbu9BzTms2E3HYb/lOnYkxO6nK9FbfCgQ1F7FmT1yLPkTnQyNTr+tN/rOT3EkKIU4UESQIAt1vhgf9up7xeHeA8LjmEhy7ogSVH9i2E/93q3Q+Mg1s+73aAVFhXyF3L7yKnxrvszKWpl7Ioa5EnQNKgITUolQdHPkjVjio0aDh/h8Idy13ALnJoJSeSRtNsGj/QLEACddB2+WuvUf7aa0Q98QShP7ul0/Uuz69jxbv7KMuta3Hu6sfGEJ0a1Ol7CSGEODkkSBIA/OunLLbkqPl44oJ9efNnY9Gd6HiY/K2w4F7vfvx4uHVBtwOkzMpM7l95P3l1eYC6rMgfJvwBg9bAN1nfeJJI3jzoZh4e8zAat4bFOxZz3YDr+K/zPWIqNFy0VQ2lWnyyLqzzHHLLLQRfd22nyrocbjZ+ncWOFUdbPGL8pSmMnpUkeY6EEOIUJUGS4GBxLU8vOeDZf/LKoYT6GU/sphlL1BYkV+PU+5Rz4ebP1azZ3bC5aDN3fHeHZz/UJ5R/zfoX/UP6c+8KNRALMAbw9DlPc278uQCeZUgeGvMQ4+PG8wfzH9iVUsVD32ox2RVwuVo+qC06HVqzmdhnnyXgvBkdFlcUhSO7y1nz0QHqq73pB3z8DIy7JIUhU2MlOBJCiFOcBEmCRz/f5WnluGxELNMHRJ7YDWuL4ct7vAFS5GC4/qNuBUiKovDvPf/m5e0vNzv+wUUfkBiYCEBmVSbjosfx7DnPEmGOaPU+0xKm8dXlX/G7kN/xVOpRnlsZg3XL1lbLtsY8ahSx//w/DJ1YE7CioJ7VHx+gMLO62fH+46KYfvMAGZQthBCnCflpfZb7dlchO3OrAIgO9OHpq4ad2A3dbvj2EbA1BghRw+AX33Wri83isDB33VyWHFniOZYcmMwr57/iCZAAFly+AF+9b4drpEWaI/n37H9jdVrxuUlL/kMPU7d6dfuV0GiIePBBwu66E42u/VxFDruLtZ9nsveH5kuhhESbOeeGdBIkS7YQQpxWJEg6i9mdbv66aK9n/7ELB5x4PqTv/uBde83o3+1B2gcrD/LI6keaDdC+fsD1PDbuMYy65l2BZoO50/fVaDS4N2wj4667On1N8HXXdhgg5WVUsuxfe7DWOrz1CjQyalYiw2fEo9VJ15oQQpxuJEg6i7255jDFNWreomFxQVw5Ku7EbrjmOdj4unf/itdaXXutI9tLtnPvinupc6gzwUw6E78b/zuuTe/cYOm2KIpC6fwXKX/zza5cRO2KFYRcd12rp21WJz98ksHBjcXNjscNCOGiXw7D5Cv/xIQQ4nQlP8HPUg0OFx9vOurZn3f5kA67q9pVkQWrnvTun/8XGHx5l2+zrmAd9664F5eiDqqO9Ytl/oz5DAob1P26AY6SEgoe+Q2WLVuan2g69V+nUwdzH/sKoNVSs/S7VoOkyqJ6Fs7fQX2VzXPML9jEjFsGkjQ07ITqK4QQou9JkHSWenNNFoXVarbn4fFBjE4M6f7NFAUWPezdT50O5zzS5dtsLNzIr7//tSdASg9J590L3yXAGND9ugHWrVspvO/XuOvrPccCL72UmkWLPAGSxRzFtjG/Yc6l/jS8/QL2zEz1nNuNZcMGXNXV6ILUXEaKorB/bSGrPjzQ7DljLkxi3KUp6KRrTQghzgjy0/wsVFFv59XV3qVHTniw9vI/QdZqddsnCK59t+u3yFnOPcvv8UzbHx89no8v/viEAiRFUQj+6Sfy77zLEyBp/fyIf+01/CZNUoOgxtaz6gvuwK7zI1+bTMrnnxFyLFGkRgNuN7UrVwHqemvfv7e/WYAUEOrD1Y+NYeIVaRIgCSHEGUR+op+F3lhzGLvTDcC1Y+IZEnsC2Z7XvgTrmkzPv/w18O1aq9TKoyv5zerfeFqQRkSM4NXzX8Wk615OJQBnaSn5t91G5DeLwOkEwHfECNKWfUfAeTOoWboUAG1AAPFvvE6hWc0unrmlGK3JRPQf/kD866+hDVCDtNqlS8naXsp7f1hHxoYiz3NSR0VwzeNjJWO2EEKcgSRIOsuU1DTw0QZ1xpheq+HX5/Xr/s0Or4IVc737Ux6EQZd06Rb7y/fz+I+Pe5YUmRo3lbdmvoWP3qfb1bJs3szh2RfSsM27Dl3AzJkkvvsf9GHqWCFb5iHM48eTuugbnAPHUVVkAaCyyEJVsbodMGMGqd98g3vC+ay1jGHJm7tpqGucvaaBaTcN4KJ7hmEOPMHEm0IIIU5JMibpLPPmD1nU29UWm4uHx5AU1r0lQqgvhy9+AY2tP4y7E2b+tUu3OFJ9hDuX3YnVaQVgRsIMXpzx4gkNIK/+9lsKfvPbZseinn2G0MubDyJP++YbNGYzGo2Gw0uOeMZvazRweHsJYy5MxuVys3uHlfW+VzW7NjIpgHNuSCc6RVqPhBDiTCZB0lmk3ubksy25AOi0Gh67cGD3bqQo8OVdYClX92NHw0XPdekWTreTh1Y9RI29BoBBoYN45pxnTihAqvriCwr/+CfPviEpiUNXXkm/OXNalNX6eYPDzC3FngluigKHtpQQlRzIyvcPUFvR0Oy6GbcMZNCUmBObCSiEEOK0IEHSWeTzrXnUNKjjcy4fGUtcsG/3brT2RTj8vbpt9Idr3gFt+8kWj/eXdX/hcPVhQF1z7fULXu9SUsimFJeL0pdebpb/KGDmBUQ++yx7ly/H6XBRdtTS6iK2DRYn5fn1zY6V59WxcP6OZsdCYsxMuiINH38jLqcbvaFrn1cIIcTpR4Kks8inm3M92zdPSOreTbJ/gO+bdKtd/S8ITe3SLf6z5z98ffhrAHQaHS/OeJEw3+7lFXLV1ZF7191Yt3vHHwVecgmxzz2LszHXUcaGItb+L6vtm2iAlvFTM5WFFha/vhuAc67vz/AZCd2qrxBCiNOHDNw+S6w7XMa+QrVrKz3KnzFJ3ciL5LTDNw96xyFN+jUMuKhLt8ioyOD5rc979h8Z8wjjosd1vS6ALTub7KuubhYgBV97DbH/eA6N1vutPWBiNMOmt5NNvIMAqalhM+IZPDW2O9UVQghxmpGWpLPEe+uOeLbvPKdrLT8ea19UM2sDRA6GC+Z16fI6ex2P//i4Z/+ytMu4dcit3apK/YYN5N57H4pFnYmGwUD8Sy8SMGNGi7J6g45zbxhAwqBQVry7H4fNheLufGSk0WowmHRccPtgUoaHd6u+QgghTj/SknQWOFJWz7J96tpiEQEmrhjZjTXaagph3Uve/UtfAl3nY2y34ubu5XeTWaUmsYz2i+aPE//Y9XqgzmA7etfdngBJHxND6pdftBogNZUyIoIb/zyB6NTALj0vJi2IG/88QQIkIYQ4y0iQdBb4eNNRz5jl2yYnY9R346990cNgU7vrGHYtJHSti+xvG/7G7jJ1TI9JZ+K181/DV9+1geOKolD68isUPPoYONR8RaZBg0hduABT//6duod/iInxl6Rg9O3EwGsNTLg8lcsfHoV/SPcTWwohhDg9SXfbGc5id/JhY/JIrQauGt2NVqQ9X8LBJeq2ORwufLZLl6/NX8sXB7/w7D8//Xn6h3QuqDnGVVdH3n2/xrJxo+eY3+TJxL/xOlpj55M57v0xn9UfZXS6/JCpsWi1Mt1fCCHORtKSdIZbsL0AS2PyyBkDIokJ6uK0f3s9LP+zd3/W38Gv8zPRcmtym2XUvjztcs6NP7dLVXAUF3PkmmubBUiht91Gwjv/6lKAtGXJkS4FSCiQtaO0K1UVQghxBpEg6Qz36RbvtP9fTk/r+g3WvwrVjfdIOw9G3tjpS20uGw+vfpgqWxWgLlr71yldy8rtKCgg58absB85AoDGYCD22WeIevx3nU7oqCgKmxZls3GhNw2Aydy8EVWjbf4V1OzbmVtLulRfIYQQZw4Jks5gh4pr2ZlbBUBymJmxXZ32X18G617x7s9+qkuX/2ntn8ioVFtuYvxi+Me0f6DVdP5bznboENnXXY+joAAAbVAQSR9/TNBxS4y0x22Hxa/sYfOibM+x5GFh2KxObyENhET7cfF9wwmJ9lPzJqHmnsw/WElDvaPTzxNCCHHmkDFJZ7B3m0z7v3JUfNeX0ljxF7BVq9uDLoPIQZ2+9JvD37AkWx3H5KPz4f+m/R+hPqGdvt5RVETO7XfgKisDQBcURPKnn2BMTu70PapKLBT96IfbXuU5NmpWIsFRZo7sLvccGz4jnslX9kNn0BI/MIT1Xx1m18o8ABQ3HNlVxsBJMZ1+rhBCiDODtCSdoRwuN4t2FXr2b5qQ2LUb1BbDjo/VbVMgXPhMpy/dV76Pv6z7i2f/z5P+zPCI4Z2+3t3QQP7Dj3gCJH1MDEkff9SlAKmmzMqil3bjtqvf4iaznpm/GMzkq/qRtb3Uc+zi+4ZzznXp6AxqOb1BxznXpXPxvcM9XXLS5SaEEGenTrUkhYZ2vgUAQKPRsG3bNpKSurn0hThhS/cUUW1Vu4mm9AsjIqCLU9h/+IfajAIw+lYI6tysuNyaXO5Zfg8Ot/rsi5Iv4pLUSzr9WEVRyP/tbz1ZtHVhYSR/+AGGuM7PysvZW853b+/B0aAOWPcLMXHFQ6MIjlLXhisvqCMuPZiZvxiCX1Dr7yV5eDg3/nkCy/69l4qC+lbLCCGEOLN1Kkiqqqpi/vz5BAUFdVhWURTuvfdeXI3rZom+seqAt/XjV9P6de3i/G2w+V/qtkYHE37ZqcuyqrO4bcltnoHa6SHpzJ08t0vdfCXPPEPdisbFc7Va4v75zy4FSNu+y2H9V4c9+1qTm8seHO4JkABu/PMEDCZdh/XyCzZxxcOjcNjke1kIIc5GnR6TdMMNNxAZGdmpsvfff3+3KyROnMut8H1jkORj0DIupQsDtt1u+OYBPAuaTfwVBHe8mGuNvYZ7V9xLpa0SUAdqvzXzLcwGcwdXqhRFofTFF6l4733PsZgnn8Rv4oROV/2nzw6x83vvbL64AcG4Y/MICPNpVs7o0/mheBqNpkvlhRBCnDk69dPf7XZ36aa1tbXdqozoGduPVnq62s7tH4FJ34ns0sfs/gyK1MzYBCfC9N93eImiKPxm9W/Ir8sHIMocxX8u/A9hvp3Pp1T28suUv/GmZz/iwQcIvvKKTl2rKArrvshsFiANPTeOiVensHRpbjtXCiGEEG2TgdtnoK93Fni2Zw2J7vyF1kpY1mQ9tQvmgcm/w8ve3/c+Gwo3AOBn8ONfs/5FnH/nu8hqli6l7LXXPfsRDz5A+K9+1enr132RyY4V3mAocXAo596YLpmyhRBCnJBuB0m1tbU8+uijjBs3jtGjR3P//fdT1jgbSfSt7/erXW1GvZaZg6M6f+Ga56C+cSxT/DgYcmWHlxysPMirO1717M+bPI/koOROP7J+/XryH3rYsx/x0EOdDpDcboUNCw83C5BGX5jEpQ+M7Hq6AyGEEOI43R5scdddd+Hr68u8efNwOBy89dZb3HzzzXz33Xc9WT/RRflVVvKrrACMTAgmyNfQuQstFbDl3+q2Vg9XvK6mnG6HW3Ezb/08rE71eVf3v5rZybM7XVdHURF5Dzzo2Q+YNYuwe+7u1LWKW2HFf/ZxaHOx59jkq/sxamYXUx0IIYQQbeh0kPTCCy/w0EMPef4PffPmzRw8eBCdTh3vMmDAACZOnNg7tRSdtnxvkWd7QkoXUjf89AI4G9TtkTdDeMcL0P4v43/sKt0FQKhPKI+Ne6zTj1MUhaK/zMXdOH7NZ8gQYp9+qtMtQCvf398sQJpweaoESEIIIXpUp4OkzMxMJkyYwJtvvsmoUaOYOXMmF198MVdccQUOh4MPPviA2bM734ogeseCHd7xSBcO7eR4pPoy2Ng4aFqjg3Me6fCSgroCntnkTTD55NQnOz2TDaDyo4+pW7MGAF14OAn/ehutn1+nrt269AgHNniDwfNuHcigybGdfrYQQgjRGZ0Okl599VXWr1/PHXfcwYwZM3j66af58MMPWb58OS6Xi2uvvZZf//rXvVlX0YHimgZ2NK7VlhRmZnBMYOcuXPEXcNnU7TG3QUhyu8VdbhePrnkUl6LmD7os7TKmxk3tdD0t27ZR/Oyznv2oxx9HH9K5NAVZO0qbLVQ7/eYBEiAJIYToFV0akzRp0iQ2b97MM888w6RJk/jHP/7BF1980Vt1E120fJ+3++nCIdGd67qqzocd/1W3tXqYdF+HlyzOXsyuMrWbLdI3skvdbM7SUnWgtkNNURByyy0EXXJxp67dv66Ale8f8OyPvCCBIed0fhadEEII0RVdnt2m1+v54x//yDfffMP8+fO55pprKCoq6vhC0et+PFTq2Z41pJOz2ja8Bo0tQoy7E8LS2i1udVr5x+Z/ePb/NOlPBJk6zsQO4Kqr5+hdd+MsUWfQmdLTiXr8d526NmNDYbMAKWFQCJOv6mImcSGEEKILOh0k7d69m/HjxxMQEMCUKVNwu918//33zJkzh8mTJ/P66693fBPRa1xuhQ1ZFQAE+RoYmdCJ7itHA2x9V93WGmBqx2OR3t37rier9qDQQUyLn9bpOhY/+SS2A2qgowsLI+Htt9HoO27MzN5VxvdNAqSQGD8u+tVwNJIHSQghRC/qdJB0++23M3XqVDZv3sy1117LL3+prud1xx13sHHjRn766ScmTZrUaxUV7duVV+XJsj0pNQxdZwKI7R+AvU7dTp8NAe23PlU2VPLR/o88+11Zl6121Sqqv/oKAI3ZTOLbb2GI6niZm7wDFSx9YzeKW10mZeDEaG7803gMxi5kERdCCCG6odNjkjIyMvjkk0/o168f/fv3Z/78+Z5zERERfPTRRyxbtqw36ig6YWN2hWd7Sr9OLAeiKN5WJICpD7dZFNScSE/89ATVtmoALkq+iMFhgztVN1ddHcV/f9KzH/7LX+IzuONrK4vqWfbOXtyNAVLa6Aim/2ygtCAJIYQ4KTodJE2fPp27776bG264gZUrVzJlypQWZWbNmtWjlROdt7IxyzbAhNROBEkHl0LxHnU7dhTEj223+JeHvuTH/B8B8NX7cv/ozi1irLjdFDz+OI58dV0308CBhN35iw6vyz9Yybev7sJhU8dLxaUHM+sXQ9DqZCUdIYQQJ0enf+O8//77jB49moULF5KamipjkE4h1RYHW3LUlqT4EF/6R3aw3pqiwGpvjiOmPNh2WdTB2k2XHnn2nGdJCEjosF6KolD0179St+J7ADRGI7HPPYtG2/63XcGhKha9vNMTIIVEm5l991AJkIQQQpxUnW5JCgkJ4f/+7/96sy6im77dXUhjjxTnD4zseJxQxhIo3KFuh/WHQZe1W/zJDU9SZlXX5ZueMJ0ZiTM6Va+Kf/+bqk8+VXe0WmKfew6f9PR2r6ksqufb13bhdLgBiEoJ5NL7R2Ayd3J5FSGEEKKHdOp/zXft2oXb7e70Tffu3YvT6ex2pUTXrMrwdrVdNrKDvEFuN6x+2rs//XHQtj0IOrMyk4WHFwJg0pl4aPRDnapT/YaNlPzDG1RH/eEPBF7Yfkb2mjIr37y8E7tV/d6JSw/msgdHSoAkhBCiT3QqSBo1ahTl5eWdvumkSZM4evRotyslOs9qd7EmQ82PFGI2MCohuP0LslZBkZoIkpBkGHxFm0UVReHJjd4B15ekXkJacPt5lAAUu53CP/zBsx98/fWE3nJzu9c4HS4WvbKT2nJ1/bjQWD8u+uUwjD7dXoNZCCGEOCGd+g2kKAp/+tOfMJs7tzaX3W4/oUqJztuRW4XdpbbynZsegbajmV8bmowlO/cx0LX9LbDi6Aq2FG/x7D867tFO1anob3/DUaCuIec7YgTRf/5Th9es/jCDyiKLek2AgUt+LV1sQggh+langqRzzz2XjIyMTt900qRJ+Pr6drtSovO2HPFO/Z/aL7z9wjUFcHiluh0QC8Ova7Oo0+1slln7b1P+hp+h4wVoa7//nqrPPld3dDoif/c7NLr2cxqt/fwQGRu9Wdsv+fUIAkJ9OnyWEEII0Zs6FSStXr26l6shumv1Qe9SJOOSQ9svvO0D7xIko24GXdstNe/ufZfC+kIA+of05/K0yzusi7uhgcK5cz37YXffhXn0qHavydhYxI4VuZ79SVelEZnUyYV5hRBCiF4kc6pPY0XVDWzNUZcISQn3Iymsg+7QfQu826N+1maxgroC3tn9jmf/9+N/36nM2pUffYSrVJ0F5zNiOBG//nW75RvqHfz46UHP/vhLUxg9K6nD5wghhBAngwRJp7Hl+7xdVJeOiG0/kCnNgJJ96nbcWAhpOxj564a/UudQlyu5MPlCxkWP67AuDRkHKX3xJc9+zNy57XazKYrCgue3YbM0zmQbEMK4i1M6fI4QQghxskiQdBpb0STL9qzB7a+7xq5PvdtDrmyz2OaizazNXwtAqE8of5rU8aBrt9VK/oMPojQO2A+46EJ8Bg1q95oti49Qnl8PgEYD028a0OFzhBBCiJNJgqTTlM3pYkOWmpYhIsDEkNh2xvG4nLDtfe/+kCtaLaYoCs9s8mbivnv43QQaOx4fVPbqq9iPHAHAEBtLzN/+1m75I7vK2PRNtmf//NsGExzVuZmTQgghxMkiQdJp6kBhLTanOvV/SlpY+11tR36E+sYB3gMvgaD4VottLNrIwUp1jFByYDLXD7i+w3o4y8qo/O8n6o5GQ/wrL6Pzb3tZlNLcWpa8tduzP2x6PAMmRHf4HCGEEOJk63KQ9N577/Htt9969h977DGCg4OZPHkyOTk5PVo50bbtRys928Pig9svnLnCu93OEiSLsxZ7tu8cdid6bfuTHxVFofAvc3HXq91mwddcg8/gwW2WdzndLH1zN26nuoZK6sgIpl7Xv/26CyGEEH2ky0HSU0895cmBtH79el555RWee+45wsPDefjhh3u8gvn5+dxyyy2EhYVhNpsZOXIkW7du9ZxXFIW5c+cSGxuLr68v06dPZ+/evT1ej1PNt7sLPdsTU9uZ+u92w76FjTsa6HdBq8UsDgvfZqnBr4/Oh5lJMzusQ9nLr1D3vbp4rTYggIgHH2i3/O7VedSUqRm1/UNNnH/boI6TXwohhBB9pMtBUm5uLv369QNgwYIFXHPNNdx99908/fTT/Pjjjz1aucrKSqZMmYLBYGDJkiXs27ePf/7znwQHB3vKPPfcczz//PO88sorbN68mejoaGbOnEltbW2P1uVUUmWxs6Vx6n9qhB+DY9oZN5S9Gqob8xClTge/sFaLLc9Zjt2tDryelTwLs6H9MULWPXspe+01z370X/6CPrztZJbWOjtbFh/x7M+8Y4gsOSKEEOKU1uXfUv7+/pSXl5OYmMiyZcs8rUc+Pj5YrdYerdyzzz5LQkIC//nPfzzHkpOTPduKojB//nyeeOIJrrrqKkDtDoyKiuLjjz/mnnvu6dH6nCrWHCxFUXusOG9AZPvjkba+690ecUOrRRRF4b8H/uvZv6r/Ve0+X3G7KWyy1EjobbcRdMnF7V7zwycHPdP9U0aEE9svuN3yQgghRF/rcpA0c+ZM7rzzTkaNGsXBgwe5+GL1l+PevXubBTA94euvv2b27Nlce+21rFmzhri4OO69917uuusuALKzsykqKmLWrFmea0wmE9OmTWPdunVtBkk2mw2bzebZr6mpAcDhcOBwOHr0Mxy7b9OvJ2pTlnex4QkpwW3ft64EfcYSNIDiG4Iz/WJopezagrXsLVe7KKPMUQwLGdZuXWsWLsS2bz8A+vh4gn99X7vld63MI3OLmq7AYNIx6erUXnnPx+vp9y46R95735F33zfkvfed3n7nXQ6SXn31Vf74xz+Sm5vLF198QViY2n2zdetWbrzxxh6tXFZWFq+//jqPPPIIf/jDH9i0aRMPPPAAJpOJW2+9laIiNZliVFTzHEFRUVHtDiJ/+umnmTdvXovjy5Yt6/Qivt2xfPnyHrnPj3t1gNp6VLp/M4szWy+XUrqM4S61C+2I32h2LVvZooyiKLxe5130dipTWbJkSZvP1jgcpD71NMfSRB6ZOZN9jeOSWmOr0lK63rvmm1+/en5Y33b53tBT7110jbz3viPvvm/Iez/5LBZLr95foyjHOm5OPUajkbFjx7Ju3TrPsQceeIDNmzezfv161q1bx5QpUygoKCAmJsZT5q677iI3N5elS5e2et/WWpISEhIoKysjMLDn1w1zOBwsX76cmTNnYjCc2Mr2dqebkX//HodLISnUzIqHp7ZZVvfexWjzNgLgvH0ZSuzoFmV2le3itmW3ARDuG863l3+LQdt2HSvefIuKV14BwHfSJGLffKPN7j6HzcVnT22lrkJ914OnxjD1+n6d+pw9oSffu+g8ee99R95935D33nfKy8uJiYmhurq6V35/d2vk7I8//sibb75JVlYWn332GXFxcXzwwQekpKQwdWrbv7S7KiYmhsHHTSkfNGgQX3zxBQDR0Wp+naKiomZBUklJSYvWpaZMJhMmk6nFcYPB0Kvf4D1x//3FVThcalw7KjG47ftV5kBjgERgPPrE8Wpq6+N8etCbifue4fdgNrXdkmbdsYOKN95Qd3Q6oh9/HKPR2Gb5NR8d8gRIYXF+nHvjAHS6k5+aq7f/XkXr5L33HXn3fUPe+8nX2++7y7+xvvjiC2bPno2vry/btm3ztMjU1tby1FNP9WjlpkyZQkZGRrNjBw8eJClJXXcsJSWF6OjoZk2cdrudNWvWMHny5B6ty6li/WHveKRRiSFtF8xe490ecFGrAVJRfRHLj6rvzqQzcVla2zmUFKeTgt//AZzq4OvQW27BZ0B6m+V3rcolY4PaHao3apl5x5A+CZCEEEKI7uryb62///3vvPHGG7z99tvNIrjJkyezbdu2Hq3cww8/zIYNG3jqqafIzMzk448/5q233uK+++4DQKPR8NBDD/HUU0/x1VdfsWfPHm677TbMZjM33XRTj9blVHFs6j/AmKR2gqS9X3m30y9stcinGZ/idKtBz7Xp17Y77b/yo4+wZ6tLiRji44l4pO2cWKVHa1n7mXeg1DnXpxMW13YWbiGEEOJU1OXutoyMDM4999wWxwMDA6mqquqJOnmMGzeOr776it///vf89a9/JSUlhfnz53PzzTd7yjz22GNYrVbuvfdeKisrmTBhAsuWLSMgIKBH63IqcLrcbD5SAUCAj77t/EgVWXB4lbodnAj9zm9RxOKw8NH+jwDQarT8bPDP2n5uWRmlL7/i2Y999hm0rXRXAlhr7Xz76k7cbrVLcNj0eAZPie3wswkhhBCnmi4HSTExMWRmZraY7v/TTz+RmpraU/XyuOSSS7jkkkvaPK/RaJg7dy5z587t8WefanbnV1NlUac7ntM/vO1s1fu/ARrH44+6tdWuti8OfYHVqea1Oj/xfGL92w5kSv7xD9x1dQAEzJqFecyYVsspisJ3/9pDfbU6oy4iMYApV5+8gdpCCCFET+pyd9s999zDgw8+yMaNG9FoNBQUFPDRRx/x29/+lnvvvbc36iga7Smo8WyPTWpnKZKsJuORBs5pcdqtuHlv73ue/TuG3tHmreo3bKR64dcAaM1mon7/eJtl9/1UQH5GFQAGHx0X3j0UnUHGIQkhhDg9dbkl6bHHHqO6upoZM2bQ0NDAueeei8lk4re//S2//vWve6OOotGWxq42gJGJwa0XstdD9g/qdkAsRAxqUeTHvB8pthQDMC56HEPDh7Z6K8Xlovjppz374ffdh6HJLMKmLDV21n3hHYd0wW2DCQz3be/jCCGEEKe0bqUAePLJJ3niiSfYt28fbrebwYMH4+8vA3N7k6IobMpWgyRfg45hcUGtF8z+AdyNGUj7nQ/ali05n2Z4p/1fP+D6Np9Z+dHH2BpnFxpTUgi9te1xSz99dgh7gwuA/uOiSB0Z0e7nEUIIIU51Xe4Lee+996ivr8dsNjN27FjGjx8vAdJJUFJro7C6AWjMj9TWdPqD33m3B1zU4nSZtYy1BWsBiDRHckHiBa3exlVTQ+lLL3n2Y/46D00b+SgObCjk0Ga1ZUqj1TDpyrQOP48QQghxqutykPTb3/6WyMhIbrjhBhYtWoSzMW+O6F37Cr3jkYbEtjGrTVHgUGPOKJ0JUqe3KPJpxqe4FTcAF6dejE6ra1EGoPxf73gGawfOuQjzuHGtlqsoqGfV+wc8+1Ou6UdAqE9HH0cIIYQ45XU5SCosLOTTTz9Fp9Nxww03EBMTw7333tts6RDR83bnVXu2h8S20dVWsB1q8tTt5Clg9Gt2uqqhyjNgW6vRck3/a1q9jaOwkIp331V3dDrC77+/zXqt+W+GZ7p/6sgIhs+I78SnEUIIIU59XQ6S9Ho9l1xyCR999BElJSXMnz+fnJwcZsyYQVqadLP0lu1HvUkkRyQEt17owCLv9sCLW5z+/NDnnmn/V/W/isTAxFZvU/KP/0Oxq9P4g6+6ClNKSqvlDm0upuBQFQB+wSYuuH1wm+u4CSGEEKebbg3cPsZsNjN79mwqKyvJyclh//79PVUv0YSiKBwoqgXUJJLJYa1kxna7YftH3v1+zccaKYrCgswFnv1r0ltvRWo4eJCaxYsB0Pr7E35f62kdHHYXP/7voGd/wmUpGEytd90JIYQQp6NuJbGxWCx89NFHzJkzh9jYWF544QWuuOIK9uzZ09P1E0BuhdUzaHtYXFDrrTU5a6FOXSuN2NEQktzs9N7yveTU5AAwPHw4Q8KGtPqsinfe8WyH3X03hsZFhI+3Y/lRrLXqLLro1EAGTmo9NYAQQghxuupyS9KNN97IN998g9ls5tprr2X16tVn7GKyp4otOd78SG2u15ax2Ls97NoWp5dmL/VsX9n/ylZv0XDggDdxZEAAITe0nh6gqsTCliVHPPvTbhoo3WxCCCHOOF0OkjQaDZ9++imzZ89Grz+h3jrRSce62gDGJreSaVtRIGOJd3/EDc1OW51Wvj78tWd/RsKMVp9T9Je5nu3Q229DF9hyFp3L6Wb5v/fhdqqDtUdekEB4vKSAEEIIcebpcpTz8ccf90Y9RDuW7Cn0bKeG+7UsUJEFldnqdsxIMDcPpJZmL6XSpg78nhw7mTDfsBa3qPtpLdadOwEwJCQQduedrdZlx4qjlBxR0xH4+BsYe3Hrg7qFEEKI012ngqSXXnqJu+++Gx8fH15qkmCwNQ888ECPVEx4HVvU1qTXEh/SylIfR9d7twe2XAz4uyPeBJN3Dms9+Kn497892+G//CVao7FlmYJ6Ni3K9uxfeNdQTL7SmiiEEOLM1KnfcC+88AI333wzPj4+vPDCC22W02g0EiT1sHqbk3qbmrDT5nS3Pvbn8ErvdvLUZqcqGipYV6DmsIrwjWBs1NgWl9syM6lvzHOlj4oi6IrLW63LhoWHPd1sg6fEEDegjfFRQgghxBmgU0FSdnZ2q9ui92UU19KYq5HrxraSqNHtgsOr1G2DGeJGNzu9MHMhCuoNLk69uNUgq+SF+Z7tkJtuQqNrOZX/yO4ysneWAaAzaJl8Tf9ufBohhBDi9NHlFAB//etfsVgsLY5brVb++te/9kilhNfhkjrP9oDoVpYjydsM1sbZb6kzQG9qdvrzg597ti9Lu6zF5a66eupWrwZAYzYTcv11Lcs43az/6rBn/9wb0qWbTQghxBmvy0HSvHnzqKura3HcYrEwb968HqmU8MqttHq2E0NbSSJ54Fvv9oALm53aW7aXo7VHATU3Uv+Qlq0/dSu/B5cLgKCL56ALDm5RZtOibCoK6gEIifFj0GTJiSSEEOLM1+UgSVGUVrtsdu7cSWhoK9PTxQnZ32Rh27SIVma25TRZM6//7GanFh5e6Nk+P+n8FpcqikLpi96B+IFz5rQok3+wkm1Lczz7590qOZGEEEKcHTrdZxISEoJGo0Gj0ZCent7sF6XL5aKuro5f/vKXvVLJs9mxIMnPqCM57LggyWmD4r3qdkgyBER5TjncDpYdWebZvyS15ay3msWLceTnA2AaPAjzhAnNzrvdCt+/611qZuTMRKJT2lhcVwghhDjDdDpImj9/PoqicMcddzBv3jyCgry/LI1GI8nJyUyaNKlXKnm2qrc5yWvsbusXFYBWe1wLTs46aFywlvjxzU5tLNxIeUM5AOfGn0ukObLZeUVRKH/rbc9++J13otE2b1jcuPAwtRXqcijhCf5MvCL1hD+TEEIIcbrodJD085//HICUlBQmT56MwWDotUoJ1e78as/2wKiAlgWyVnu305pn0V6d6z13UcpFLS6tXbYcW0YGAMbUVAIual6mtqKBXavyANBo4Nzr09HpurXUnxBCCHFa6lSQVFNTQ2DjEhWjRo3CarVitVpbLRvYylIWonsymixHMjS+lW6u3E3e7ZRzPZsOt4PF2epabgatgamxzXMnKYpCyT/+4dmPfOThZt2nbrfC8n/vxWl3AzBocgwx/YJP5KMIIYQQp51OBUkhISEUFhYSGRlJcHBwqwN3jw3odjXOlBInrqDKG4i2WI7EVge5G9Tt0DQI8uZQ2l68nVq7GmCdG38uwT7BzS61bNiAI09tJTL174//+c0HdR/aVERhptqK5RdsYuKVaT3xcYQQQojTSqeCpJUrV3pmrq1atapXKyS8ssrqPdstpv8f3QCK2tJD0uRmp1bnrfZsT4uf1uK+lR//17MddvfdzQfhO91s+vaIZ3/GLQPx9W+5RIkQQghxputUkDRt2rRWt0Xvym4Mkkx6LXHBx63Ztv9r73Y/b0uQy+1icZba1abT6JiR0HyskrOyktrvvwdAGxBA4OxZzc5nbi2hplRtwYrtH0ziEEnrIIQQ4uzU5ZG4S5cu5aeffvLsv/rqq4wcOZKbbrqJysrKHq3c2czpcpNTrgZJCaHmljPbDjVO79cZ1UzbjZYfXe6Z1XZO3Dktutoq3nkH3GoLVOAlF6NpspCt262w6Zssz/74S1MkJ5IQQoizVpeDpEcffZSaGjV3z+7du3nkkUeYM2cOWVlZPPLIIz1ewbNVXqUVh0tdcy09yr/5yYosqC1Ut+PHg2+w59RnGZ95tq9Ov7rZZc6KCio+/Ejd0WoJu+22ZueztpdSU6ZO+Y9MDiS2fzBCCCHE2arLC3BlZ2czePBgAL744gsuvfRSnnrqKbZt28acVjI2i+7JbjYe6bhB2wcWe7eTvLmpCuoK2Fy0GYA4/7gW45GqvvgCpUENgkJuuB5jUpLnnKIobF16xLM/5sIkaUUSQghxVutyS5LRaPQscLtixQpmzVLHtISGhnpamMSJO1jsnf4/IPq4lqSctd7tRG+QtDh7MQpq69NlaZc1C3IURaHma+84ppBbbml2y+ydZZTlqmvyhcb6kTIi/IQ/gxBCCHE663JL0tSpU3nkkUeYMmUKmzZt4tNPPwXg4MGDxMfHd3C16KzDpd5FhNMimgRJbrd3vTafIEid7jn1Q94Pnu2LUy9udj/Lhg3YDmUC4DtqFKbU5tmzty454tmWViQhhBCiGy1Jr7zyCnq9ns8//5zXX3+duLg4AJYsWcKFF17YwdWis3bnq61yWg2kNg2SSvZCQ5W6nTQFtDoASi2lbC/ZDkBCQAKJAYnN7td02n/wtdc2O5d3oIKSHLXlKjTWj/7johBCCCHOdl1uSUpMTGTRokUtjr/wwgs9UiEBDQ4XGUVqkJQeFYC/qclfU95m73aT/EgbizZ6ti9MvrB5V5vTSf369QBo/f0JvKR5K9PuNfme7VEzE6UVSQghhKAbQRKAy+ViwYIF7N+/H41Gw6BBg7j88svR6XQ9Xb+zUl6lBbc6tIgB0cet2dZ0KZKECZ7NrcVbPdtjo8Y2u6R+3TrcdWr3nd+kSWibTPuvq7SRvbMMAN8AA/3GNl8IVwghhDhbdTlIyszMZM6cOeTn5zNgwAAUReHgwYMkJCTw7bffkpYmS1icqCNlFs92QshxmbZL9qlfNVqIHg6og7LX5quDuXUaHcMihjW7pPobb8tf4MXNZyBuXpyN0hiRDZ4Si94gga4QQggB3RiT9MADD5CWlkZubi7btm1j+/btHD16lJSUFB544IHeqONZJ7fSGySlNF2zzWmD4r3qdmgaGHwAyK7JprBezZs0MnIkAUZv65OzooKapUsBNcO2/wxv4smKgnoOrFWv0xu0DD8voVc+jxBCCHE66nJL0po1a9iwYYNnLTeAsLAwnnnmGaZMmdKjlTtb5Vd6F7aNCfJpcmIruJ3qduxIz+ENBRs821Pjpja7V/XCr8HhACDo8svRmkyec1sWZ+NubEUaOSsRc6Cs0SaEEEIc0+WWJJPJRG1tbYvjdXV1GI3yS7YnHCjyvt+0yCYz2w4t9243mfp/LIEktByPVLNkiWc7+BpvBu6j+8o5tKUEAJNZz6gLms+GE0IIIc52XQ6SLrnkEu6++242btyIoigoisKGDRv45S9/yWWXXdYbdTzrZDXmSAo2G4gKbNKS1DRI6q8m8WxwNrChUG1J8jf4MyzcOx7JunsPDbt2AWBMS8Nn4EAAnHYXP3xy0FNu9OwkjL7dGsMvhBBCnLG6HCS99NJLpKWlMWnSJHx8fPDx8WHKlCn069ePF198sTfqeFZpcLgoqFaXDokL9vWecDmgLEPdDk0Ff3UW2tqCtdQ51KBqatxUdFrvwOuqz7zruIXceKNne/1Xh6kuUbv0wuL9GTlTWpGEEEKI43W5+SA4OJiFCxdy6NAh9u/fD8DgwYPp169fj1fubLS3wLu0y8DoQO+J4j3gsqvbsaM8h/+X8T/P9gVJF3i23XY7tStWqDs6HUGXq6189gYn+9cXesqdf+sgtFrJiySEEEIcr9t9LP379/cERpJ8sOfkV3kHbadHNRmPVLDdux0zAlC72naV7vIcnhLrHThft3o1rooKAPynT0cXoM54y9hQhKPBBajZtSMSj8vDJIQQQgigG91tAO+88w5Dhw71dLcNHTqUf/3rXz1dt7NSboV3+n980xxJTYOkuDEA7Cvf5+lqGxI2BH+jN6iqXuhdzDb4anXAttvl5qfPDnmOn//zQT1adyGEEOJM0uWWpD/96U+88MIL3H///UyapK5Av379eh5++GGOHDnC3//+9x6v5Nkkr0mOpNjgJoO2c9RlRdDoPN1ta/LWeE5fP+B6z7Y9N5e6lSsB0IWF4T9VbWHK3FqC26VO+Y/pF0RkUpPuPCGEEEI00+Ug6fXXX+ftt9/mxiYDgS+77DKGDx/O/fffL0HSCTpcWu/ZTg1vbBmyVEB5YwtQ9DAwqgkmj2XZhub5kaq//hoUNRgKvvYaNEYjiqKwZfERT5mR58tgbSGEEKI9Xe5uc7lcjB07tsXxMWPG4HQ6e6RSZ7Oj5WpLUrDZQJDZoB7MWuUtkDgRgGpbNYeq1MApKTCJCHMEAIrbTeUnn3iKB19zLQB5ByqpLFLv7R9iImVkeK9+DiGEEOJ01+Ug6ZZbbuH1119vcfytt97i5ptv7pFKna0aHC6Ka9Xp/0mhTcYj7V3g3U47H4ANhRtwK26geSuSdetWXKXqgrXmiRMxxscBsHt1nqfMxCvSZLC9EEII0YFuzW575513WLZsGRMnqq0aGzZsIDc3l1tvvZVHHnnEU+7555/vmVqeJY5WWI71kpHcdM22w40tSRqtpyVpXcE6z+mmQVLVwoWe7aDLLweg9Ggt2TvVwMk30Ei/sZG9UX0hhBDijNLlIGnPnj2MHj0agMOHDwMQERFBREQEe/bs8ZSTloquyyn3DtpOCmsMkuwWcDSOU1Lc4BOIoiie8UhGrZExUepsN7fdTu0yNSu3xmQicNZMAHZ+n+u574jz4tHpujWpUQghhDirdDlIWrVqVceFRLcUNMmRFB/SmG27YJsaHAEMU8cXZVdnU2wpBmBM1Bh89WpZy+bNuGvUZJQBM2ei9fOjvKCOjI1FAOgNWoZNiz8ZH0UIIYQ47UmTwimkaZDkWZKkIttbIH48oC5FcsyUOG8CyeqvFni2/WdMB+DHT715kUacnyBrtAkhhBCdJEHSKSS3SY6kmKDGHEnl3iCH0FQAfsj7wXNocuxkAFx1ddQuV7vatAEBBJx3HiU5NeRnVAIQEObDmDnJvVh7IYQQ4swiQdIp5EiZGiTptRrvmKRC77IjRA7E4XawsXAjALF+sfQLVpeGqVm0CMVmAyDwoovQ+vqy7bujnktHXpCIwehd/FYIIYQQ7ZMg6RRSUqsGOeH+JnRajZoQsqgxSPKLgMA4DlUeQkGdAjcicoRngHzV51947hN87bXUVdrI3lkKgMlPz+CpMSfxkwghhBCnPwmSThE2p4uKejVIigo0qQct5eofgMhBoNGwvcS7htuw8GEAOIpLaGicWWhISMBn6BB2rcr1LEEyeEoseoO0IgkhhBBd0a0g6YMPPmDKlCnExsaSk5MDwPz581nYJEeP6Jq8SivuxhxJ3q62Hd4CkYMB+Gj/R55Dx6b+1/3gXcMt8MLZWGsd7FqlJo/UajUMPTeu9youhBBCnKG6HCS9/vrrPPLII8yZM4eqqipcLhcAwcHBzJ8/v6frd9YoqbF5tiMDGluSCrytRsSOxq24qbHXeA71D+4PQP0P3oHc/tOmse+nAlwONW3AwEnRBIb79mLNhRBCiDNTl4Okl19+mbfffpsnnngCnc7bhTN27Fh2797do5U7m+Q1mdkWe2z6f8EOb4HYUWRXZ1NtqwYgxi8Gg86A22Kh7ocfAdCFhOA7ahSHthR7LhtxgSxkK4QQQnRHl4Ok7OxsRo0a1eK4yWSivr6+lStEZ+RWenMkJYU1rttWsk/9qveBsDR2lXpnul3d/2oA6jdu9Mxq858+nbpqBxUF6t9DVEogoTFNljcRQgghRKd1OUhKSUlhx44dLY4vWbKEwYMH90Sdzko55d4AMzHUDPZ6qMhSD4T3B62ODYUbPGVGR6lLw9T/+KPnmP95M8jaXurZTxgU2su1FkIIIc5cXQ6SHn30Ue677z4+/fRTFEVh06ZNPPnkk/zhD3/g0Ucf7Y06ejz99NNoNBoeeughzzFFUZg7dy6xsbH4+voyffp09u7d26v16A25Fd7utrgQXyg94D0ZNQy34mZ9wXoAzHozIyNHojid1CxZCoDGaMRv0iQyt3q72pKHhZ+cygshhBBnoC6vUXH77bfjdDp57LHHsFgs3HTTTcTFxfHiiy9yww039EYdAdi8eTNvvfUWw4cPb3b8ueee4/nnn+fdd98lPT2dv//978ycOZOMjAwCAgJ6rT497WBxHQBBvgbMRj0UeRcLJnoYO0p2UGlTs2ePiRqDQWugfuN6XJXqMb/Jk6lv0FGUpQ7sDo4yE5l8+nx+IYQQ4lTTrRQAd911Fzk5OZSUlFBUVERubi6/+MUverpuHnV1ddx88828/fbbhISEeI4risL8+fN54oknuOqqqxg6dCjvvfceFouFjz/+uNfq09MURaHO5gTaWI4kvD8bizZ6ds+JPwfAM2AbIHDORRzYUOTZHzAhypNoUgghhBBdd0KrnYaHn5zunPvuu4+LL76YCy64gL///e+e49nZ2RQVFTFr1izPMZPJxLRp01i3bh333HNPq/ez2WzYbN4p9zU1auuLw+HA4XD0eP2P3bOte9c2eI9nldXjcDjQ5W31RLCO0P5szPTmR5ocPRm73U71okXqAb0e3eix7Ho+01MmeWRYr3yW00lH7130DnnvfUfefd+Q9953evuddzlISklJabeFIisr64QqdLxPPvmErVu3smXLlhbniorUlpOoqKhmx6OiojxJLlvz9NNPM2/evBbHly1bhtlsPsEat2154wK0xytvgGN/FekBThZ/+y1z8rajBRr0wSz5cTvbq9WcSUGaIHas2cH+3G9IKlUHadenprLg8x3YLGorlCnMydrNq3rtc5xu2nrvonfJe+878u77hrz3k89isXRc6AR0OUhqOmga1Chu+/btLF26tMcHbufm5vLggw+ybNkyfHx82ix3fNCmKEq7gdzvf/97HnnkEc9+TU0NCQkJzJo1i8DAwBOv+HEcDgfLly9n5syZGAyGFufXZ5XD9q0AjB2YzJxzgjHsUFMCGJPGkjghEfcyNTnk+ITxzJk6h4q33qKi8frk666luCaOatQlTM69YhgpI2XQdkfvXfQOee99R95935D33nfKy8t79f5dDpIefPDBVo+/+uqrrbb2nIitW7dSUlLCmDFjPMdcLhc//PADr7zyChkZGYDaohQT413AtaSkpEXrUlMmkwmTydTiuMFg6NVv8Lbun1PR4NnuHx2IodLbbaYN78/eCu9svfEx49HrdNQu/NpzzDhuCrmveFvOUkdGylptTfT236tonbz3viPvvm/Iez/5evt999gCtxdddBFffPFFxwW74Pzzz2f37t3s2LHD82fs2LHcfPPN7Nixg9TUVKKjo5s1cdrtdtasWcPkyZN7tC696XCpN0dSvwh/KPImjSRyEOsK1nl2x0SNoWH3bhxHjwJgnjiRjEw8y5AMPkcWsxVCCCF6wgkN3G7q888/JzS0Z5MXBgQEMHTo0GbH/Pz8CAsL8xx/6KGHeOqpp+jfvz/9+/fnqaeewmw2c9NNN/VoXXpT0xxJyeF+sG2nZ78hajCb9r0IQIRvBP2C+1H+yRue84GzZ7FxZ5lnf9i0+JNQYyGEEOLM1+UgadSoUc3G+yiKQlFREaWlpbz22ms9WrnOeOyxx7Bardx7771UVlYyYcIEli1bdlrlSCqvt3u2w/yMkL9N3dEZ2ad143Cro/cnxExAo9FQ99NaT3lb+jhK16itSqGxfoTFyTIkQgghRE/ocpB0xRVXNNvXarVEREQwffp0Bg4c2FP1atPq1aub7Ws0GubOncvcuXN7/dm9pbBaHaQd7m9C77RA5RH1RORgtpV7Fw0eFz0Ot9VKQ+NCwoa4OPJKvH+FAyZES24kIYQQood0KUhyOp0kJycze/ZsoqOje6tOZxW3W6G0Vs3ZFBPkA0W7AUU9GTOCtfneVqMxUWOwbNqEYldbnnwmTWXP6jzP+dRRESet3kIIIcSZrksDt/V6Pb/61a+aJWIUJ6a0zoa7MSaKCDBBxWHPOUd4f3aXqa1GsX6xJAUmUffjT57zFSmTqa9WA6bk4eEER/ZejichhBDibNPl2W0TJkxg+/btvVGXs1JepdWznRDiC+XeICnDxwebSw1IR0SMQFEUar/7Tj2p11Ng8+ZCGjI19uRUWAghhDhLdHlM0r333stvfvMb8vLyGDNmDH5+zQcKH78ArWhfUbU3R1JkoA8U7vfsb3XVebYHhg3EfuQIzsYs276jRpF3WD1v9NWTMLhnZxYKIYQQZ7tOB0l33HEH8+fP5/rrrwfggQce8JzTaDSeLNcul6vna3kGK6rxBkkxQT6w+6C6o/cl217lOZcWlEbDdu8gbseQSdiOqIvixvYPRqfvsZRXQgghhKALQdJ7773HM888Q3Z2dm/W56xztNybSDIhxBeqGwdih6awq3Fmm1ajZWz0WKrXP+kpWxk2CI6oCSRj+weftPoKIYQQZ4tOB0mKoo4uTkpK6rXKnI2ajkmKN9VD4xgkq18Eh6vU8Un9g/vjZ/CjcONGADRGI/lV/kANAElDwk5upYUQQoizQJf6aCQHT88rbByTpNVAVNUOz/EdIdG4FbWlaFDYIJyVlTgKCgAwDB9N0ZFaAAIjfAmNlQSSQgghRE/r0sDt9PT0DgOlioqKds+L5srr1ZajiAAT2vwfPMe3+fpCpbo9Nmos9T95p/7XJI3FXa627CUMkgHbQgghRG/oUpA0b948goKCeqsuZx2XW6G8Ts1zFOZngrJDnnOH3N5uuGERw6h77RXPfnXUUChXB8hHpwaepNoKIYQQZ5cuBUk33HADkZGRvVWXs055nQ1nYybJmCAfKD2gnjCYOVSvDuD20fmQ6J9I1qbNAGj8/Mgp1AMuNFoNiYNlPJIQQgjRGzo9JknGI/W84hpv5vKYQD1U5QJgDU0ht1YNktKC03AXFuMqKwPANWwSdZXqdbH9gzEHGk9yrYUQQoizQ6eDpGOz20TPaZojKVVXCm4HALuCo1Ea12/rF9yPuh/WeMpVxo/3bMcPDDlJNRVCCCHOPp3ubnO73b1Zj7NS0yApSV/p2c7y8QF1qBLxAfHYD2d5zpXqvMuPJA+TrjYhhBCit0ia5j5U3GRJkjhNmWf7oNbbajcqchQNe/cC4NLqKa3UAeAbYCAszv8k1VQIIYQ4+0iQ1IeOTf8HCLPlebYPOms924PNqVj37AGgvt9EHHa1RS9xSJiMExNCCCF6kQRJfaikycDtAKsaJDmADEshAHH+cbBlFzjVNdpq+k/1lE+Q8UhCCCFEr5IgqQ8VNMm2bapUF7bdb/LB5lYHJI2MHEndanXQtoKGXFc8ABqthgSZ+i+EEEL0KgmS+oiiKORXWgBICNSjKc0AYEd4oqfM6MjRWDZtAqA+MB5rg9q9FtsvSKb+CyGEEL1MgqQ+UmVxUNOgdqONDamHxin/35i8ZQZag7Hn5ABQP/Acz/HEodKKJIQQQvQ2CZL6SFmddzzSEH2+Z9ul90ZJEWszPNvlUSM927JemxBCCNH7JEjqIwVNpv+nadQgyQXkOOs8x+0btwDg1JkosajT/f2CjITHy9R/IYQQordJkNRH8iu9C9jGu9TlSLINBuyKunDtBQnn03BAXcutNnEsbpfaHZc8PFym/gshhBAngQRJfeRgsTcXUkSDOu5ou4+3q22cvh/umhoAqhNGe47HD5SuNiGEEOJkkCCpj2w/6l2GxK/uKABLg7wB0KAjTs92sTFJ3dBA3IDgk1I/IYQQ4mwnQVIfCfQ1ABBCDTp7NQBmg6/nfFBeFQAWn3DqnerxmLQgfP1l6r8QQghxMkiQ1EdKa9XZbYmaEs+xYp13vWHt/sMAVIQO9hxLkqn/QgghxEkjQVIfya9SB24PD1DHJilAjls9lmyKoWHHTgCqY4Z7ronpF3xS6yiEEEKczSRI6gP1Nie1jYkkB5tKASjQ67Ao6rHxpUEoDsf/t3fn0VGV9xvAnztrZiaZrCSTyQJhiSBRIsENEXABVCRVCiIFgVoXCmEx54hYen4ElOX0CCJWEGhPsAoHsSyFVpEgSKFUkUAkLMWgYRESI1lJJsz6/v6YcMOYAYNk5g7wfM7J6cy9b26++Q5tnt773vdCAKgxdwQAqDUqWNLMitRLRER0M2JIUkBNo1N+3RHeB9se0TXPNcqsMAIA6sOTYRfeO96Su0VDpebHRUREFCz8q6uAqnqH/DrJ5V1IsljffPu/9ZR3QcnqqHR5Wwpv/SciIgoqhiQFVDY0P5IkyuWduH3E2LyKdvjJSgBAdVzzpO3krtFBqo6IiIgAhiRF/FDnfSSJHg6EO72BqFzrXRIgtcEAT/kPEJBQG9kJAGCI0CLGalKmWCIiopsUQ5ICzjVdbktpuv3fCeCk5H0cSda5CABAnbk9XJJ3npK1cxQfRUJERBRkDEkKqGwKSd2lEwCAby6ZtH3XN95ntFVFd5W3Jd3CS21ERETBxpCkgENnvStsx0jeNZK+0XkvtUlCIPXQOQBAbUzzpG1rl6jgFkhEREQMSUooaXq4bQepHABwtOlMUuezgPaCEx5JhZrIzgA4H4mIiEgpDEkKiDY1zTWSqgAA3zWdSUo/473UVhPVBR6oAQDJXWM4H4mIiEgBDEkKuDgnqYumHALNc5IyyrzPbjsXmyGPTesRF/T6iIiIiCEp6M5fcKK20QlAwCoqUK5Wo7ppJe1bvItvoy6qszyei0gSEREpgyEpyH6o8y4kaYYNOjjlS22RDQLhdQ44NUacNyUBAKISjAgL1ypWKxER0c2MISnIKuu9IckqeReRPN60iKTV+xbVUV0gJO98pBSusk1ERKQYhqQgq2rwzkdq33Rn28Xb/1MrmtZHirn0USS81EZERKQUhqQgO9Z0+39q02rbx5ombXf7HhAAqmK6AQAklYTkbjyTREREpBSGpCCrsTkBAEnSOdgkCSVNZ5J6H/Wg0dAOF8JivfvTo6AL0yhWJxER0c2OISnIGuwuAIBFqsYJrQYeSUKErWl9pMjmu9qS0qOUKI+IiIiaMCQFmcPtAQAkSpU43nSprWNZy+e1WTpFBb02IiIiasaQFGQXF5JMln7Et1rv5bQHDwp4JDUqY7sDAPRGDRI7RypWIxERETEkBV21zQEtXIiVzuN00+3/0fUCdeYOcGsMAIDUW2OgVvOjISIiUhL/EgdZjc2JeFQDAE5qNIAQsFb6zkdK7sZb/4mIiJTGkBRk5+rtiJdqIAB8r9UgqRIwN3oXkbzI2iVKsfqIiIjIiyEpiBodbthdHqRIP+IHtRo2lQrpZwQ8kgp1kR0BAAazDpHtDApXSkRERAxJQVRtuzhpuwKnmyZtZ34nUB+eArda7913SzQkSVKsRiIiIvJiSAqi2kbvGklWqRKlTZO2U370Ttq+KKGDWYnSiIiI6CcYkoLobG0jACBZOuddaVsImG1A7aUhKY0hiYiIKBQwJAWR3eldSDJNKkOpVovoeu+k7frwZO8ACYhLDlewQiIiIrqIISmIfqy3QwcnUlUVKNFpkVQp4FbpYDMmAABik8Kh0akVrpKIiIgAhqSgqqx3IFGqRJlGjSq1Gmk/ANXR6RCSNxjxUhsREVHoYEgKotoLTsShFt82Tdru8Z3A+fAUeX/yLdFKlUZEREQ/wZAURNv/9yMsUrX3zjYhcPsJgdqm9ZEAIL59hILVERER0aVCOiTNmzcPd955JyIiIhAfH48nnngCx44d8xkjhEBeXh6sVisMBgP69++Pw4cPK1TxlVmjDEiSfsQprQYx5wEBCbXmNACAMVIHcxwXkSQiIgoVIR2Sdu7ciYkTJ+KLL75AQUEBXC4XBg4ciIaGBnnMn/70JyxcuBB//vOf8dVXX8FisWDAgAE4f/68gpX7V2NzIlk6h+81GlirBGzGePmhtgkdzFxEkoiIKIRolC7gSrZs2eLzPj8/H/Hx8SgsLETfvn0hhMCiRYswY8YMDB06FADw3nvvISEhAatXr8aLL77o97h2ux12u11+X1dXBwBwOp1wOp1t/ntcPGZtowNJ0jmc1Gpw/wmBuqazSAAQl2IKyM++mV3sJ/saXOy7cth7ZbDvygl0z0M6JP1UbW0tACAmJgYAUFpaivLycgwcOFAeo9fr0a9fP+zZs+eyIWnevHmYNWtWi+1bt26F0WgMQOVetTYH4rWVOKvRQOf0oN5klfeV/nAUZR8fCtjPvpkVFBQoXcJNiX1XDnuvDPY9+Gw2W0CPf92EJCEEcnNz0adPH2RkZAAAysvLAQAJCQk+YxMSEnDy5MnLHuvVV19Fbm6u/L6urg4pKSkYOHAgzOa2vw3f6XTik08L4BIS1NpqeKRoJFUC9RHNIWlQdn+YovRt/rNvZk6nEwUFBRgwYAC0TXcUUuCx78ph75XBviunsrIyoMe/bkJSTk4ODh48iN27d7fY99O5PEKIK87v0ev10OtbBhKtVhuwf+AX3IAJjbBrvJf5rJUC/7O2BwAYzTpExpk4JylAAvm50uWx78ph75XBvgdfoPsd0hO3L5o0aRI2bdqEHTt2IDk5Wd5usVgANJ9RuqiioqLF2SWl2VxAtHQeZRoNtC4BkyMGLq330l679hEMSERERCEmpEOSEAI5OTlYv349tm/fjrS0NJ/9aWlpsFgsPteBHQ4Hdu7cid69ewe73CtqdAFxqMN2owFxtUDjJfORYq18XhsREVGoCenLbRMnTsTq1avxj3/8AxEREfIZo8jISBgMBkiShKlTp2Lu3Lno0qULunTpgrlz58JoNOI3v/mNwtX7uuCWECfVQg3AUi3k57UBQExi4CaLExER0S8T0iFp6dKlAID+/fv7bM/Pz8e4ceMAANOmTUNjYyMmTJiA6upq3H333di6dSsiIkJr9eoqO2CVzmGjyYhHqgUaLglJURaTgpURERGRPyEdkoQQPztGkiTk5eUhLy8v8AVdA0kC2ksVsLrcSKySYDNa5H1RCTyTREREFGpCek7SjaTBCbSTqlCtViHlR4EGYyIAwBSphd4Q0lmViIjopsSQFCQNLgkaVT1skgRrTaR8Z1tsUmhdFiQiIiIvhqQgqXcCbq0N0fWAS9de3h6bxDvbiIiIQhFDUpA0uAChaUD6GYH68Obb/+NSGJKIiIhCEUNSkFxwuuHU2LyPIwlvXhAzLoWX24iIiEIRQ1KQGFy1OKnVIPVHgQaTd9K2Ws0724iIiEIVQ1KQmN01OKtRo11N8+3/kfFGqFR8HAkREVEoYkgKEpOnFj9q1Ii4ECtvi0rgIpJEREShiiEpCBwuD6JQh3NCA70nUt5utzkVrIqIiIiuhCEpCM7bXUiVymGoUqHRGC9vT8tsp2BVREREdCUMSUFQb3chVl2BiAbAZmh+Zlu0hZO2iYiIQhVDUhDUX3ChSqVGQg1gMzafPeKdbURERKGLISkIGhwuaDTnEV8jcCHMO3FbkoDw6DCFKyMiIqLLYUgKgsp6B87rGhFfA9h13onbxggNb/8nIiIKYQxJQeDyCKgkB6IbDHDqvCtsR8bz9n8iIqJQxpAUBA6XBzpNLcLczXe2RVkYkoiIiEIZQ1IQNDjcqIEKamGWt0XEcD4SERFRKGNICgKb3YUGpxYOfbS8zRSlU7AiIiIi+jkMSUFwwemGxwHYjM1rJEW2MyhYEREREf0chqQgcF5ogLpBQoMpUd4WzTlJREREIY0hKQjcjXUIq1PDZrQAAPRaDwwRvNxGREQUyhiSgsFWBVOdCg5tOAAg3KxWuCAiIiL6OQxJQeC2V8J4IQ6QvO02x3E+EhERUahjSAoCl6sSJmes/D7SEqFgNURERNQaDElB4HafQ7v65pBkTjRfYTQRERGFAoakIPC4ayFUly4kycttREREoY4hKQgkdwPs+kj5vTGSd7YRERGFOoakINBdOA/7Jatth0fzkSREREShjiEpCHR2G5ya5ktsYSaNgtUQERFRazAkBZjHI2CqvwBH0+U2tXQBKjXbTkREFOr41zrA7C4PVG4XHDrvxG09GhWuiIiIiFqDISnAGp1umOvU8Ki0AACdUeGCiIiIqFUYkgLM4fLAqdHL7/V6ScFqiIiIqLUYkgLM7nJD62y+m00fFa5gNURERNRaDEkBVm93QeVuPpNkjOT1NiIiousBQ1KAeTyAHc3ByBjBM0lERETXA4akAHO4PUg91xyMwtvx4bZERETXA4akAHO6PfgxJlV+b4zlmSQiIqLrAUNSgDndHkiiuc16o1bBaoiIiKi1GJIC7ILTA42n+TEkpij9FUYTERFRqGBICjCH3Qahap64zTNJRERE1weGpABrPF8Bj7r57JHOoFawGiIiImothqQAc9eVwaVuWkxSuKHWsOVERETXA/7FDrDqspOoj/De3aYSFyBJfCwJERHR9YAhKcCMsMmvJWFXsBIiIiK6GgxJASbOV0HyuAEAbnWMwtUQERFRazEkBZjnfDWEyjtZW+cpUbgaIiIiai2GpACTGptv+feobFcYSURERKGEISnApIYLza/V8QpWQkRERFeDISnAHM7mdZHCdKcVrISIiIiuBkNSgKmFTn6t0vH2fyIiousFQ1KAmeo88mutnqttExERXS8YkgLMpm9+bluY2q1gJURERHQ1GJICzKFKkl+rIyMUrISIiIiuBkNSgOncVfJrjd6gYCVERER0NRiSAszQ0DwPKcKsV7ASIiIiuhoMSQFmMzbf3aYL5+U2IiKi6wVDUoBJQiO/NkRFKVcIERERXRWGpABzSs1nkkxR0QpWQkRERFfjhglJS5YsQVpaGsLCwpCVlYVdu3YpXRIAwBnWXX5tjolRsBIiIiK6GjdESPrwww8xdepUzJgxAwcOHMD999+PRx99FKdOnVK6NOjt38uvTdGRClZCREREV+OGCEkLFy7E7373Ozz33HPo1q0bFi1ahJSUFCxdulTp0mA3pMmv1XrdFUYSERFRKNH8/JDQ5nA4UFhYiOnTp/tsHzhwIPbs2eP3e+x2O+x2u/y+trYWAFBVVQWn09mm9TU6GgAAGmc9KisrodVq2/T4dHlOpxM2m419DzL2XTnsvTLYd+VUVXnXIhRCBOT4131IOnfuHNxuNxISEny2JyQkoLy83O/3zJs3D7NmzWqxPS0tzc/otvPSBwE9PBER0U2psrISkZFtP6Xlug9JF0mS5PNeCNFi20WvvvoqcnNz5fcejwdVVVWIjY297Pdci7q6OqSkpOD06dMwm81tfnzyj31XBvuuHPZeGey7cmpra5GamoqYAN0Ydd2HpLi4OKjV6hZnjSoqKlqcXbpIr9dDr/dd/ToqCGsYmc1m/hdIAey7Mth35bD3ymDflaNSBWaK9XU/cVun0yErKwsFBQU+2wsKCtC7d2+FqiIiIqLr3XV/JgkAcnNz8cwzz6BXr1649957sXz5cpw6dQrjx49XujQiIiK6Tt0QIWnEiBGorKzE7NmzUVZWhoyMDHz88cdo37690qUB8F7emzlzZotLfBRY7Lsy2HflsPfKYN+VE+jeSyJQ980RERERXceu+zlJRERERIHAkERERETkB0MSERERkR8MSURERER+MCQF2JIlS5CWloawsDBkZWVh165dSpd0Q5k3bx7uvPNOREREID4+Hk888QSOHTvmM0YIgby8PFitVhgMBvTv3x+HDx9WqOIb07x58yBJEqZOnSpvY98D58yZMxg9ejRiY2NhNBqRmZmJwsJCeT97Hxgulwt//OMfkZaWBoPBgI4dO2L27NnweDzyGPb+2v373//GkCFDYLVaIUkSNm7c6LO/NT222+2YNGkS4uLiYDKZkJ2dje+///7qixEUMGvWrBFarVasWLFCHDlyREyZMkWYTCZx8uRJpUu7YQwaNEjk5+eLQ4cOiaKiIjF48GCRmpoq6uvr5THz588XERERYt26daK4uFiMGDFCJCYmirq6OgUrv3Hs3btXdOjQQdx+++1iypQp8nb2PTCqqqpE+/btxbhx48SXX34pSktLxbZt28Tx48flMex9YLz++usiNjZW/POf/xSlpaXio48+EuHh4WLRokXyGPb+2n388cdixowZYt26dQKA2LBhg8/+1vR4/PjxIikpSRQUFIj9+/eLBx54QPTo0UO4XK6rqoUhKYDuuusuMX78eJ9tXbt2FdOnT1eoohtfRUWFACB27twphBDC4/EIi8Ui5s+fL4+5cOGCiIyMFO+++65SZd4wzp8/L7p06SIKCgpEv3795JDEvgfOK6+8Ivr06XPZ/ex94AwePFg8++yzPtuGDh0qRo8eLYRg7wPhpyGpNT2uqakRWq1WrFmzRh5z5swZoVKpxJYtW67q5/NyW4A4HA4UFhZi4MCBPtsHDhyIPXv2KFTVja+2thYA5IcdlpaWory83Odz0Ov16NevHz+HNjBx4kQMHjwYDz/8sM929j1wNm3ahF69emH48OGIj4/HHXfcgRUrVsj72fvA6dOnDz777DN88803AICvv/4au3fvxmOPPQaAvQ+G1vS4sLAQTqfTZ4zVakVGRsZVfw43xIrboejcuXNwu90tHrKbkJDQ4mG81DaEEMjNzUWfPn2QkZEBAHKv/X0OJ0+eDHqNN5I1a9agsLAQ+/bta7GPfQ+c7777DkuXLkVubi7+8Ic/YO/evZg8eTL0ej3GjBnD3gfQK6+8gtraWnTt2hVqtRputxtz5szByJEjAfDffTC0psfl5eXQ6XSIjo5uMeZq//4yJAWYJEk+74UQLbZR28jJycHBgwexe/fuFvv4ObSt06dPY8qUKdi6dSvCwsIuO459b3sejwe9evXC3LlzAQB33HEHDh8+jKVLl2LMmDHyOPa+7X344Yf44IMPsHr1anTv3h1FRUWYOnUqrFYrxo4dK49j7wPvl/T4l3wOvNwWIHFxcVCr1S1Sa0VFRYsETNdu0qRJ2LRpE3bs2IHk5GR5u8ViAQB+Dm2ssLAQFRUVyMrKgkajgUajwc6dO7F48WJoNBq5t+x720tMTMStt97qs61bt244deoUAP6bD6SXX34Z06dPx9NPP43bbrsNzzzzDF566SXMmzcPAHsfDK3pscVigcPhQHV19WXHtBZDUoDodDpkZWWhoKDAZ3tBQQF69+6tUFU3HiEEcnJysH79emzfvh1paWk++9PS0mCxWHw+B4fDgZ07d/JzuAYPPfQQiouLUVRUJH/16tULo0aNQlFRETp27Mi+B8h9993XYpmLb775Rn6gN//NB47NZoNK5ftnU61Wy0sAsPeB15oeZ2VlQavV+owpKyvDoUOHrv5z+EXTzalVLi4B8Ne//lUcOXJETJ06VZhMJnHixAmlS7th/P73vxeRkZHi888/F2VlZfKXzWaTx8yfP19ERkaK9evXi+LiYjFy5EjekhsAl97dJgT7Hih79+4VGo1GzJkzR5SUlIhVq1YJo9EoPvjgA3kMex8YY8eOFUlJSfISAOvXrxdxcXFi2rRp8hj2/tqdP39eHDhwQBw4cEAAEAsXLhQHDhyQl89pTY/Hjx8vkpOTxbZt28T+/fvFgw8+yCUAQtE777wj2rdvL3Q6nejZs6d8azq1DQB+v/Lz8+UxHo9HzJw5U1gsFqHX60Xfvn1FcXGxckXfoH4aktj3wNm8ebPIyMgQer1edO3aVSxfvtxnP3sfGHV1dWLKlCkiNTVVhIWFiY4dO4oZM2YIu90uj2Hvr92OHTv8/u/62LFjhRCt63FjY6PIyckRMTExwmAwiMcff1ycOnXqqmuRhBDiF5/3IiIiIrpBcU4SERERkR8MSURERER+MCQRERER+cGQREREROQHQxIRERGRHwxJRERERH4wJBERERH5wZBERERE5AdDEhFd0cqVKxEVFaV0GddEkiRs3LjximPGjRuHJ554Iij1+JOXlwdJkiBJEhYtWnRNx+rfv798rKKiojapj+hmxJBEdBMYN26c/Efz0q/jx48rXVpQlJWV4dFHHwUAnDhxwm94eOutt7By5crgF3eJ7t27o6ysDC+88IK8LTc3FzExMUhNTcWaNWt8xq9duxZDhgxpcZz169dj7969Aa+X6EanUboAIgqORx55BPn5+T7b2rVrp1A1wWWxWH52TGRkZBAquTKNRuNT6+bNm7F69Wps3boVJSUl+O1vf4sBAwYgNjYWNTU1mDFjBj777LMWx4mJiUFdXV0wSye6IfFMEtFNQq/Xw2Kx+Hyp1WosXLgQt912G0wmE1JSUjBhwgTU19df9jhff/01HnjgAURERMBsNiMrKwv79u2T9+/Zswd9+/aFwWBASkoKJk+ejIaGhsseLy8vD5mZmVi2bBlSUlJgNBoxfPhw1NTUyGM8Hg9mz56N5ORk6PV6ZGZmYsuWLfJ+h8OBnJwcJCYmIiwsDB06dMC8efPk/ZdebktLSwMA3HHHHZAkCf379wfge7lt2bJlSEpKgsfj8ak1OzsbY8eOld9v3rwZWVlZCAsLQ8eOHTFr1iy4XC6f3y01NRV6vR5WqxWTJ0++bB/8OXr0KPr3749evXph5MiRMJvN+O677wAA06ZNw4QJE5CamnpVxySi1mNIIrrJqVQqLF68GIcOHcJ7772H7du3Y9q0aZcdP2rUKCQnJ+Orr75CYWEhpk+fDq1WCwAoLi7GoEGDMHToUBw8eBAffvghdu/ejZycnCvWcPz4caxduxabN2/Gli1bUFRUhIkTJ8r733rrLSxYsABvvPEGDh48iEGDBiE7OxslJSUAgMWLF2PTpk1Yu3Ytjh07hg8++AAdOnTw+7MuXobatm0bysrKsH79+hZjhg8fjnPnzmHHjh3yturqanz66acYNWoUAODTTz/F6NGjMXnyZBw5cgTLli3DypUrMWfOHADA3//+d7z55ptYtmwZSkpKsHHjRtx2221X7MNP9ejRA/v27UN1dTUKCwvR2NiIzp07Y/fu3di/f/9Vhy4iukqCiG54Y8eOFWq1WphMJvlr2LBhfseuXbtWxMbGyu/z8/NFZGSk/D4iIkKsXLnS7/c+88wz4oUXXvDZtmvXLqFSqURjY6Pf75k5c6ZQq9Xi9OnT8rZPPvlEqFQqUVZWJoQQwmq1ijlz5vh835133ikmTJgghBBi0qRJ4sEHHxQej8fvzwAgNmzYIIQQorS0VAAQBw4c8BkzduxY8atf/Up+n52dLZ599ln5/bJly4TFYhEul0sIIcT9998v5s6d63OM999/XyQmJgohhFiwYIFIT08XDofDb03++tCjRw+/2zt16iQyMjLE+vXrhd1uFxkZGWLfvn3i7bffFunp6aJ3797i0KFDPt93ud+TiFqPZ5KIbhIPPPAAioqK5K/FixcDAHbs2IEBAwYgKSkJERERGDNmDCorKy97iSw3NxfPPfccHn74YcyfPx/ffvutvK+wsBArV65EeHi4/DVo0CB4PB6UlpZetrbU1FQkJyfL7++99154PB4cO3YMdXV1OHv2LO677z6f77nvvvtw9OhRAN5LZUVFRbjlllswefJkbN269Rf36aJRo0Zh3bp1sNvtAIBVq1bh6aefhlqtln/X2bNn+/yuzz//PMrKymCz2TB8+HA0NjaiY8eOeP7557FhwwafS3GtlZeXh+PHj6O4uBhPPvkk5s6di4cffhharRavv/46du/ejeeeew5jxoy55t+ZiHwxJBHdJEwmEzp37ix/JSYm4uTJk3jssceQkZGBdevWobCwEO+88w4AwOl0+j1OXl4eDh8+jMGDB2P79u249dZbsWHDBgDeuUMvvviiTxj7+uuvUVJSgk6dOrW6VkmSfP7zp68BQAghb+vZsydKS0vx2muvobGxEU899RSGDRvW+ub4MWTIEHg8HvzrX//C6dOnsWvXLowePVre7/F4MGvWLJ/ftbi4GCUlJQgLC0NKSgqOHTuGd955BwaDARMmTEDfvn0v29fW+N///odVq1bhtddew+eff46+ffuiXbt2eOqpp7B//35O1iZqY7y7jegmtm/fPrhcLixYsAAqlff/M61du/Znvy89PR3p6el46aWXMHLkSOTn5+PJJ59Ez549cfjwYXTu3Pmq6jh16hTOnj0Lq9UKAPjvf/8LlUqF9PR0mM1mWK1W7N69G3379pW/Z8+ePbjrrrvk92azGSNGjMCIESMwbNgwPPLII6iqqkJMTIzPz9LpdAAAt9t9xZoMBgOGDh2KVatW4fjx40hPT0dWVpa8v2fPnjh27NgVf1eDwYDs7GxkZ2dj4sSJ6Nq1K4qLi9GzZ8/WN6eJEAIvvPACFixYgPDwcLjdbjlwXfzPn040J6Jrw5BEdBPr1KkTXC4X3n77bQwZMgT/+c9/8O677152fGNjI15++WUMGzYMaWlp+P777/HVV1/h17/+NQDglVdewT333IOJEyfi+eefh8lkwtGjR1FQUIC33377sscNCwvD2LFj8cYbb6Curg6TJ0/GU089Jd8O//LLL2PmzJno1KkTMjMzkZ+fj6KiIqxatQoA8OabbyIxMRGZmZlQqVT46KOPYLFY/C6CGR8fD4PBgC1btiA5ORlhYWGXvf1/1KhRGDJkCA4fPuxzFgkA/u///g+PP/44UlJSMHz4cKhUKhw8eBDFxcV4/fXXsXLlSrjdbtx9990wGo14//33YTAY0L59+yt+JpezYsUKxMfHIzs7G4D3cmNeXh6++OILfPLJJ7j11luv+0U/iUKO0pOiiCjwfjop+VILFy4UiYmJwmAwiEGDBom//e1vAoCorq4WQvhO3Lbb7eLpp58WKSkpQqfTCavVKnJycnwmZe/du1cMGDBAhIeHC5PJJG6//fYWk64vdXHC8pIlS4TVahVhYWFi6NChoqqqSh7jdrvFrFmzRFJSktBqtaJHjx7ik08+kfcvX75cZGZmCpPJJMxms3jooYfE/v375f24ZOK2EEKsWLFCpKSkCJVKJfr163fZHrlcLpGYmCgAiG+//bZF7Vu2bBG9e/cWBoNBmM1mcdddd4nly5cLIYTYsGGDuPvuu4XZbBYmk0ncc889Ytu2bT/bB3/Ky8tF+/btxZkzZ3y2z5o1S8TExIiuXbuKL7/80mcfJ24TXTtJCCGUjWlEdDPLy8vDxo0bb/rHZ7R1H06cOIG0tDQcOHAAmZmZbXJMopsNJ24TEYWI4uJihIeHY8mSJdd0nEcffRTdu3dvo6qIbl6ck0REFAImT54sz3u61sfF/OUvf0FjYyMAcEVuomvAy21EREREfvByGxEREZEfDElEREREfjAkEREREfnBkERERETkB0MSERERkR8MSURERER+MCQRERER+cGQREREROTH/wN0TAWrzVEQ3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr_vals = []\n",
    "tpr_vals = []\n",
    "for ahead in range(max_ahead):\n",
    "    pred_vals = []\n",
    "    prob_vals = []\n",
    "    for graph in Truth_Graph_List[ahead]:\n",
    "        prob = graph.y\n",
    "        pred = np.asarray(models[max_ahead-1]([graph.x, graph.a]))\n",
    "        pred_vals.append(pred)\n",
    "        prob_vals.append(prob)\n",
    "\n",
    "    pred_vals = np.concatenate(pred_vals)\n",
    "    prob_vals = np.concatenate(prob_vals)\n",
    "\n",
    "    fprs, tprs, thres, auc = plot_roc(prob_vals, pred_vals)\n",
    "    \n",
    "    fpr_vals.append(fprs)\n",
    "    tpr_vals.append(tprs)\n",
    "\n",
    "    geo_mean = np.sqrt(tprs*(1-fprs))\n",
    "    \n",
    "    print('--------------------------')\n",
    "    print(f\"{ahead+1} Hour Lookahead AUC: \", auc)\n",
    "    print(\"Threshold Selected: \", thres[np.argmax(geo_mean)])\n",
    "    print(\"FPR Selected: \", fprs[np.argmax(geo_mean)])\n",
    "    print(\"TPR Selected: \", tprs[np.argmax(geo_mean)])\n",
    "    print('--------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.read_gml(\"Graph.gml\")\n",
    "Conjuct_Lon_Lat = nx.get_node_attributes(g,\"pos\")\n",
    "\n",
    "LonLat = []\n",
    "for n in range(n_nodes):\n",
    "    Lon = Node_Data[0][n,6]\n",
    "    Lat = Node_Data[0][n,7]\n",
    "    LonLat.append([Lon, Lat])\n",
    "\n",
    "Node_LonLat = np.array(LonLat)\n",
    "Diffs = []\n",
    "for key in list(Conjuct_Lon_Lat.keys()):\n",
    "    conj_lonlat = np.array(Conjuct_Lon_Lat[key]) \n",
    "    diff = np.sum(np.abs(Node_LonLat-conj_lonlat),axis=1)\n",
    "    Diffs.append(np.argsort(diff))\n",
    "\n",
    "Node_Lon_Lat = []\n",
    "Node_Color = []\n",
    "Size = []\n",
    "Tooltip = []\n",
    "for lonlat in LonLat:\n",
    "    \n",
    "    Node_Lon_Lat.append(list(lonlat))\n",
    "    Node_Color.append([0, 255, 0, 255])\n",
    "    Size.append(1)\n",
    "    Tooltip.append(\"Test does this work\")\n",
    "    \n",
    "num_conj_nodes = len(list(Conjuct_Lon_Lat.keys()))\n",
    "for key in range(num_conj_nodes):\n",
    "    conj_lonlat = np.array(Conjuct_Lon_Lat[str(key)])\n",
    "    \n",
    "    Node_Lon_Lat.append(list(conj_lonlat))\n",
    "    Node_Color.append([0, 255, 0, 255])\n",
    "    Size.append(20)\n",
    "    Tooltip.append(\" Test does this work\")\n",
    "    \n",
    "    \n",
    "dictv = {'coordinates': Node_Lon_Lat, 'color': Node_Color, 'size': Size, 'tooltip': Tooltip}\n",
    "\n",
    "plotting_df = pd.DataFrame(dictv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9128a05cd9254bd586b0c2ff42166b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54f091d905441ddb2a710db080dac13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Current Time (Hour):'), IntSlider(value=2, max=1459, min=2), Play(value=1, descrip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc402bf1a514ae5b156436d30e65eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Prediction Lookahead (min):'), IntSlider(value=0, max=360)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fbd0c308554c609e2d46a6e247d138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='k - KNN:'), IntSlider(value=1, max=30, min=1)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05dd70ae3e96446ba3453ae24316bc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='True Positive Rate:'), FloatSlider(value=0.5, max=1.0, step=0.001)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34eba32cc72f44009f264067ba1d38cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='False Positive Rate:'), FloatSlider(value=0.5, max=1.0, step=0.001)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860067ef5aba408caba56fc016a67a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Save Scenario', style=ButtonStyle()),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e216634716a043258d2a5a7e4adb5f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DeckGLWidget(carto_key=None, custom_libraries=[], google_maps_key=None, json_input='{\"effects\": [{\"@@type\": \"L"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Weather_Scenario_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36msave_scen\u001b[1;34m(btn)\u001b[0m\n\u001b[0;32m    220\u001b[0m Flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    221\u001b[0m num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 223\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavetxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWeather_Scenario_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:1498\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1495\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_string_like(fname):\n\u001b[0;32m   1497\u001b[0m     \u001b[38;5;66;03m# datasource doesn't support creating a new file ...\u001b[39;00m\n\u001b[1;32m-> 1498\u001b[0m     \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1499\u001b[0m     fh \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39m_datasource\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwt\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[0;32m   1500\u001b[0m     own_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'Weather_Scenario_1.csv'"
     ]
    }
   ],
   "source": [
    "max_time = len(Truth_Graph_List[0])\n",
    "\n",
    "\n",
    "sunlight = {\n",
    "    \"@@type\": \"_SunLight\",\n",
    "    \"timestamp\": 1564696800000,  # Date.UTC(2019, 7, 1, 22),\n",
    "    \"color\": [255, 255, 255],\n",
    "    \"intensity\": 1.0,\n",
    "    \"_shadow\": True,\n",
    "}\n",
    "\n",
    "ambient_light = {\"@@type\": \"AmbientLight\", \"color\": [255, 255, 255], \"intensity\": 1.0}\n",
    "\n",
    "lighting_effect = {\n",
    "    \"@@type\": \"LightingEffect\",\n",
    "    \"shadowColor\": [0, 0, 0, 0.5],\n",
    "    \"ambientLight\": ambient_light,\n",
    "    \"directionalLights\": [sunlight],\n",
    "}\n",
    "\n",
    "view_state = pdk.ViewState(\n",
    "    **{\"latitude\": JFK_LAT_LON[0], \"longitude\": JFK_LAT_LON[1], \"zoom\": 7, \"maxZoom\": 14, \"pitch\": 90, \"bearing\": 0}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "layer = pdk.Layer(\n",
    "    \"ScatterplotLayer\",\n",
    "    plotting_df,\n",
    "    pickable=True,\n",
    "    stroked=True,\n",
    "    filled=True,\n",
    "    radius_scale=200,\n",
    "    radius_min_pixels=1,\n",
    "    radius_max_pixels=100,\n",
    "    line_width_min_pixels=1,\n",
    "    get_position=\"coordinates\",\n",
    "    get_radius=\"size\",\n",
    "    get_fill_color=\"color\",\n",
    "    get_line_color=[0, 0, 0],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "tooltip = {\"html\": \"{tooltip}\"}\n",
    "\n",
    "keys = {\"mapbox\": \"pk.eyJ1IjoibWNkb25zdCIsImEiOiJjbDRyNGphOWwweHA1M2lxemI1ZXhmM3Y1In0.Km2Tt6dKpTqwfNmTMEKrQA\"}\n",
    "\n",
    "\n",
    "layers = [layer]\n",
    "\n",
    "r = pdk.Deck(\n",
    "    layers,\n",
    "    initial_view_state=view_state,\n",
    "    effects=[lighting_effect],\n",
    "    map_style=\"dark\",\n",
    "    api_keys=keys,\n",
    "    tooltip=tooltip,\n",
    ")\n",
    "\n",
    "\n",
    "time_label = ipywidgets.Label(value=\"Current Time (Hour):\", width=100)\n",
    "time_slider = ipywidgets.IntSlider(value=0, min=1+1, max=max_time-1, step=1)\n",
    "time_play = ipywidgets.Play(value=1, min=1, max=max_time-1, step=1, description='Press play', interval=200)\n",
    "ipywidgets.jslink((time_play, 'value'), (time_slider, 'value'))\n",
    "\n",
    "pred_label = ipywidgets.Label(value=\"Prediction Lookahead (min):\")\n",
    "pred_slider = ipywidgets.IntSlider(value=0, min=0, max=(max_ahead+1)*60, width=\"auto\", step=1)\n",
    "\n",
    "\n",
    "knn_label = ipywidgets.Label(value=\"k - KNN:\")\n",
    "knn_slider = ipywidgets.IntSlider(value=0, min=1, max=30, step=1)\n",
    "\n",
    "fpr_label = ipywidgets.Label(value=\"False Positive Rate:\")\n",
    "tpr_label = ipywidgets.Label(value=\"True Positive Rate:\")\n",
    "fpr_Slider = ipywidgets.FloatSlider(value=0.5, min=0, max=1,step=0.001)\n",
    "tpr_Slider = ipywidgets.FloatSlider(value=0.5, min=0, max=1,step=0.001)\n",
    "\n",
    "save_scenario = ipywidgets.Button(description=\"Save Scenario\")\n",
    "\n",
    "CG_Button = ipywidgets.ToggleButtons(\n",
    "    options=['No CG', 'CG'],\n",
    "    description='CG:',\n",
    "    disabled=False,\n",
    "    button_style=''\n",
    ")\n",
    "\n",
    "\n",
    "layout1 = ipywidgets.HBox([time_label, time_slider, time_play])\n",
    "layout2 = ipywidgets.HBox([pred_label, pred_slider])\n",
    "layout3 = ipywidgets.HBox([knn_label, knn_slider])\n",
    "layout4 = ipywidgets.HBox([tpr_label, tpr_Slider])\n",
    "layout5 = ipywidgets.HBox([fpr_label, fpr_Slider])\n",
    "layout6 = ipywidgets.HBox([save_scenario])\n",
    "\n",
    "\n",
    "# # function\n",
    "\n",
    "def update_graph(time, pred_time, knn_val, tpr_val):\n",
    "    \n",
    "    Conjuc_Nodes_Array = list(Conjuct_Lon_Lat.keys())\n",
    "    \n",
    "    tpr_diff = np.abs(tpr_vals[0]-tpr_val)\n",
    "    cutoff = thres[np.argmin(tpr_diff)]\n",
    "    \n",
    "    graph = Truth_Graph_List[0][time-1]\n",
    "    truth = graph.y[:,0]\n",
    "    \n",
    "    preds = []\n",
    "    for ahead in range(max_ahead):\n",
    "        graph = Truth_Graph_List[ahead][time]\n",
    "        pred = np.asarray(models[ahead]([graph.x, graph.a]))\n",
    "        preds.append(pred)\n",
    "\n",
    "        \n",
    "    colors = []\n",
    "    pred_vals = []\n",
    "    for n in range(n_nodes):\n",
    "        \n",
    "        x_array = [0]\n",
    "        y_array = [truth[n]]\n",
    "        \n",
    "        for ahead in range(max_ahead):\n",
    "            x_array.append((ahead+1)*60)\n",
    "            y_array.append(preds[ahead][n][0])\n",
    "\n",
    "            \n",
    "        xv = np.array(x_array)\n",
    "        yv = np.array(y_array)\n",
    "        \n",
    "        pred_val = np.interp(pred_time,xv,yv)\n",
    "        pred_vals.append(pred_val)\n",
    "        \n",
    "        if pred_val < cutoff:\n",
    "            colors.append([0, 255, 0, 255])\n",
    "        else:\n",
    "            colors.append([255, 0, 0, 255])\n",
    "            \n",
    "    pred_vals = np.array(pred_vals)\n",
    "            \n",
    "    for i,key in enumerate(Conjuc_Nodes_Array):\n",
    "        \n",
    "        pred_val = np.mean(pred_vals[Diffs[i][:knn_val]])\n",
    "\n",
    "        if pred_val < cutoff:\n",
    "            colors.append([0, 255, 0, 255])\n",
    "        else:\n",
    "            colors.append([255, 0, 0, 255])\n",
    "            \n",
    "            \n",
    "    Time_Nodes = (max_ahead+1)*60\n",
    "    num_conj_nodes = len(Conjuc_Nodes_Array)\n",
    "    \n",
    "    dictv = {'color': colors}\n",
    "    \n",
    "    df = pd.DataFrame(dictv)\n",
    "    \n",
    "    plotting_df.color = df.color\n",
    "\n",
    "    \n",
    "    layer.data = plotting_df\n",
    "\n",
    "    \n",
    "    return r.update()\n",
    "\n",
    "def save_scen(btn):\n",
    "    \n",
    "    time = time_slider.value\n",
    "    knn_val = knn_slider.value\n",
    "    tpr_val = tpr_Slider.value\n",
    "    \n",
    "    Conjuc_Nodes_Array = list(Conjuct_Lon_Lat.keys())\n",
    "    \n",
    "    tpr_diff = np.abs(tpr_vals[0]-tpr_val)\n",
    "    cutoff = thres[np.argmin(tpr_diff)]\n",
    "    \n",
    "    graph = Truth_Graph_List[0][time-1]\n",
    "    truth = graph.y[:,0]\n",
    "    \n",
    "    preds = []\n",
    "    for ahead in range(max_ahead):\n",
    "        graph = Truth_Graph_List[ahead][time]\n",
    "        pred = np.asarray(models[ahead]([graph.x, graph.a]))\n",
    "        preds.append(pred)\n",
    "            \n",
    "            \n",
    "    Time_Nodes = (max_ahead+1)*60\n",
    "    num_conj_nodes = len(Conjuc_Nodes_Array)\n",
    "\n",
    "    cutoff_vals = np.zeros((Time_Nodes, num_conj_nodes))\n",
    "    for pred_time in range(Time_Nodes):\n",
    "        \n",
    "        pred_vals = []\n",
    "        for n in range(n_nodes):\n",
    "        \n",
    "            x_array = [0]\n",
    "            y_array = [truth[n]]\n",
    "\n",
    "            for ahead in range(max_ahead):\n",
    "                x_array.append((ahead+1)*60)\n",
    "                y_array.append(preds[ahead][n][0])\n",
    "\n",
    "\n",
    "            xv = np.array(x_array)\n",
    "            yv = np.array(y_array)\n",
    "\n",
    "            pred_val = np.interp(pred_time,xv,yv)\n",
    "            pred_vals.append(pred_val)\n",
    "        \n",
    "        \n",
    "   \n",
    "        pred_vals = np.array(pred_vals)\n",
    "        for i,key in enumerate(Conjuc_Nodes_Array):\n",
    "\n",
    "            pred_val = np.mean(pred_vals[Diffs[i][:knn_val]])\n",
    "            if pred_val > cutoff:\n",
    "                cutoff_vals[pred_time,i] = 1\n",
    "                \n",
    "    Flag = True\n",
    "    num = 1\n",
    "       \n",
    "    np.savetxt(f\"Weather_Scenario_{num}.csv\", cutoff_vals, delimiter=\",\")\n",
    "           \n",
    "    \n",
    "            \n",
    "\n",
    "def update_fpr(change):\n",
    "    fpr_Slider.value = np.interp(tpr_Slider.value,tpr_vals[0],fpr_vals[0])\n",
    "\n",
    "\n",
    "def update_tpr(change):\n",
    "    tpr_Slider.value = np.interp(fpr_Slider.value,fpr_vals[0],tpr_vals[0])\n",
    "    \n",
    "    \n",
    "tpr_Slider.observe(update_fpr, names='value')\n",
    "save_scenario.on_click(save_scen)\n",
    "\n",
    "\n",
    "# # interaction between widget and function\n",
    "interact = ipywidgets.interactive_output(update_graph, {'time': time_slider, 'pred_time': pred_slider, 'knn_val': knn_slider, 'tpr_val': tpr_Slider, 'knn_val': knn_slider});\n",
    "\n",
    "display(interact,layout1,layout2,layout3,layout4,layout5,layout6)\n",
    "\n",
    "\n",
    "\n",
    "# # display and save map (to_html(), show())\n",
    "r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonlat_org = Wind_Projected_Data_Org[(0,0)]\n",
    "lonlat_new = Wind_Projected_Data_New[(0,0)]\n",
    "\n",
    "Node_Lon_Lat = []\n",
    "Node_Color = []\n",
    "Size = []\n",
    "Tooltip = []\n",
    "for n, lonlat in enumerate(lonlat_org):\n",
    "    \n",
    "    Node_Lon_Lat.append(list(lonlat))\n",
    "    Node_Color.append([0, 255, 0, 255])\n",
    "    Size.append(20)\n",
    "    Tooltip.append(f\"Node {n}\")\n",
    "    \n",
    "for n, lonlat in enumerate(lonlat_new):\n",
    "    \n",
    "    Node_Lon_Lat.append(list(lonlat))\n",
    "    Node_Color.append([255, 0, 0, 255])\n",
    "    Size.append(20)\n",
    "    Tooltip.append(f\"Node {n}\")\n",
    "    \n",
    "    \n",
    "dictv = {'coordinates': Node_Lon_Lat, 'color': Node_Color, 'size': Size, 'tooltip': Tooltip}\n",
    "\n",
    "plotting_df = pd.DataFrame(dictv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394a04764c9f4543a216b86d35333132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580867c859ba4bea9d45c2c1742c2373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Current Time (Hour):'), IntSlider(value=0, max=1459), Play(value=1, description='P"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d74e488b4c8422f8e772a1d807a392d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Prediction Lookahead (min):'), IntSlider(value=1, max=5, min=1)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb6d231fca6475daa6afe03f0487f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DeckGLWidget(carto_key=None, custom_libraries=[], google_maps_key=None, json_input='{\"effects\": [{\"@@type\": \"L"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sunlight = {\n",
    "    \"@@type\": \"_SunLight\",\n",
    "    \"timestamp\": 1564696800000,  # Date.UTC(2019, 7, 1, 22),\n",
    "    \"color\": [255, 255, 255],\n",
    "    \"intensity\": 1.0,\n",
    "    \"_shadow\": True,\n",
    "}\n",
    "\n",
    "ambient_light = {\"@@type\": \"AmbientLight\", \"color\": [255, 255, 255], \"intensity\": 1.0}\n",
    "\n",
    "lighting_effect = {\n",
    "    \"@@type\": \"LightingEffect\",\n",
    "    \"shadowColor\": [0, 0, 0, 0.5],\n",
    "    \"ambientLight\": ambient_light,\n",
    "    \"directionalLights\": [sunlight],\n",
    "}\n",
    "\n",
    "view_state = pdk.ViewState(\n",
    "    **{\"latitude\": JFK_LAT_LON[0], \"longitude\": JFK_LAT_LON[1], \"zoom\": 7, \"maxZoom\": 14, \"pitch\": 90, \"bearing\": 0}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "layer = pdk.Layer(\n",
    "    \"ScatterplotLayer\",\n",
    "    plotting_df,\n",
    "    pickable=True,\n",
    "    stroked=True,\n",
    "    filled=True,\n",
    "    radius_scale=200,\n",
    "    radius_min_pixels=1,\n",
    "    radius_max_pixels=100,\n",
    "    line_width_min_pixels=1,\n",
    "    get_position=\"coordinates\",\n",
    "    get_radius=\"size\",\n",
    "    get_fill_color=\"color\",\n",
    "    get_line_color=[0, 0, 0],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "tooltip = {\"html\": \"{tooltip}\"}\n",
    "\n",
    "keys = {\"mapbox\": \"pk.eyJ1IjoibWNkb25zdCIsImEiOiJjbDRyNGphOWwweHA1M2lxemI1ZXhmM3Y1In0.Km2Tt6dKpTqwfNmTMEKrQA\"}\n",
    "\n",
    "\n",
    "layers = [layer]\n",
    "\n",
    "r = pdk.Deck(\n",
    "    layers,\n",
    "    initial_view_state=view_state,\n",
    "    effects=[lighting_effect],\n",
    "    map_style=\"dark\",\n",
    "    api_keys=keys,\n",
    "    tooltip=tooltip,\n",
    ")\n",
    "\n",
    "\n",
    "time_label = ipywidgets.Label(value=\"Current Time (Hour):\", width=100)\n",
    "time_slider = ipywidgets.IntSlider(value=0, min=0, max=max_time-1, step=1)\n",
    "\n",
    "pred_label = ipywidgets.Label(value=\"Prediction Lookahead (min):\")\n",
    "pred_slider = ipywidgets.IntSlider(value=0, min=1, max=max_ahead, width=\"auto\", step=1)\n",
    "\n",
    "\n",
    "\n",
    "layout1 = ipywidgets.HBox([time_label, time_slider, time_play])\n",
    "layout2 = ipywidgets.HBox([pred_label, pred_slider])\n",
    "\n",
    "\n",
    "# # function\n",
    "\n",
    "def update_graph(time, pred_time):\n",
    "    \n",
    "    east_winds = East_Wind[(time,pred_time-1)]\n",
    "    north_winds = North_Wind[(time,pred_time-1)]\n",
    "    \n",
    "    lonlat_org = Wind_Projected_Data_Org[(time,pred_time-1)]\n",
    "    lonlat_new = Wind_Projected_Data_New[(time,pred_time-1)]\n",
    "\n",
    "    Node_Lon_Lat = []\n",
    "    Node_Color = []\n",
    "    Size = []\n",
    "    Tooltip = []\n",
    "    for n, lonlat in enumerate(lonlat_org):\n",
    "\n",
    "        Node_Lon_Lat.append(list(lonlat))\n",
    "        Node_Color.append([0, 255, 0, 255])\n",
    "        Size.append(20)\n",
    "        Tooltip.append(f\"Node {n} | East Wind: {east_winds[n]} | North Wind {north_winds[n]}\")\n",
    "\n",
    "    for n, lonlat in enumerate(lonlat_new):\n",
    "\n",
    "        Node_Lon_Lat.append(list(lonlat))\n",
    "        Node_Color.append([255, 0, 0, 255])\n",
    "        Size.append(20)\n",
    "        Tooltip.append(f\"Projected Node {n}\")\n",
    "\n",
    "\n",
    "    dictv = {'coordinates': Node_Lon_Lat, 'color': Node_Color, 'size': Size, 'tooltip': Tooltip}\n",
    "\n",
    "    plotting_df = pd.DataFrame(dictv)\n",
    "    \n",
    "    layer.data = plotting_df\n",
    "\n",
    "    \n",
    "    return r.update()\n",
    "\n",
    "\n",
    "\n",
    "# # interaction between widget and function\n",
    "interact = ipywidgets.interactive_output(update_graph, {'time': time_slider, 'pred_time': pred_slider});\n",
    "\n",
    "display(interact,layout1,layout2)\n",
    "\n",
    "\n",
    "\n",
    "# # display and save map (to_html(), show())\n",
    "r.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
